<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <meta name="description" content=""/>
    <meta name="author"
          content="Zeqiang Lai"
    />
    <title>Awesome Diffusion</title>

    <!-- CSS only -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-0evHe/X+R7YkIZDRvuzKMRqM+OrBnVFBL6DOitfPri4tjfHxaWutUpFmBp4vmVor" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="style.css" rel="stylesheet"/>
    <link href="sidebars.css" rel="stylesheet"/>
</head>
<body>
<nav class="navbar navbar-expand-md fixed-top bg-light">
    <div class="container">
        <button
                class="navbar-toggler float-left"
                type="button"
                data-bs-toggle="collapse"
                data-bs-target="#bd-docs-nav"
                aria-controls="bd-docs-nav"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <a class="navbar-brand" href="#">Awesome Diffusion Models</a>
        <button
                class="navbar-toggler"
                type="button"
                data-bs-toggle="collapse"
                data-bs-target="#navbarCollapse"
                aria-controls="navbarCollapse"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav me-auto mb-2 mb-md-0">
                <li class="nav-item">
                        <a class="nav-link active" aria-current="page" href="index.html">Paper</a>
                </li>
                <li class="nav-item">
                        <a class="nav-link" href="resource.html">Resources</a>
                </li>
            </ul>
            <ul class="navbar-nav flex-row flex-wrap ms-md-auto">
                <li class="nav-item col-6 col-lg-auto">
                    <a class="nav-link py-2 px-0 px-lg-2" href="#" onclick="toggle_counter()"
                       rel="noopener">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                             class="bi bi-disc navbar-nav-svg" viewBox="0 0 16 16">
                            <path d="M8 15A7 7 0 1 1 8 1a7 7 0 0 1 0 14zm0 1A8 8 0 1 0 8 0a8 8 0 0 0 0 16z"/>
                            <path d="M10 8a2 2 0 1 1-4 0 2 2 0 0 1 4 0zM8 4a4 4 0 0 0-4 4 .5.5 0 0 1-1 0 5 5 0 0 1 5-5 .5.5 0 0 1 0 1zm4.5 3.5a.5.5 0 0 1 .5.5 5 5 0 0 1-5 5 .5.5 0 0 1 0-1 4 4 0 0 0 4-4 .5.5 0 0 1 .5-.5z"/>
                        </svg>
                        <small class="d-lg-none ms-2">Toggle Counter</small>
                    </a>
                </li>
                <li class="nav-item col-6 col-lg-auto">
                    <a class="nav-link py-2 px-0 px-lg-2" href="https://github.com/heejkoo/Awesome-Diffusion-Models" target="_blank" rel="noopener">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" class="navbar-nav-svg"
                             viewBox="0 0 512 499.36" role="img"><title>GitHub</title>
                            <path fill="currentColor" fill-rule="evenodd"
                                  d="M256 0C114.64 0 0 114.61 0 256c0 113.09 73.34 209 175.08 242.9 12.8 2.35 17.47-5.56 17.47-12.34 0-6.08-.22-22.18-.35-43.54-71.2 15.49-86.2-34.34-86.2-34.34-11.64-29.57-28.42-37.45-28.42-37.45-23.27-15.84 1.73-15.55 1.73-15.55 25.69 1.81 39.21 26.38 39.21 26.38 22.84 39.12 59.92 27.82 74.5 21.27 2.33-16.54 8.94-27.82 16.25-34.22-56.84-6.43-116.6-28.43-116.6-126.49 0-27.95 10-50.8 26.35-68.69-2.63-6.48-11.42-32.5 2.51-67.75 0 0 21.49-6.88 70.4 26.24a242.65 242.65 0 0 1 128.18 0c48.87-33.13 70.33-26.24 70.33-26.24 14 35.25 5.18 61.27 2.55 67.75 16.41 17.9 26.31 40.75 26.31 68.69 0 98.35-59.85 120-116.88 126.32 9.19 7.9 17.38 23.53 17.38 47.41 0 34.22-.31 61.83-.31 70.23 0 6.85 4.61 14.81 17.6 12.31C438.72 464.97 512 369.08 512 256.02 512 114.62 397.37 0 256 0z"></path>
                        </svg>
                        <small class="d-lg-none ms-2">GitHub</small>
                    </a>
                </li>
            </ul>
        </div>
    </div>
</nav>


<div class="container-fluid">
    <div class="container">
        <div class="row">
            <div class="col-md-3 bd-sidebar" style="padding-right: 2rem">
                <!-- <nav class="collapse show" id="bd-docs-nav"> -->
                    <ol class="list-unstyled">
                            <li class="mb-1">
                                <div class="d-flex justify-content-between align-items-center">
                                    <a class="btn rounded border-0 collapsed" href="vision.html">
                                        <strong>Vision</strong>
                                    </a>
                                    <span class="badge rounded-pill text-bg-secondary counter"> 1543 </span>
                                </div>
                                <div class="collapse show" id="home-collapse">
                                    <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Generation
                                                    </a>
                                                    <div class="counter">295</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_classification.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Classification
                                                    </a>
                                                    <div class="counter">31</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_segmentation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Segmentation
                                                    </a>
                                                    <div class="counter">49</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_image_translation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Image Translation
                                                    </a>
                                                    <div class="counter">46</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_inverse_problems.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Inverse Problems
                                                    </a>
                                                    <div class="counter">163</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_medical_imaging.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Medical Imaging
                                                    </a>
                                                    <div class="counter">133</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_multi-modal_learning.html"
                                                       class="a-toggle link-dark d-inline-flex text-decoration-none rounded"
                                                    >Multi-modal Learning
                                                    </a>
                                                    <div class="counter">417</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_3d_vision.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >3D Vision
                                                    </a>
                                                    <div class="counter">183</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_adversarial_attack.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Adversarial Attack
                                                    </a>
                                                    <div class="counter">45</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_miscellany.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Miscellany
                                                    </a>
                                                    <div class="counter">181</div>
                                                </div>
                                            </li>
                                    </ul>
                                </div>
                            </li>
                            <li class="mb-1">
                                <div class="d-flex justify-content-between align-items-center">
                                    <a class="btn rounded border-0 collapsed" href="audio.html">
                                        <strong>Audio</strong>
                                    </a>
                                    <span class="badge rounded-pill text-bg-secondary counter"> 118 </span>
                                </div>
                                <div class="collapse show" id="home-collapse">
                                    <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Generation
                                                    </a>
                                                    <div class="counter">34</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_conversion.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Conversion
                                                    </a>
                                                    <div class="counter">4</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_enhancement.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Enhancement
                                                    </a>
                                                    <div class="counter">25</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_separation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Separation
                                                    </a>
                                                    <div class="counter">5</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_text-to-speech.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Text-to-Speech
                                                    </a>
                                                    <div class="counter">40</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_miscellany.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Miscellany
                                                    </a>
                                                    <div class="counter">10</div>
                                                </div>
                                            </li>
                                    </ul>
                                </div>
                            </li>
                            <li class="mb-1">
                                <div class="d-flex justify-content-between align-items-center">
                                    <a class="btn rounded border-0 collapsed" href="tabular_and_time_series.html">
                                        <strong>Tabular and Time Series</strong>
                                    </a>
                                    <span class="badge rounded-pill text-bg-secondary counter"> 38 </span>
                                </div>
                                <div class="collapse show" id="home-collapse">
                                    <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="tabular_and_time_series_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Generation
                                                    </a>
                                                    <div class="counter">10</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="tabular_and_time_series_forecasting.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Forecasting
                                                    </a>
                                                    <div class="counter">12</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="tabular_and_time_series_imputation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Imputation
                                                    </a>
                                                    <div class="counter">6</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="tabular_and_time_series_miscellany.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Miscellany
                                                    </a>
                                                    <div class="counter">10</div>
                                                </div>
                                            </li>
                                    </ul>
                                </div>
                            </li>
                            <li class="mb-1">
                                <div class="d-flex justify-content-between align-items-center">
                                    <a class="btn rounded border-0 collapsed" href="graph.html">
                                        <strong>Graph</strong>
                                    </a>
                                    <span class="badge rounded-pill text-bg-secondary counter"> 70 </span>
                                </div>
                                <div class="collapse show" id="home-collapse">
                                    <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="graph_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Generation
                                                    </a>
                                                    <div class="counter">20</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="graph_molecular_and_material_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Molecular and Material Generation
                                                    </a>
                                                    <div class="counter">50</div>
                                                </div>
                                            </li>
                                    </ul>
                                </div>
                            </li>
                    </ul>

                <!-- </nav> -->
            </div>
            <main class='col-md-9 bd-content' role="main">
                <ol class="list-group list-group-numbered">
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Michelangelo: Conditional 3D Shape Generation based on Shape-Image-Text Aligned Latent Representation  </div>
                                <div> Zibo Zhao, Wen Liu, Xin Chen, Xianfang Zeng, Rui Wang, Pei Cheng, Bin Fu, Tao Chen, Gang Yu, Shenghua Gao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.17115"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-29</div>
                            </div>
                            <div class="paper-date">2023-06-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> PFB-Diff: Progressive Feature Blending Diffusion for Text-driven Image Editing  </div>
                                <div> Wenjing Huang, Shikui Tu, Lei Xu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.16894"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-28</div>
                            </div>
                            <div class="paper-date">2023-06-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Decompose and Realign: Tackling Condition Misalignment in Text-to-Image Diffusion Models  </div>
                                <div> Luozhou Wang, Guibao Shen, Yijun Li, Ying-cong Chen </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.14408"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-26</div>
                            </div>
                            <div class="paper-date">2023-06-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> A-STAR: Test-time Attention Segregation and Retention for Text-to-image Synthesis  </div>
                                <div> Aishwarya Agarwal, Srikrishna Karanam, K J Joseph, Apoorv Saxena, Koustava Goswami, Balaji Vasan Srinivasan </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.14544"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-26</div>
                            </div>
                            <div class="paper-date">2023-06-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffSketcher: Text Guided Vector Sketch Synthesis through Latent Diffusion Models  </div>
                                <div> Ximing Xing, Chuang Wang, Haitao Zhou, Jing Zhang, Qian Yu, Dong Xu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.14685"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-26</div>
                            </div>
                            <div class="paper-date">2023-06-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Zero-shot spatial layout conditioning for text-to-image diffusion models  </div>
                                <div> Guillaume Couairon, Marlène Careil, Matthieu Cord, Stéphane Lathuilière, Jakob Verbeek </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.13754"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-23</div>
                            </div>
                            <div class="paper-date">2023-06-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DreamTime: An Improved Optimization Strategy for Text-to-3D Content Creation  </div>
                                <div> Yukun Huang, Jianan Wang, Yukai Shi, Xianbiao Qi, Zheng-Jun Zha, Lei Zhang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.12422"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-21</div>
                            </div>
                            <div class="paper-date">2023-06-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model  </div>
                                <div> Zilun Zhang, Tiancheng Zhao, Yulong Guo, Jianwei Yin </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.11300"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-20</div>
                            </div>
                            <div class="paper-date">2023-06-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> EMoG: Synthesizing Emotive Co-speech 3D Gesture with Diffusion Model  </div>
                                <div> Lianying Yin, Yijun Wang, Tianyu He, Jinming Liu, Wei Zhao, Bohan Li, Xin Jin, Jianxin Lin </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.11496"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-20</div>
                            </div>
                            <div class="paper-date">2023-06-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Align, Adapt and Inject: Sound-guided Unified Image Generation  </div>
                                <div> Yue Yang, Kaipeng Zhang, Yuying Ge, Wenqi Shao, Zeyue Xue, Yu Qiao, Ping Luo </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.11504"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-20</div>
                            </div>
                            <div class="paper-date">2023-06-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Conditional Text Image Generation with Diffusion Models  </div>
                                <div> Yuanzhi Zhu, Zhaohai Li, Tianwei Wang, Mengchao He, Cong Yao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.10804"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-19</div>
                            </div>
                            <div class="paper-date">2023-06-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Instruct-NeuralTalker: Editing Audio-Driven Talking Radiance Fields with Instructions  </div>
                                <div> Yuqi Sun, Reian He, Weimin Tan, Bo Yan </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.10813"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-19</div>
                            </div>
                            <div class="paper-date">2023-06-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Point-Cloud Completion with Pretrained Text-to-image Diffusion Models  </div>
                                <div> Yoni Kasten, Ohad Rahamim, Gal Chechik </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.10533"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-18</div>
                            </div>
                            <div class="paper-date">2023-06-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models  </div>
                                <div> Hao-Wen Dong, Xiaoyu Liu, Jordi Pons, Gautam Bhattacharya, Santiago Pascual, Joan Serrà, Taylor Berg-Kirkpatrick, Julian McAuley </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.09635"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-16</div>
                            </div>
                            <div class="paper-date">2023-06-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks  </div>
                                <div> Hongcheng Gao, Hao Zhang, Yinpeng Dong, Zhijie Deng </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.13103"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-16</div>
                            </div>
                            <div class="paper-date">2023-06-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models  </div>
                                <div> Geon Yeong Park, Jeongsol Kim, Beomsu Kim, Sang Wan Lee, Jong Chul Ye </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.09869"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-16</div>
                            </div>
                            <div class="paper-date">2023-06-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Training Multimedia Event Extraction With Generated Images and Captions  </div>
                                <div> Zilin Du, Yunxin Li, Xu Guo, Yidan Sun, Boyang Li </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.08966"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-15</div>
                            </div>
                            <div class="paper-date">2023-06-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Linguistic Binding in Diffusion Models: Enhancing Attribute Correspondence through Attention Map Alignment  </div>
                                <div> Royi Rassin, Eran Hirsch, Daniel Glickman, Shauli Ravfogel, Yoav Goldberg, Gal Chechik </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.08877"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-15</div>
                            </div>
                            <div class="paper-date">2023-06-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion Models for Zero-Shot Open-Vocabulary Segmentation  </div>
                                <div> Laurynas Karazija, Iro Laina, Andrea Vedaldi, Christian Rupprecht </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.09316"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-15</div>
                            </div>
                            <div class="paper-date">2023-06-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis  </div>
                                <div> Shivam Mehta, Siyang Wang, Simon Alexanderson, Jonas Beskow, Éva Székely, Gustav Eje Henter </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.09417"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-15</div>
                            </div>
                            <div class="paper-date">2023-06-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Taming Diffusion Models for Music-driven Conducting Motion Generation  </div>
                                <div> Zhuoran Zhao, Jinbin Bai, Delong Chen, Debang Wang, Yubo Pan </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.10065"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-15</div>
                            </div>
                            <div class="paper-date">2023-06-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion in Diffusion: Cyclic One-Way Diffusion for Text-Vision-Conditioned Generation  </div>
                                <div> Yongqi Yang, Ruoyu Wang, Zhihao Qian, Ye Zhu, Yu Wu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.08247"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-14</div>
                            </div>
                            <div class="paper-date">2023-06-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> GBSD: Generative Bokeh with Stage Diffusion  </div>
                                <div> Jieren Deng, Xin Zhou, Hao Tian, Zhihong Pan, Derek Aguiar </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.08251"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-14</div>
                            </div>
                            <div class="paper-date">2023-06-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Training-free Diffusion Model Adaptation for Variable-Sized Text-to-Image Synthesis  </div>
                                <div> Zhiyu Jin, Xuli Shen, Bin Li, Xiangyang Xue </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.08645"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-14</div>
                            </div>
                            <div class="paper-date">2023-06-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Norm-guided latent space exploration for text-to-image generation  </div>
                                <div> Dvir Samuel, Rami Ben-Ari, Nir Darshan, Haggai Maron, Gal Chechik </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.08687"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-14</div>
                            </div>
                            <div class="paper-date">2023-06-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> VidEdit: Zero-Shot and Spatially Aware Text-Driven Video Editing  </div>
                                <div> Paul Couairon, Clément Rambour, Jean-Emmanuel Haugeard, Nicolas Thome </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.08707"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-14</div>
                            </div>
                            <div class="paper-date">2023-06-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Paste, Inpaint and Harmonize via Denoising: Subject-Driven Image Editing with Pre-Trained Diffusion Model  </div>
                                <div> Xin Zhang, Jiaxian Guo, Paul Yoo, Yutaka Matsuo, Yusuke Iwasawa </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.07596"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-13</div>
                            </div>
                            <div class="paper-date">2023-06-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation  </div>
                                <div> Shuai Yang, Yifan Zhou, Ziwei Liu, Chen Change Loy </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.07954"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-13</div>
                            </div>
                            <div class="paper-date">2023-06-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> InstructP2P: Learning to Edit 3D Point Clouds with Text Instructions  </div>
                                <div> Jiale Xu, Xintao Wang, Yan-Pei Cao, Weihao Cheng, Ying Shan, Shenghua Gao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.07154"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-12</div>
                            </div>
                            <div class="paper-date">2023-06-12</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> MovieFactory: Automatic Movie Creation from Text using Large Generative Models for Language and Images  </div>
                                <div> Junchen Zhu, Huan Yang, Huiguo He, Wenjing Wang, Zixi Tuo, Wen-Huang Cheng, Lianli Gao, Jingkuan Song, Jianlong Fu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.07257"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-12</div>
                            </div>
                            <div class="paper-date">2023-06-12</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Controlling Text-to-Image Diffusion by Orthogonal Finetuning  </div>
                                <div> Zeju Qiu, Weiyang Liu, Haiwen Feng, Yuxuan Xue, Yao Feng, Zhen Liu, Dan Zhang, Adrian Weller, Bernhard Schölkopf </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.07280"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-12</div>
                            </div>
                            <div class="paper-date">2023-06-12</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Language-Guided Traffic Simulation via Scene-Level Diffusion  </div>
                                <div> Ziyuan Zhong, Davis Rempe, Yuxiao Chen, Boris Ivanovic, Yulong Cao, Danfei Xu, Marco Pavone, Baishakhi Ray </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.06344"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-10</div>
                            </div>
                            <div class="paper-date">2023-06-10</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Improving Tuning-Free Real Image Editing with Proximal Guidance  </div>
                                <div> Ligong Han, Song Wen, Qi Chen, Zhixing Zhang, Kunpeng Song, Mengwei Ren, Ruijiang Gao, Yuxiao Chen, Di Liu, Qilong Zhangli, Anastasis Stathopoulos, Jindong Jiang, Zhaoyang Xia, Akash Srivastava, Dimitris Metaxas </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.05414"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-08</div>
                            </div>
                            <div class="paper-date">2023-06-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SyncDiffusion: Coherent Montage via Synchronized Joint Diffusions  </div>
                                <div> Yuseung Lee, Kunho Kim, Hyunjin Kim, Minhyuk Sung </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.05178"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://syncdiffusion.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/KAIST-Geometric-AI-Group/SyncDiffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-08</div>
                            </div>
                            <div class="paper-date">2023-06-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Grounded Text-to-Image Synthesis with Attention Refocusing  </div>
                                <div> Quynh Phung, Songwei Ge, Jia-Bin Huang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.05427"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-08</div>
                            </div>
                            <div class="paper-date">2023-06-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> BOOT: Data-free Distillation of Denoising Diffusion Models with Bootstrapping  </div>
                                <div> Jiatao Gu, Shuangfei Zhai, Yizhe Zhang, Lingjie Liu, Josh Susskind </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.05544"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-08</div>
                            </div>
                            <div class="paper-date">2023-06-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Improving Diffusion-based Image Translation using Asymmetric Gradient Guidance  </div>
                                <div> Gihyun Kwon, Jong Chul Ye </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.04396"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-07</div>
                            </div>
                            <div class="paper-date">2023-06-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt  </div>
                                <div> Kai Chen, Enze Xie, Zhe Chen, Lanqing Hong, Zhenguo Li, Dit-Yan Yeung </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.04607"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-07</div>
                            </div>
                            <div class="paper-date">2023-06-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Multi-modal Latent Diffusion  </div>
                                <div> Mustapha Bounoua, Giulio Franzese, Pietro Michiardi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.04445"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-07</div>
                            </div>
                            <div class="paper-date">2023-06-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Designing a Better Asymmetric VQGAN for StableDiffusion  </div>
                                <div> Zixin Zhu, Xuelu Feng, Dongdong Chen, Jianmin Bao, Le Wang, Yinpeng Chen, Lu Yuan, Gang Hua </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.04632"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/buxiangzhiren/Asymmetric_VQGAN"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-07</div>
                            </div>
                            <div class="paper-date">2023-06-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ConceptBed: Evaluating Concept Learning Abilities of Text-to-Image Diffusion Models  </div>
                                <div> Maitreya Patel, Tejas Gokhale, Chitta Baral, Yezhou Yang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.04695"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-07</div>
                            </div>
                            <div class="paper-date">2023-06-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> WOUAF: Weight Modulation for User Attribution and Fingerprinting in Text-to-Image Diffusion Models  </div>
                                <div> Changhoon Kim, Kyle Min, Maitreya Patel, Sheng Cheng, Yezhou Yang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.04744"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-07</div>
                            </div>
                            <div class="paper-date">2023-06-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> User-friendly Image Editing with Minimal Text Input: Leveraging Captioning and Injection Techniques  </div>
                                <div> Sunwoo Kim, Wooseok Jang, Hyunsu Kim, Junho Kim, Yunjey Choi, Seungryong Kim, Gayeong Lee </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.02717"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-05</div>
                            </div>
                            <div class="paper-date">2023-06-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Towards Unified Text-based Person Retrieval: A Large-scale Multi-Attribute and Language Search Benchmark  </div>
                                <div> Shuyu Yang, Yinan Zhou, Yaxiong Wang, Yujiao Wu, Li Zhu, Zhedong Zheng </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.02898"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-05</div>
                            </div>
                            <div class="paper-date">2023-06-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Instruct-Video2Avatar: Video-to-Avatar Generation with Instructions  </div>
                                <div> Shaoxu Li </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.02903"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-05</div>
                            </div>
                            <div class="paper-date">2023-06-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> HeadSculpt: Crafting 3D Head Avatars with Text  </div>
                                <div> Xiao Han, Yukang Cao, Kai Han, Xiatian Zhu, Jiankang Deng, Yi-Zhe Song, Tao Xiang, Kwan-Yee K. Wong </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.03038"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://brandonhan.uk/HeadSculpt/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-05</div>
                            </div>
                            <div class="paper-date">2023-06-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> LipVoicer: Generating Speech from Silent Videos Guided by Lip Reading  </div>
                                <div> Yochai Yemini, Aviv Shamsian, Lior Bracha, Sharon Gannot, Ethan Fetaya </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.03258"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://lipvoicer.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-05</div>
                            </div>
                            <div class="paper-date">2023-06-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Stable Diffusion is Unstable  </div>
                                <div> Chengbin Du, Yanxi Li, Zhongwei Qiu, Chang Xu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.02583"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-05</div>
                            </div>
                            <div class="paper-date">2023-06-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Detector Guidance for Multi-Object Text-to-Image Generation  </div>
                                <div> Luping Liu, Zijian Zhang, Yi Ren, Rongjie Huang, Xiang Yin, Zhou Zhao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.02236"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-04</div>
                            </div>
                            <div class="paper-date">2023-06-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Efficient Text-Guided 3D-Aware Portrait Generation with Score Distillation Sampling on Distribution  </div>
                                <div> Yiji Cheng, Fei Yin, Xiaoke Huang, Xintong Yu, Jiaxiang Liu, Shikun Feng, Yujiu Yang, Yansong Tang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.02083"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-03</div>
                            </div>
                            <div class="paper-date">2023-06-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Word-Level Explanations for Analyzing Bias in Text-to-Image Models  </div>
                                <div> Alexander Lin, Lucas Monteiro Paes, Sree Harsha Tanneru, Suraj Srinivas, Himabindu Lakkaraju </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.05500"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-03</div>
                            </div>
                            <div class="paper-date">2023-06-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Privacy Distillation: Reducing Re-identification Risk of Multimodal Diffusion Models  </div>
                                <div> Virginia Fernandez, Pedro Sanchez, Walter Hugo Lopez Pinaya, Grzegorz Jacenków, Sotirios A. Tsaftaris, Jorge Cardoso </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.01322"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-02</div>
                            </div>
                            <div class="paper-date">2023-06-02</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Audio-Visual Speech Enhancement with Score-Based Generative Models  </div>
                                <div> Julius Richter, Simone Frintrop, Timo Gerkmann </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.01432"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-02</div>
                            </div>
                            <div class="paper-date">2023-06-02</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Video Colorization with Pre-trained Text-to-Image Diffusion Models  </div>
                                <div> Hanyuan Liu, Minshan Xie, Jinbo Xing, Chengze Li, Tien-Tsin Wong </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.01732"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-02</div>
                            </div>
                            <div class="paper-date">2023-06-02</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Probabilistic Adaptation of Text-to-Video Models  </div>
                                <div> Mengjiao Yang, Yilun Du, Bo Dai, Dale Schuurmans, Joshua B. Tenenbaum, Pieter Abbeel </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.01872"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://video-adapter.github.io/video-adapter/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-02</div>
                            </div>
                            <div class="paper-date">2023-06-02</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> FigGen: Text to Scientific Figure Generation  </div>
                                <div> Juan A. Rodriguez, David Vazquez, Issam Laradji, Marco Pedersoli, Pau Rodriguez </div>
                                <div>
                                        ICLR 2023.

                                        <a href="https://arxiv.org/abs/2306.00800"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> UniDiff: Advancing Vision-Language Models with Generative and Discriminative Learning  </div>
                                <div> Xiao Dong, Runhui Huang, Xiaoyong Wei, Zequn Jie, Jianxing Yu, Jian Yin, Xiaodan Liang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00813"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Wuerstchen: Efficient Pretraining of Text-to-Image Models  </div>
                                <div> Pablo Pernias, Dominic Rampas, Marc Aubreville </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00637"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Inserting Anybody in Diffusion Models via Celeb Basis  </div>
                                <div> Ge Yuan, Xiaodong Cun, Yong Zhang, Maomao Li, Chenyang Qi, Xintao Wang, Ying Shan, Huicheng Zheng </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00926"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://celeb-basis.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Make-Your-Video: Customized Video Generation Using Textual and Structural Guidance  </div>
                                <div> Jinbo Xing, Menghan Xia, Yuxin Liu, Yuechen Zhang, Yong Zhang, Yingqing He, Hanyuan Liu, Haoxin Chen, Xiaodong Cun, Xintao Wang, Ying Shan, Tien-Tsin Wong </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00943"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://doubiiu.github.io/projects/Make-Your-Video/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Cocktail: Mixing Multi-Modality Controls for Text-Conditional Image Generation  </div>
                                <div> Minghui Hu, Jianbin Zheng, Daqing Liu, Chuanxia Zheng, Chaoyue Wang, Dacheng Tao, Tat-Jen Cham </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00964"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://mhh0318.github.io/cocktail/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/mhh0318/Cocktail"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> The Hidden Language of Diffusion Models  </div>
                                <div> Hila Chefer, Oran Lang, Mor Geva, Volodymyr Polosukhin, Assaf Shocher, Michal Irani, Inbar Mosseri, Lior Wolf </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00966"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://hila-chefer.github.io/Conceptor/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ViCo: Detail-Preserving Visual Condition for Personalized Text-to-Image Generation  </div>
                                <div> Shaozhe Hao, Kai Han, Shihao Zhao, Kwan-Yee K. Wong </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00971"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/haoosz/ViCo"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Intelligent Grimm -- Open-ended Visual Storytelling via Latent Diffusion Models  </div>
                                <div> Chang Liu, Haoning Wu, Yujie Zhong, Xiaoyun Zhang, Weidi Xie </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00973"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://haoningwu3639.github.io/StoryGen_Webpage/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Intriguing Properties of Text-guided Diffusion Models  </div>
                                <div> Qihao Liu, Adam Kortylewski, Yutong Bai, Song Bai, Alan Yuille </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00974"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> StyleDrop: Text-to-Image Generation in Any Style  </div>
                                <div> Kihyuk Sohn, Nataniel Ruiz, Kimin Lee, Daniel Castro Chin, Irina Blok, Huiwen Chang, Jarred Barber, Lu Jiang, Glenn Entis, Yuanzhen Li, Yuan Hao, Irfan Essa, Michael Rubinstein, Dilip Krishnan </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00983"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://styledrop.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion Self-Guidance for Controllable Image Generation  </div>
                                <div> Dave Epstein, Allan Jabri, Ben Poole, Alexei A. Efros, Aleksander Holynski </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00986"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://dave.ml/selfguidance/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> StableRep: Synthetic Images from Text-to-Image Models Make Strong Visual Representation Learners  </div>
                                <div> Yonglong Tian, Lijie Fan, Phillip Isola, Huiwen Chang, Dilip Krishnan </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00984"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Boosting Text-to-Image Diffusion Models with Fine-Grained Semantic Rewards  </div>
                                <div> Guian Fang, Zutao Jiang, Jianhua Han, Guansong Lu, Hang Xu, Xiaodan Liang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.19599"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/Enderfga/FineRewards"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-31</div>
                            </div>
                            <div class="paper-date">2023-05-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Control4D: Dynamic Portrait Editing by Learning 4D GAN from 2D Diffusion-based Editor  </div>
                                <div> Ruizhi Shao, Jingxiang Sun, Cheng Peng, Zerong Zheng, Boyao Zhou, Hongwen Zhang, Yebin Liu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.20082"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://control4darxiv.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-31</div>
                            </div>
                            <div class="paper-date">2023-05-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Understanding and Mitigating Copying in Diffusion Models  </div>
                                <div> Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, Tom Goldstein </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2305.20086"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/somepago/DCR"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-31</div>
                            </div>
                            <div class="paper-date">2023-05-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion Brush: A Latent Diffusion Model-based Editing Tool for AI-generated Images  </div>
                                <div> Peyman Gholami, Robert Xiao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.00219"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-31</div>
                            </div>
                            <div class="paper-date">2023-05-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> LayerDiffusion: Layered Controlled Image Editing with Diffusion Models  </div>
                                <div> Pengzhi Li, QInxuan Huang, Yikang Ding, Zhiheng Li </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.18676"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-30</div>
                            </div>
                            <div class="paper-date">2023-05-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> HiFA: High-fidelity Text-to-3D with Advanced Diffusion Guidance  </div>
                                <div> Junzhe Zhu, Peiye Zhuang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.18766"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-30</div>
                            </div>
                            <div class="paper-date">2023-05-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> StyleAvatar3D: Leveraging Image-Text Diffusion Models for High-Fidelity 3D Avatar Generation  </div>
                                <div> Chi Zhang, Yiwen Chen, Yijun Fu, Zhenglin Zhou, Gang YU, Billzb Wang, Bin Fu, Tao Chen, Guosheng Lin, Chunhua Shen </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.19012"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-30</div>
                            </div>
                            <div class="paper-date">2023-05-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Nested Diffusion Processes for Anytime Image Generation  </div>
                                <div> Noam Elata, Bahjat Kawar, Tomer Michaeli, Michael Elad </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.19066"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-30</div>
                            </div>
                            <div class="paper-date">2023-05-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Video ControlNet: Towards Temporally Consistent Synthetic-to-Real Video Translation Using Conditional Image Diffusion Models  </div>
                                <div> Ernie Chu, Shuo-Yen Lin, Jun-Cheng Chen </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.19193"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-30</div>
                            </div>
                            <div class="paper-date">2023-05-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> PanoGen: Text-Conditioned Panoramic Environment Generation for Vision-and-Language Navigation  </div>
                                <div> Jialu Li, Mohit Bansal </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.19195"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://pano-gen.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/jialuli-luka/PanoGen"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-30</div>
                            </div>
                            <div class="paper-date">2023-05-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Perturbation-Assisted Sample Synthesis: A Novel Approach for Uncertainty Quantification  </div>
                                <div> Yifei Liu, Rex Shen, Xiaotong Shen </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.18671"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-30</div>
                            </div>
                            <div class="paper-date">2023-05-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Conditional Score Guidance for Text-Driven Image-to-Image Translation  </div>
                                <div> Hyunsoo Lee, Minsoo Kang, Bohyung Han </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.18007"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-29</div>
                            </div>
                            <div class="paper-date">2023-05-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> InstructEdit: Improving Automatic Masks for Diffusion-based Image Editing With User Instructions  </div>
                                <div> Qian Wang, Biao Zhang, Michael Birsak, Peter Wonka </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.18047"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-29</div>
                            </div>
                            <div class="paper-date">2023-05-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-Only Image Captioning with Multi-Context Data Generation  </div>
                                <div> Feipeng Ma, Yizhou Zhou, Fengyun Rao, Yueyi Zhang, Xiaoyan Sun </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.18072"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-29</div>
                            </div>
                            <div class="paper-date">2023-05-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Gen-L-Video: Multi-Text to Long Video Generation via Temporal Co-Denoising  </div>
                                <div> Fu-Yun Wang, Wenshuo Chen, Guanglu Song, Han-Jia Ye, Yu Liu, Hongsheng Li </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.18264"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/G-U-N/Gen-L-Video"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-29</div>
                            </div>
                            <div class="paper-date">2023-05-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Mix-of-Show: Decentralized Low-Rank Adaptation for Multi-Concept Customization of Diffusion Models  </div>
                                <div> Yuchao Gu, Xintao Wang, Jay Zhangjie Wu, Yujun Shi, Yunpeng Chen, Zihan Fan, Wuyou Xiao, Rui Zhao, Shuning Chang, Weijia Wu, Yixiao Ge, Ying Shan, Mike Zheng Shou </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.18292"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://showlab.github.io/Mix-of-Show/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-29</div>
                            </div>
                            <div class="paper-date">2023-05-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths  </div>
                                <div> Zeyue Xue, Guanglu Song, Qiushan Guo, Boxiao Liu, Zhuofan Zong, Yu Liu, Ping Luo </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.18295"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-29</div>
                            </div>
                            <div class="paper-date">2023-05-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Controllable Text-to-Image Generation with GPT-4  </div>
                                <div> Tianjun Zhang, Yi Zhang, Vibhav Vineet, Neel Joshi, Xin Wang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.18583"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-29</div>
                            </div>
                            <div class="paper-date">2023-05-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Cognitively Inspired Cross-Modal Data Generation Using Diffusion Models  </div>
                                <div> Zizhao Hu, Mohammad Rostami </div>
                                <div>
                                        NeurIPS 2023.

                                        <a href="https://arxiv.org/abs/2305.18433"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-28</div>
                            </div>
                            <div class="paper-date">2023-05-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> FISEdit: Accelerating Text-to-image Editing via Cache-enabled Sparse Diffusion Inference  </div>
                                <div> Zihao Yu, Haoyang Li, Fangcheng Fu, Xupeng Miao, Bin Cui </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.17423"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-27</div>
                            </div>
                            <div class="paper-date">2023-05-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Towards Consistent Video Editing with Text-to-Image Diffusion Models  </div>
                                <div> Zicheng Zhang, Bonan Li, Xuecheng Nie, Congying Han, Tiande Guo, Luoqi Liu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.17431"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-27</div>
                            </div>
                            <div class="paper-date">2023-05-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-to-image Editing by Image Information Removal  </div>
                                <div> Zhongping Zhang, Jian Zheng, Jacob Zhiyuan Fang, Bryan A. Plummer </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.17489"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-27</div>
                            </div>
                            <div class="paper-date">2023-05-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Negative-prompt Inversion: Fast Image Inversion for Editing with Text-guided Diffusion Models  </div>
                                <div> Daiki Miyake, Akihiro Iohara, Yu Saito, Toshiyuki Tanaka </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.16807"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-26</div>
                            </div>
                            <div class="paper-date">2023-05-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Improved Visual Story Generation with Adaptive Context Modeling  </div>
                                <div> Zhangyin Feng, Yuchen Ren, Xinmiao Yu, Xiaocheng Feng, Duyu Tang, Shuming Shi, Bing Qin </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.16811"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-26</div>
                            </div>
                            <div class="paper-date">2023-05-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ControlVideo: Adding Conditional Control for One Shot Text-to-Video Editing  </div>
                                <div> Min Zhao, Rongzhen Wang, Fan Bao, Chongxuan Li, Jun Zhu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.17098"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://ml.cs.tsinghua.edu.cn/controlvideo/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-26</div>
                            </div>
                            <div class="paper-date">2023-05-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Custom-Edit: Text-Guided Image Editing with Customized Diffusion Models  </div>
                                <div> Jooyoung Choi, Yunjey Choi, Yunji Kim, Junho Kim, Sungroh Yoon </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.15779"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> On Architectural Compression of Text-to-Image Diffusion Models  </div>
                                <div> Bo-Kyeong Kim, Hyoung-Kyu Song, Thibault Castells, Shinkook Choi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.15798"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation  </div>
                                <div> Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan Li, Hang Su, Jun Zhu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.16213"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://ml.cs.tsinghua.edu.cn/prolificdreamer/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ProSpect: Expanded Conditioning for the Personalization of Attribute-aware Image Generation  </div>
                                <div> Yuxin Zhang, Weiming Dong, Fan Tang, Nisha Huang, Haibin Huang, Chongyang Ma, Tong-Yee Lee, Oliver Deussen, Changsheng Xu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.16225"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Prompt-Free Diffusion: Taking "Text" out of Text-to-Image Diffusion Models  </div>
                                <div> Xingqian Xu, Jiayi Guo, Zhangyang Wang, Gao Huang, Irfan Essa, Humphrey Shi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.16223"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/SHI-Labs/Prompt-Free-Diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diversify Your Vision Datasets with Automatic Diffusion-Based Augmentation  </div>
                                <div> Lisa Dunlap, Alyssa Umino, Han Zhang, Jiezhi Yang, Joseph E. Gonzalez, Trevor Darrell </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.16289"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/lisadunlap/ALIA"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Break-A-Scene: Extracting Multiple Concepts from a Single Image  </div>
                                <div> Omri Avrahami, Kfir Aberman, Ohad Fried, Daniel Cohen-Or, Dani Lischinski </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.16311"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://omriavrahami.com/break-a-scene/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Parallel Sampling of Diffusion Models  </div>
                                <div> Andy Shih, Suneel Belkhale, Stefano Ermon, Dorsa Sadigh, Nima Anari </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.16317"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/AndyShih12/paradigms"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models  </div>
                                <div> Shihao Zhao, Dongdong Chen, Yen-Chun Chen, Jianmin Bao, Shaozhe Hao, Lu Yuan, Kwan-Yee K. Wong </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.16322"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://shihaozhaozsh.github.io/unicontrolnet/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/ShihaoZhaoZSH/Uni-ControlNet"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DPOK: Reinforcement Learning for Fine-tuning Text-to-Image Diffusion Models  </div>
                                <div> Ying Fan, Olivia Watkins, Yuqing Du, Hao Liu, Moonkyung Ryu, Craig Boutilier, Pieter Abbeel, Mohammad Ghavamzadeh, Kangwook Lee, Kimin Lee </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.16381"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Are Diffusion Models Vision-And-Language Reasoners?  </div>
                                <div> Benno Krojer, Elinor Poole-Dayan, Vikram Voleti, Christopher Pal, Siva Reddy </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.16397"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/McGill-NLP/diffusion-itm"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> BLIP-Diffusion: Pre-trained Subject Representation for Controllable Text-to-Image Generation and Editing  </div>
                                <div> Dongxu Li, Junnan Li, Steven C. H. Hoi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.14720"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-24</div>
                            </div>
                            <div class="paper-date">2023-05-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> I Spy a Metaphor: Large Language Models and Diffusion Models Co-Create Visual Metaphors  </div>
                                <div> Tuhin Chakrabarty, Arkadiy Saakyan, Olivia Winn, Artemis Panagopoulou, Yue Yang, Marianna Apidianaki, Smaranda Muresan </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.14724"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-24</div>
                            </div>
                            <div class="paper-date">2023-05-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion Models  </div>
                                <div> Sungnyun Kim, Junsoo Lee, Kibeom Hong, Daesik Kim, Namhyuk Ahn </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.15194"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/sungnyun/diffblender"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-24</div>
                            </div>
                            <div class="paper-date">2023-05-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ChatFace: Chat-Guided Real Face Editing via Diffusion Latent Space Manipulation  </div>
                                <div> Dongxu Yue, Qin Guo, Munan Ning, Jiaxi Cui, Yuesheng Zhu, Li Yuan </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.14742"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-24</div>
                            </div>
                            <div class="paper-date">2023-05-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> MultiFusion: Fusing Pre-Trained Models for Multi-Lingual, Multi-Modal Image Generation  </div>
                                <div> Marco Bellagente, Manuel Brack, Hannah Teufel, Felix Friedrich, Björn Deiseroth, Constantin Eichenberg, Andrew Dai, Robert Baldock, Souradeep Nanda, Koen Oostermeijer, Andres Felipe Cruz-Salinas, Patrick Schramowski, Kristian Kersting, Samuel Weinbach </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.15296"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-24</div>
                            </div>
                            <div class="paper-date">2023-05-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models  </div>
                                <div> Long Lian, Boyi Li, Adam Yala, Trevor Darrell </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13655"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-23</div>
                            </div>
                            <div class="paper-date">2023-05-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Understanding Text-driven Motion Synthesis with Keyframe Collaboration via Diffusion Models  </div>
                                <div> Dong Wei, Xiaoning Sun, Huaijiang Sun, Bin Li, Shengxiang Hu, Weiqing Li, Jianfeng Lu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13773"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-23</div>
                            </div>
                            <div class="paper-date">2023-05-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Control-A-Video: Controllable Text-to-Video Generation with Diffusion Models  </div>
                                <div> Weifeng Chen, Jie Wu, Pan Xie, Hefeng Wu, Jiashi Li, Xin Xia, Xuefeng Xiao, Liang Lin </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13840"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-23</div>
                            </div>
                            <div class="paper-date">2023-05-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes From Text-To-Image Models  </div>
                                <div> Yiting Qu, Xinyue Shen, Xinlei He, Michael Backes, Savvas Zannettou, Yang Zhang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13873"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-23</div>
                            </div>
                            <div class="paper-date">2023-05-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Compositional Text-to-Image Synthesis with Attention Map Control of Diffusion Models  </div>
                                <div> Ruichen Wang, Zekang Chen, Chen Chen, Jian Ma, Haonan Lu, Xiaodong Lin </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13921"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-23</div>
                            </div>
                            <div class="paper-date">2023-05-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> The CLIP Model is Secretly an Image-to-Prompt Converter  </div>
                                <div> Yuxuan Ding, Chunna Tian, Haoxuan Ding, Lingqiao Liu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.12716"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> AudioToken: Adaptation of Text-Conditioned Diffusion Models for Audio-to-Image Generation  </div>
                                <div> Guy Yariv, Itai Gat, Lior Wolf, Yossi Adi, Idan Schwartz </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13050"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ControlVideo: Training-free Controllable Text-to-Video Generation  </div>
                                <div> Yabo Zhang, Yuxiang Wei, Dongsheng Jiang, Xiaopeng Zhang, Wangmeng Zuo, Qi Tian </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13077"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/YBYBZhang/ControlVideo"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> If at First You Don't Succeed, Try, Try Again: Faithful Diffusion-based Text-to-Image Generation by Selection  </div>
                                <div> Shyamgopal Karthik, Karsten Roth, Massimiliano Mancini, Zeynep Akata </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13308"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://rl-diffusion.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Training Diffusion Models with Reinforcement Learning  </div>
                                <div> Kevin Black, Michael Janner, Yilun Du, Ilya Kostrikov, Sergey Levine </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13301"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> FACTIFY3M: A Benchmark for Multimodal Fact Verification with Explainability through 5W Question-Answering  </div>
                                <div> Megha Chakraborty, Khusbu Pahwa, Anku Rani, Adarsh Mahor, Aditya Pakala, Arghya Sarkar, Harshit Dave, Ishan Paul, Janvita Reddy, Preethi Gurumurthy, Ritvik G, Samahriti Mukherjee, Shreyas Chatterjee, Kinjal Sensharma, Dwip Dalal, Suryavardan S, Shreyash Mishra, Parth Patwa, Aman Chadha, Amit Sheth, Amitava Das </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.05523"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On  </div>
                                <div> Davide Morelli, Alberto Baldrati, Giuseppe Cartella, Marcella Cornia, Marco Bertini, Rita Cucchiara </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13501"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Adversarial Nibbler: A Data-Centric Challenge for Improving the Safety of Text-to-Image Models  </div>
                                <div> Alicia Parrish, Hannah Rose Kirk, Jessica Quaye, Charvi Rastogi, Max Bartolo, Oana Inel, Juan Ciro, Rafael Mosquera, Addison Howard, Will Cukierski, D. Sculley, Vijay Janapa Reddi, Lora Aroyo </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.14384"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> InstructVid2Vid: Controllable Video Editing with Natural Language Instructions  </div>
                                <div> Bosheng Qin, Juncheng Li, Siliang Tang, Tat-Seng Chua, Yueting Zhuang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.12328"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-21</div>
                            </div>
                            <div class="paper-date">2023-05-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SneakyPrompt: Evaluating Robustness of Text-to-image Generative Models' Safety Filters  </div>
                                <div> Yuchen Yang, Bo Hui, Haolin Yuan, Neil Gong, Yinzhi Cao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.12082"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-20</div>
                            </div>
                            <div class="paper-date">2023-05-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Efficient Cross-Lingual Transfer for Chinese Stable Diffusion with Images as Pivots  </div>
                                <div> Jinyi Hu, Xu Han, Xiaoyuan Yi, Yutong Chen, Wenhao Li, Zhiyuan Liu, Maosong Sun </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.11540"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-19</div>
                            </div>
                            <div class="paper-date">2023-05-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Brain Captioning: Decoding human brain activity into images and text  </div>
                                <div> Matteo Ferrante, Furkan Ozcelik, Tommaso Boccato, Rufin VanRullen, Nicola Toschi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.11560"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-19</div>
                            </div>
                            <div class="paper-date">2023-05-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text2NeRF: Text-Driven 3D Scene Generation with Neural Radiance Fields  </div>
                                <div> Jingbo Zhang, Xiaoyu Li, Ziyu Wan, Can Wang, Jing Liao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.11588"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-19</div>
                            </div>
                            <div class="paper-date">2023-05-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Any-to-Any Generation via Composable Diffusion  </div>
                                <div> Zineng Tang, Ziyi Yang, Chenguang Zhu, Michael Zeng, Mohit Bansal </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.11846"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://codi-gen.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/microsoft/i-Code/tree/main/i-Code-V3"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-19</div>
                            </div>
                            <div class="paper-date">2023-05-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Late-Constraint Diffusion Guidance for Controllable Image Synthesis  </div>
                                <div> Chang Liu, Dong Liu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.11520"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://alonzoleeeooo.github.io/LCDG/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/AlonzoLeeeooo/LCDG"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-19</div>
                            </div>
                            <div class="paper-date">2023-05-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Inspecting the Geographical Representativeness of Images from Text-to-Image Models  </div>
                                <div> Abhipsa Basu, R. Venkatesh Babu, Danish Pruthi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.11080"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-18</div>
                            </div>
                            <div class="paper-date">2023-05-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> X-IQE: eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models  </div>
                                <div> Yixiong Chen </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.10843"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/Schuture/Benchmarking-Awesome-Diffusion-Models"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-18</div>
                            </div>
                            <div class="paper-date">2023-05-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> LDM3D: Latent Diffusion Model for 3D  </div>
                                <div> Gabriela Ben Melech Stan, Diana Wofk, Scottie Fox, Alex Redden, Will Saxton, Jean Yu, Estelle Aflalo, Shao-Yen Tseng, Fabio Nonato, Matthias Muller, Vasudev Lal </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.10853"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-18</div>
                            </div>
                            <div class="paper-date">2023-05-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> VideoFactory: Swap Attention in Spatiotemporal Diffusions for Text-to-Video Generation  </div>
                                <div> Wenjing Wang, Huan Yang, Zixi Tuo, Huiguo He, Junchen Zhu, Jianlong Fu, Jiaying Liu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.10874"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-18</div>
                            </div>
                            <div class="paper-date">2023-05-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> TextDiffuser: Diffusion Models as Text Painters  </div>
                                <div> Jingye Chen, Yupan Huang, Tengchao Lv, Lei Cui, Qifeng Chen, Furu Wei </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.10855"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-18</div>
                            </div>
                            <div class="paper-date">2023-05-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> AIwriting: Relations Between Image Generation and Digital Writing  </div>
                                <div> Scott Rettberg, Talan Memmott, Jill Walker Rettberg, Jason Nelson, Patrick Lichty </div>
                                <div>
                                        ISEA 2023.

                                        <a href="https://arxiv.org/abs/2305.10834"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-18</div>
                            </div>
                            <div class="paper-date">2023-05-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Zero-Day Backdoor Attack against Text-to-Image Diffusion Models via Personalization  </div>
                                <div> Yihao Huang, Qing Guo, Felix Juefei-Xu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.10701"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-18</div>
                            </div>
                            <div class="paper-date">2023-05-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Discriminative Diffusion Models as Few-shot Vision and Language Learners  </div>
                                <div> Xuehai He, Weixi Feng, Tsu-Jui Fu, Varun Jampani, Arjun Akula, Pradyumna Narayana, Sugato Basu, William Yang Wang, Xin Eric Wang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.10722"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-18</div>
                            </div>
                            <div class="paper-date">2023-05-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Preserve Your Own Correlation: A Noise Prior for Video Diffusion Models  </div>
                                <div> Songwei Ge, Seungjun Nah, Guilin Liu, Tyler Poon, Andrew Tao, Bryan Catanzaro, David Jacobs, Jia-Bin Huang, Ming-Yu Liu, Yogesh Balaji </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.10474"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://research.nvidia.com/labs/dir/pyoco/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-17</div>
                            </div>
                            <div class="paper-date">2023-05-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Make-An-Animation: Large-Scale Text-conditional 3D Human Motion Generation  </div>
                                <div> Samaneh Azadi, Akbar Shah, Thomas Hayes, Devi Parikh, Sonal Gupta </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.09662"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://azadis.github.io/make-an-animation/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-16</div>
                            </div>
                            <div class="paper-date">2023-05-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Generating coherent comic with rich story using ChatGPT and Stable Diffusion  </div>
                                <div> Ze Jin, Zorina Song </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.11067"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-16</div>
                            </div>
                            <div class="paper-date">2023-05-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> AMD: Autoregressive Motion Diffusion  </div>
                                <div> Bo Han, Hao Peng, Minjing Dong, Chang Xu, Yi Ren, Yixuan Shen, Yuheng Li </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.09381"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-16</div>
                            </div>
                            <div class="paper-date">2023-05-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Interactive Fashion Content Generation Using LLMs and Latent Diffusion Models  </div>
                                <div> Krishna Sri Ipsit Mantri, Nevasini Sasikumar </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.05182"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-15</div>
                            </div>
                            <div class="paper-date">2023-05-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Common Diffusion Noise Schedules and Sample Steps are Flawed  </div>
                                <div> Shanchuan Lin, Bingchen Liu, Jiashi Li, Xiao Yang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.08891"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-15</div>
                            </div>
                            <div class="paper-date">2023-05-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Make-A-Protagonist: Generic Video Editing with An Ensemble of Experts  </div>
                                <div> Yuyang Zhao, Enze Xie, Lanqing Hong, Zhenguo Li, Gim Hee Lee </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.08850"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://make-a-protagonist.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/Make-A-Protagonist/Make-A-Protagonist"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-15</div>
                            </div>
                            <div class="paper-date">2023-05-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Null-text Guidance in Diffusion Models is Secretly a Cartoon-style Creator  </div>
                                <div> Jing Zhao, Heliang Zheng, Chaoyue Wang, Long Lan, Wanrong Huang, Wenjing Yang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.06710"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://nulltextforcartoon.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/NullTextforCartoon/NullTextforCartoon"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-11</div>
                            </div>
                            <div class="paper-date">2023-05-11</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> iEdit: Localised Text-guided Image Editing with Weak Supervision  </div>
                                <div> Rumeysa Bodur, Erhan Gundogdu, Binod Bhattarai, Tae-Kyun Kim, Michael Donoser, Loris Bazzani </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.05947"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-10</div>
                            </div>
                            <div class="paper-date">2023-05-10</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Style-A-Video: Agile Diffusion for Arbitrary Text-based Video Style Transfer  </div>
                                <div> Nisha Huang, Yuxin Zhang, Weiming Dong </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.05464"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-09</div>
                            </div>
                            <div class="paper-date">2023-05-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models  </div>
                                <div> Shanshan Zhong, Zhongzhan Huang, Wushao Wen, Jinghui Qin, Liang Lin </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.05189"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/Qrange-group/SUR-adapter"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-09</div>
                            </div>
                            <div class="paper-date">2023-05-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Prompt Tuning Inversion for Text-Driven Image Editing Using Diffusion Models  </div>
                                <div> Wenkai Dong, Song Xue, Xiaoyue Duan, Shumin Han </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.04441"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-08</div>
                            </div>
                            <div class="paper-date">2023-05-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ReGeneration Learning of Diffusion Models with Rich Prompts for Zero-Shot Image Translation  </div>
                                <div> Yupei Lin, Sen Zhang, Xiaojun Yang, Xiao Wang, Yukai Shi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.04651"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://yupeilin2388.github.io/publication/ReDiffuser"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-08</div>
                            </div>
                            <div class="paper-date">2023-05-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> IIITD-20K: Dense captioning for Text-Image ReID  </div>
                                <div> A V Subramanyam, Niranjan Sundararajan, Vibhu Dubey, Brejesh Lall </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.04497"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-08</div>
                            </div>
                            <div class="paper-date">2023-05-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffuseStyleGesture: Stylized Audio-Driven Co-Speech Gesture Generation with Diffusion Models  </div>
                                <div> Sicheng Yang, Zhiyong Wu, Minglei Li, Zhensong Zhang, Lei Hao, Weihong Bao, Ming Cheng, Long Xiao </div>
                                <div>
                                        IJCAI 2023.

                                        <a href="https://arxiv.org/abs/2305.04919"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/YoungSeng/DiffuseStyleGesture"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-08</div>
                            </div>
                            <div class="paper-date">2023-05-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-to-Image Diffusion Models can be Easily Backdoored through Multimodal Data Poisoning  </div>
                                <div> Shengfang Zhai, Yinpeng Dong, Qingni Shen, Shi Pu, Yuejian Fang, Hang Su </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.04175"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-07</div>
                            </div>
                            <div class="paper-date">2023-05-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> AADiff: Audio-Aligned Video Synthesis with Text-to-Image Diffusion  </div>
                                <div> Seungwoo Lee, Chaerin Kong, Donghyeon Jeon, Nojun Kwak </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.04001"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-06</div>
                            </div>
                            <div class="paper-date">2023-05-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Guided Image Synthesis via Initial Image Editing in Diffusion Model  </div>
                                <div> Jiafeng Mao, Xueting Wang, Kiyoharu Aizawa </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.03382"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-05</div>
                            </div>
                            <div class="paper-date">2023-05-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation  </div>
                                <div> Hong Chen, Yipeng Zhang, Xin Wang, Xuguang Duan, Yuwei Zhou, Wenwu Zhu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.03374"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://disenbooth.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-05</div>
                            </div>
                            <div class="paper-date">2023-05-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Data Curation for Image Captioning with Text-to-Image Generative Models  </div>
                                <div> Wenyan Li, Jonas F. Lotz, Chen Qiu, Desmond Elliott </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.03610"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-05</div>
                            </div>
                            <div class="paper-date">2023-05-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Multimodal-driven Talking Face Generation, Face Swapping, Diffusion Model  </div>
                                <div> Chao Xu, Shaoting Zhu, Junwei Zhu, Tianxin Huang, Jiangning Zhang, Ying Tai, Yong Liu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.02594"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-04</div>
                            </div>
                            <div class="paper-date">2023-05-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion  </div>
                                <div> Seongmin Lee, Benjamin Hoover, Hendrik Strobelt, Zijie J. Wang, ShengYun Peng, Austin Wright, Kevin Li, Haekyu Park, Haoyang Yang, Duen Horng Chau </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.03509"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://poloclub.github.io/diffusion-explainer/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-04</div>
                            </div>
                            <div class="paper-date">2023-05-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Multimodal Data Augmentation for Image Captioning using Diffusion Models  </div>
                                <div> Changrong Xiao, Sean Xin Xu, Kunpeng Zhang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.01855"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-03</div>
                            </div>
                            <div class="paper-date">2023-05-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> In-Context Learning Unlocked for Diffusion Models  </div>
                                <div> Zhendong Wang, Yifan Jiang, Yadong Lu, Yelong Shen, Pengcheng He, Weizhu Chen, Zhangyang Wang, Mingyuan Zhou </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.01115"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://zhendong-wang.github.io/prompt-diffusion.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/Zhendong-Wang/Prompt-Diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-01</div>
                            </div>
                            <div class="paper-date">2023-05-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SceneGenie: Scene Graph Guided Diffusion Models for Image Synthesis  </div>
                                <div> Azade Farshad, Yousef Yeganeh, Yu Chi, Chengzhi Shen, Björn Ommer, Nassir Navab </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.14573"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-28</div>
                            </div>
                            <div class="paper-date">2023-04-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Edit Everything: A Text-Guided Generative System for Images Editing  </div>
                                <div> Defeng Xie, Ruichen Wang, Jian Ma, Chen Chen, Haonan Lu, Dong Yang, Fobo Shi, Xiaodong Lin </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.14006"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/DefengXie/Edit_Everything"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-27</div>
                            </div>
                            <div class="paper-date">2023-04-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> It is all about where you start: Text-to-image generation with seed selection  </div>
                                <div> Dvir Samuel, Rami Ben-Ari, Simon Raviv, Nir Darshan, Gal Chechik </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.14530"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-27</div>
                            </div>
                            <div class="paper-date">2023-04-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Training-Free Location-Aware Text-to-Image Synthesis  </div>
                                <div> Jiafeng Mao, Xueting Wang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.13427"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-26</div>
                            </div>
                            <div class="paper-date">2023-04-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> TextMesh: Generation of Realistic 3D Meshes From Text Prompts  </div>
                                <div> Christina Tsalicoglou, Fabian Manhardt, Alessio Tonioni, Michael Niemeyer, Federico Tombari </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.12439"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-24</div>
                            </div>
                            <div class="paper-date">2023-04-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Using Text-to-Image Generation for Architectural Design Ideation  </div>
                                <div> Ville Paananen, Jonas Oppenlaender, Aku Visuri </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.10182"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-20</div>
                            </div>
                            <div class="paper-date">2023-04-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Anything-3D: Towards Single-view Anything Reconstruction in the Wild  </div>
                                <div> Qiuhong Shen, Xingyi Yang, Xinchao Wang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.10261"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/Anything-of-anything/Anything-3D"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-19</div>
                            </div>
                            <div class="paper-date">2023-04-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models  </div>
                                <div> Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung Wook Kim, Sanja Fidler, Karsten Kreis </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2304.08818"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://research.nvidia.com/labs/toronto-ai/VideoLDM/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-18</div>
                            </div>
                            <div class="paper-date">2023-04-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> TTIDA: Controllable Generative Data Augmentation via Text-to-Text and Text-to-Image Models  </div>
                                <div> Yuwei Yin, Jean Kaddour, Xiang Zhang, Yixin Nie, Zhenguang Liu, Lingpeng Kong, Qi Liu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.08821"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-18</div>
                            </div>
                            <div class="paper-date">2023-04-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> UPGPT: Universal Diffusion Model for Person Image Generation, Editing and Pose Transfer  </div>
                                <div> Soon Yau Cheong, Armin Mustafa, Andrew Gilbert </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.08870"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/soon-yau/upgpt"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-18</div>
                            </div>
                            <div class="paper-date">2023-04-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing  </div>
                                <div> Mingdeng Cao, Xintao Wang, Zhongang Qi, Ying Shan, Xiaohu Qie, Yinqiang Zheng </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.08465"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/TencentARC/MasaCtrl"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-17</div>
                            </div>
                            <div class="paper-date">2023-04-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Latent-Shift: Latent Diffusion with Temporal Shift for Efficient Text-to-Video Generation  </div>
                                <div> Jie An, Songyang Zhang, Harry Yang, Sonal Gupta, Jia-Bin Huang, Jiebo Luo, Xi Yin </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.08477"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://latent-shift.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-17</div>
                            </div>
                            <div class="paper-date">2023-04-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text2Performer: Text-Driven Human Video Generation  </div>
                                <div> Yuming Jiang, Shuai Yang, Tong Liang Koh, Wayne Wu, Chen Change Loy, Ziwei Liu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.08483"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://yumingj.github.io/projects/Text2Performer.html"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-17</div>
                            </div>
                            <div class="paper-date">2023-04-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Delta Denoising Score  </div>
                                <div> Amir Hertz, Kfir Aberman, Daniel Cohen-Or </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.07090"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://delta-denoising-score.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-14</div>
                            </div>
                            <div class="paper-date">2023-04-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-Conditional Contextualized Avatars For Zero-Shot Personalization  </div>
                                <div> Samaneh Azadi, Thomas Hayes, Akbar Shah, Guan Pang, Devi Parikh, Sonal Gupta </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.07410"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-14</div>
                            </div>
                            <div class="paper-date">2023-04-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Soundini: Sound-Guided Diffusion for Natural Video Editing  </div>
                                <div> Seung Hyun Lee, Sieun Kim, Innfarn Yoo, Feng Yang, Donghyeon Cho, Youngseo Kim, Huiwen Chang, Jinkyu Kim, Sangpil Kim </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.06818"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://kuai-lab.github.io/soundini-gallery/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-13</div>
                            </div>
                            <div class="paper-date">2023-04-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Expressive Text-to-Image Generation with Rich Text  </div>
                                <div> Songwei Ge, Taesung Park, Jun-Yan Zhu, Jia-Bin Huang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.06720"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://rich-text-to-image.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/SongweiGe/rich-text-to-image"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-13</div>
                            </div>
                            <div class="paper-date">2023-04-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Continual Diffusion: Continual Customization of Text-to-Image Diffusion with C-LoRA  </div>
                                <div> James Seale Smith, Yen-Chang Hsu, Lingyu Zhang, Ting Hua, Zsolt Kira, Yilin Shen, Hongxia Jin </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.06027"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://jamessealesmith.github.io/continual-diffusion/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-12</div>
                            </div>
                            <div class="paper-date">2023-04-12</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> An Edit Friendly DDPM Noise Space: Inversion and Manipulations  </div>
                                <div> Inbar Huberman-Spiegelglas, Vladimir Kulikov, Tomer Michaeli </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.06140"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-12</div>
                            </div>
                            <div class="paper-date">2023-04-12</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Improving Diffusion Models for Scene Text Editing with Dual Encoders  </div>
                                <div> Jiabao Ji, Guanhua Zhang, Zhaowen Wang, Bairu Hou, Zhifei Zhang, Brian Price, Shiyu Chang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.05568"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/UCSB-NLP-Chang/DiffSTE"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-12</div>
                            </div>
                            <div class="paper-date">2023-04-12</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Re-imagine the Negative Prompt Algorithm: Transform 2D Diffusion into 3D, alleviate Janus problem and Beyond  </div>
                                <div> Mohammadreza Armandpour, Huangjie Zheng, Ali Sadeghian, Amir Sadeghian, Mingyuan Zhou </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.04968"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-11</div>
                            </div>
                            <div class="paper-date">2023-04-11</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image Models  </div>
                                <div> Eslam Mohamed Bakr, Pengzhan Sun, Xiaoqian Shen, Faizan Farooq Khan, Li Erran Li, Mohamed Elhoseiny </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.05390"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://eslambakr.github.io/hrsbench.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-11</div>
                            </div>
                            <div class="paper-date">2023-04-11</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Towards Real-time Text-driven Image Manipulation with Unconditional Diffusion Models  </div>
                                <div> Nikita Starodubcev, Dmitry Baranchuk, Valentin Khrulkov, Artem Babenko </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.04344"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-10</div>
                            </div>
                            <div class="paper-date">2023-04-10</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> HumanSD: A Native Skeleton-Guided Diffusion Model for Human Image Generation  </div>
                                <div> Xuan Ju, Ailing Zeng, Chenchen Zhao, Jianan Wang, Lei Zhang, Qiang Xu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.04269"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://idea-research.github.io/HumanSD/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-09</div>
                            </div>
                            <div class="paper-date">2023-04-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Harnessing the Spatial-Temporal Attention of Diffusion Models for High-Fidelity Text-to-Image Synthesis  </div>
                                <div> Qiucheng Wu, Yujian Liu, Handong Zhao, Trung Bui, Zhe Lin, Yang Zhang, Shiyu Chang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.03869"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/UCSB-NLP-Chang/Diffusion-SpaceTime-Attn"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-07</div>
                            </div>
                            <div class="paper-date">2023-04-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DITTO-NeRF: Diffusion-based Iterative Text To Omni-directional 3D Model  </div>
                                <div> Hoigi Seo, Hayeon Kim, Gwanghyun Kim, Se Young Chun </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.02827"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://janeyeon.github.io/ditto-nerf/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-06</div>
                            </div>
                            <div class="paper-date">2023-04-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Benchmarking Robustness to Text-Guided Corruptions  </div>
                                <div> Mohammadreza Mofayezi, Yasamin Medghalchi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.02963"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-06</div>
                            </div>
                            <div class="paper-date">2023-04-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Training-Free Layout Control with Cross-Attention Guidance  </div>
                                <div> Minghao Chen, Iro Laina, Andrea Vedaldi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.03373"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://silent-chen.github.io/layout-guidance/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/silent-chen/layout-guidance"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-06</div>
                            </div>
                            <div class="paper-date">2023-04-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Zero-shot Generative Model Adaptation via Image-specific Prompt Learning  </div>
                                <div> Jiayi Guo, Chaofei Wang, You Wu, Eric Zhang, Kai Wang, Xingqian Xu, Shiji Song, Humphrey Shi, Gao Huang </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2304.03119"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/Picsart-AI-Research/IPL-Zero-Shot-Generative-Model-Adaptation"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-06</div>
                            </div>
                            <div class="paper-date">2023-04-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> A Diffusion-based Method for Multi-turn Compositional Image Generation  </div>
                                <div> Chao Wang, Xiaoyu Yang, Jinmiao Huang, Kevin Ferreira </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.02192"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-05</div>
                            </div>
                            <div class="paper-date">2023-04-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Taming Encoder for Zero Fine-tuning Image Customization with Text-to-Image Diffusion Models  </div>
                                <div> Xuhui Jia, Yang Zhao, Kelvin C.K. Chan, Yandong Li, Han Zhang, Boqing Gong, Tingbo Hou, Huisheng Wang, Yu-Chuan Su </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.02642"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-05</div>
                            </div>
                            <div class="paper-date">2023-04-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-Conditioned Sampling Framework for Text-to-Image Generation with Masked Generative Models  </div>
                                <div> Jaewoong Lee, Sangwon Jang, Jaehyeong Jo, Jaehong Yoon, Yunji Kim, Jin-Hwa Kim, Jung-Woo Ha, Sung Ju Hwang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.01515"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-04</div>
                            </div>
                            <div class="paper-date">2023-04-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> PODIA-3D: Domain Adaptation of 3D Generative Model Across Large Domain Gap Using Pose-Preserved Text-to-Image Diffusion  </div>
                                <div> Gwanghyun Kim, Ji Ha Jang, Se Young Chun </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.01900"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://gwang-kim.github.io/podia_3d/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-04</div>
                            </div>
                            <div class="paper-date">2023-04-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing  </div>
                                <div> Alberto Baldrati, Davide Morelli, Giuseppe Cartella, Marcella Cornia, Marco Bertini, Rita Cucchiara </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.02051"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-04</div>
                            </div>
                            <div class="paper-date">2023-04-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> viz2viz: Prompt-driven stylized visualization generation using a diffusion model  </div>
                                <div> Jiaqi Wu, John Joon Young Chung, Eytan Adar </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.01919"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-04</div>
                            </div>
                            <div class="paper-date">2023-04-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DreamAvatar: Text-and-Shape Guided 3D Human Avatar Generation via Diffusion Models  </div>
                                <div> Yukang Cao, Yan-Pei Cao, Kai Han, Ying Shan, Kwan-Yee K. Wong </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.00916"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-03</div>
                            </div>
                            <div class="paper-date">2023-04-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model  </div>
                                <div> Mingyuan Zhang, Xinying Guo, Liang Pan, Zhongang Cai, Fangzhou Hong, Huirong Li, Lei Yang, Ziwei Liu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.01116"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://mingyuan-zhang.github.io/projects/ReMoDiffuse.html"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/mingyuan-zhang/ReMoDiffuse"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-03</div>
                            </div>
                            <div class="paper-date">2023-04-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DreamFace: Progressive Generation of Animatable 3D Faces under Text Guidance  </div>
                                <div> Longwen Zhang, Qiwei Qiu, Hongyang Lin, Qixuan Zhang, Cheng Shi, Wei Yang, Ye Shi, Sibei Yang, Lan Xu, Jingyi Yu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.03117"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://sites.google.com/view/dreamface"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-01</div>
                            </div>
                            <div class="paper-date">2023-04-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> GlyphDraw: Learning to Draw Chinese Characters in Image Synthesis Models Coherently  </div>
                                <div> Jian Ma, Mingjun Zhao, Chen Chen, Ruichen Wang, Di Niu, Haonan Lu, Xiaodong Lin </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.17870"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://1073521013.github.io/glyph-draw.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-31</div>
                            </div>
                            <div class="paper-date">2023-03-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> LayoutDiffusion: Controllable Diffusion Model for Layout-to-image Generation  </div>
                                <div> Guangcong Zheng, Xianpan Zhou, Xuewei Li, Zhongang Qi, Ying Shan, Xi Li </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2303.17189"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/ZGCTroy/LayoutDiffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-30</div>
                            </div>
                            <div class="paper-date">2023-03-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DAE-Talker: High Fidelity Speech-Driven Talking Face Generation with Diffusion Autoencoder  </div>
                                <div> Chenpng Du, Qi Chen, Tianyu He, Xu Tan, Xie Chen, Kai Yu, Sheng Zhao, Jiang Bian </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.17550"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-30</div>
                            </div>
                            <div class="paper-date">2023-03-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Discriminative Class Tokens for Text-to-Image Diffusion Models  </div>
                                <div> Idan Schwartz, Vésteinn Snæbjarnarson, Sagie Benaim, Hila Chefer, Ryan Cotterell, Lior Wolf, Serge Belongie </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.17155"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-30</div>
                            </div>
                            <div class="paper-date">2023-03-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Zero-Shot Video Editing Using Off-The-Shelf Image Diffusion Models  </div>
                                <div> Wen Wang, Kangyang Xie, Zide Liu, Hao Chen, Yue Cao, Xinlong Wang, Chunhua Shen </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.17599"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-30</div>
                            </div>
                            <div class="paper-date">2023-03-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffCollage: Parallel Generation of Large Content with Diffusion Models  </div>
                                <div> Qinsheng Zhang, Jiaming Song, Xun Huang, Yongxin Chen, Ming-Yu Liu </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2303.17076"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://research.nvidia.com/labs/dir/diffcollage/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-30</div>
                            </div>
                            <div class="paper-date">2023-03-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Forget-Me-Not: Learning to Forget in Text-to-Image Diffusion Models  </div>
                                <div> Eric Zhang, Kai Wang, Xingqian Xu, Zhangyang Wang, Humphrey Shi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.17591"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/SHI-Labs/Forget-Me-Not"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-30</div>
                            </div>
                            <div class="paper-date">2023-03-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Social Biases through the Text-to-Image Generation Lens  </div>
                                <div> Ranjita Naik, Besmira Nushi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.06034"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-30</div>
                            </div>
                            <div class="paper-date">2023-03-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models  </div>
                                <div> Vidit Goel, Elia Peruzzo, Yifan Jiang, Dejia Xu, Nicu Sebe, Trevor Darrell, Zhangyang Wang, Humphrey Shi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.17546"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/Picsart-AI-Research/PAIR-Diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-30</div>
                            </div>
                            <div class="paper-date">2023-03-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> AvatarCraft: Transforming Text into Neural Human Avatars with Parameterized Shape and Pose Control  </div>
                                <div> Ruixiang Jiang, Can Wang, Jingbo Zhang, Menglei Chai, Mingming He, Dongdong Chen, Jing Liao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.17606"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://avatar-craft.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/songrise/avatarcraft"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-30</div>
                            </div>
                            <div class="paper-date">2023-03-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> MDP: A Generalized Framework for Text-Guided Image Editing by Manipulating the Diffusion Path  </div>
                                <div> Qian Wang, Biao Zhang, Michael Birsak, Peter Wonka </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.16765"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/QianWangX/MDP-Diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-29</div>
                            </div>
                            <div class="paper-date">2023-03-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> 4D Facial Expression Diffusion Model  </div>
                                <div> Kaifeng Zou, Sylvain Faisan, Boyang Yu, Sébastien Valette, Hyewon Seo </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.16611"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/ZOUKaifeng/4DFM"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-29</div>
                            </div>
                            <div class="paper-date">2023-03-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> StyleDiffusion: Prompt-Embedding Inversion for Text-Based Editing  </div>
                                <div> Senmao Li, Joost van de Weijer, Taihang Hu, Fahad Shahbaz Khan, Qibin Hou, Yaxing Wang, Jian Yang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.15649"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-28</div>
                            </div>
                            <div class="paper-date">2023-03-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Instruct 3D-to-3D: Text Instruction Guided 3D-to-3D conversion  </div>
                                <div> Hiromichi Kamata, Yuiko Sakuma, Akio Hayakawa, Masato Ishii, Takuya Narihira </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.15780"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://sony.github.io/Instruct3Dto3D-doc/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-28</div>
                            </div>
                            <div class="paper-date">2023-03-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Anti-DreamBooth: Protecting users from personalized text-to-image synthesis  </div>
                                <div> Thanh Van Le, Hao Phung, Thuan Hoang Nguyen, Quan Dao, Ngoc Tran, Anh Tran </div>
                                <div>
                                        SIGGRAPH 2023.

                                        <a href="https://arxiv.org/abs/2303.15433"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/VinAIResearch/Anti-DreamBooth"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-27</div>
                            </div>
                            <div class="paper-date">2023-03-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation  </div>
                                <div> Susung Hong, Donghoon Ahn, Seungryong Kim </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.15413"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-27</div>
                            </div>
                            <div class="paper-date">2023-03-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Seer: Language Instructed Video Prediction with Latent Diffusion Models  </div>
                                <div> Xianfan Gu, Chuan Wen, Jiaming Song, Yang Gao </div>
                                <div>
                                        CVPR Workshop 2023.

                                        <a href="https://arxiv.org/abs/2303.14897"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-27</div>
                            </div>
                            <div class="paper-date">2023-03-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> GestureDiffuCLIP: Gesture Diffusion Model with CLIP Latents  </div>
                                <div> Tenglong Ao, Zeyi Zhang, Libin Liu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.14613"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-26</div>
                            </div>
                            <div class="paper-date">2023-03-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Better Aligning Text-to-Image Models with Human Preference  </div>
                                <div> Xiaoshi Wu, Keqiang Sun, Feng Zhu, Rui Zhao, Hongsheng Li </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.14420"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://tgxs002.github.io/align_sd_web/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-25</div>
                            </div>
                            <div class="paper-date">2023-03-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation  </div>
                                <div> Rui Chen, Yongwei Chen, Ningxin Jiao, Kui Jia </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.13873"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-24</div>
                            </div>
                            <div class="paper-date">2023-03-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D Scene Layout  </div>
                                <div> Yiqi Lin, Haotian Bai, Sijia Li, Haonan Lu, Xiaodong Lin, Hui Xiong, Lin Wang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.13843"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://fantasia3d.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-24</div>
                            </div>
                            <div class="paper-date">2023-03-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffuScene: Scene Graph Denoising Diffusion Probabilistic Model for Generative Indoor Scene Synthesis  </div>
                                <div> Jiapeng Tang, Yinyu Nie, Lev Markhasin, Angela Dai, Justus Thies, Matthias Nießner </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.14207"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://tangjiapeng.github.io/projects/DiffuScene/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-24</div>
                            </div>
                            <div class="paper-date">2023-03-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ISS++: Image as Stepping Stone for Text-Guided 3D Shape Generation  </div>
                                <div> Zhengzhe Liu, Peng Dai, Ruihui Li, Xiaojuan Qi, Chi-Wing Fu </div>
                                <div>
                                        ICLR 2023.

                                        <a href="https://arxiv.org/abs/2303.15181"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-24</div>
                            </div>
                            <div class="paper-date">2023-03-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models  </div>
                                <div> Jing Zhao, Heliang Zheng, Chaoyue Wang, Long Lan, Wenjing Yang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.13126"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://magicfusion.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/MagicFusion/MagicFusion.github.io"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-23</div>
                            </div>
                            <div class="paper-date">2023-03-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators  </div>
                                <div> Levon Khachatryan, Andranik Movsisyan, Vahram Tadevosyan, Roberto Henschel, Zhangyang Wang, Shant Navasardyan, Humphrey Shi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.13439"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/Picsart-AI-Research/Text2Video-Zero"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-23</div>
                            </div>
                            <div class="paper-date">2023-03-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Ablating Concepts in Text-to-Image Diffusion Models  </div>
                                <div> Nupur Kumari, Bingliang Zhang, Sheng-Yu Wang, Eli Shechtman, Richard Zhang, Jun-Yan Zhu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.13516"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://www.cs.cmu.edu/~concept-ablation/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/nupurkmr9/concept-ablation"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-23</div>
                            </div>
                            <div class="paper-date">2023-03-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ReVersion: Diffusion-Based Relation Inversion from Images  </div>
                                <div> Ziqi Huang, Tianxing Wu, Yuming Jiang, Kelvin C.K. Chan, Ziwei Liu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.13495"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://ziqihuangg.github.io/projects/reversion.html"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/ziqihuangg/ReVersio"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-23</div>
                            </div>
                            <div class="paper-date">2023-03-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions  </div>
                                <div> Ayaan Haque, Matthew Tancik, Alexei A. Efros, Aleksander Holynski, Angjoo Kanazawa </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.12789"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://instruct-nerf2nerf.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-22</div>
                            </div>
                            <div class="paper-date">2023-03-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Pix2Video: Video Editing using Image Diffusion  </div>
                                <div> Duygu Ceylan, Chun-Hao Paul Huang, Niloy J. Mitra </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.12688"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://duyguceylan.github.io/pix2video.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-22</div>
                            </div>
                            <div class="paper-date">2023-03-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> 3D-CLFusion: Fast Text-to-3D Rendering with Contrastive Latent Diffusion  </div>
                                <div> Yu-Jhe Li, Kris Kitani </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.11938"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-21</div>
                            </div>
                            <div class="paper-date">2023-03-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> CompoDiff: Versatile Composed Image Retrieval With Latent Diffusion  </div>
                                <div> Geonmo Gu, Sanghyuk Chun, Wonjae Kim, HeeJae Jun, Yoohoon Kang, Sangdoo Yun </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.11916"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-21</div>
                            </div>
                            <div class="paper-date">2023-03-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Vox-E: Text-guided Voxel Editing of 3D Objects  </div>
                                <div> Etai Sella, Gal Fiebelman, Peter Hedman, Hadar Averbuch-Elor </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.12048"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://tau-vailab.github.io/Vox-E/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-21</div>
                            </div>
                            <div class="paper-date">2023-03-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SALAD: Part-Level Latent Diffusion for 3D Shape Generation and Manipulation  </div>
                                <div> Juil Koo, Seungwoo Yoo, Minh Hieu Nguyen, Minhyuk Sung </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.12236"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://salad3d.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-21</div>
                            </div>
                            <div class="paper-date">2023-03-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Discovering Interpretable Directions in the Semantic Latent Space of Diffusion Models  </div>
                                <div> René Haas, Inbar Huberman-Spiegelglas, Rotem Mulayoff, Tomer Michaeli </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.11073"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-20</div>
                            </div>
                            <div class="paper-date">2023-03-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SVDiff: Compact Parameter Space for Diffusion Fine-Tuning  </div>
                                <div> Ligong Han, Yinxiao Li, Han Zhang, Peyman Milanfar, Dimitris Metaxas, Feng Yang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.11305"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-20</div>
                            </div>
                            <div class="paper-date">2023-03-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Localizing Object-level Shape Variations with Text-to-Image Diffusion Models  </div>
                                <div> Or Patashnik, Daniel Garibi, Idan Azuri, Hadar Averbuch-Elor, Daniel Cohen-Or </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.11306"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://orpatashnik.github.io/local-prompt-mixing/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-20</div>
                            </div>
                            <div class="paper-date">2023-03-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text2Tex: Text-driven Texture Synthesis via Diffusion Models  </div>
                                <div> Dave Zhenyu Chen, Yawar Siddiqui, Hsin-Ying Lee, Sergey Tulyakov, Matthias Nießner </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.11396"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://daveredrum.github.io/Text2Tex/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-20</div>
                            </div>
                            <div class="paper-date">2023-03-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SKED: Sketch-guided Text-based 3D Editing  </div>
                                <div> Aryan Mikaeili, Or Perel, Daniel Cohen-Or, Ali Mahdavi-Amiri </div>
                                <div>
                                        arxiv 2023.

                                        <a href="https://arxiv.org/abs/2303.10735"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-19</div>
                            </div>
                            <div class="paper-date">2023-03-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model  </div>
                                <div> Jiwen Yu, Yinhuai Wang, Chen Zhao, Bernard Ghanem, Jian Zhang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.09833"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/vvictoryuki/FreeDoM"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-17</div>
                            </div>
                            <div class="paper-date">2023-03-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffusionRet: Generative Text-Video Retrieval with Diffusion Model  </div>
                                <div> Peng Jin, Hao Li, Zesen Cheng, Kehan Li, Xiangyang Ji, Chang Liu, Li Yuan, Jie Chen </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.09867"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-17</div>
                            </div>
                            <div class="paper-date">2023-03-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> GlueGen: Plug and Play Multi-modal Encoders for X-to-image Generation  </div>
                                <div> Can Qin, Ning Yu, Chen Xing, Shu Zhang, Zeyuan Chen, Stefano Ermon, Yun Fu, Caiming Xiong, Ran Xu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.10056"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-17</div>
                            </div>
                            <div class="paper-date">2023-03-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DialogPaint: A Dialog-based Image Editing Model  </div>
                                <div> Jingxuan Wei, Shiyu Wu, Xin Jiang, Yequan Wang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.10073"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-17</div>
                            </div>
                            <div class="paper-date">2023-03-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> P+: Extended Textual Conditioning in Text-to-Image Generation  </div>
                                <div> Andrey Voynov, Qinghao Chu, Daniel Cohen-Or, Kfir Aberman </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.09522"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://prompt-plus.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-16</div>
                            </div>
                            <div class="paper-date">2023-03-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> HIVE: Harnessing Human Feedback for Instructional Visual Editing  </div>
                                <div> Shu Zhang, Xinyi Yang, Yihao Feng, Can Qin, Chia-Chih Chen, Ning Yu, Zeyuan Chen, Huan Wang, Silvio Savarese, Stefano Ermon, Caiming Xiong, Ran Xu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.09618"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-16</div>
                            </div>
                            <div class="paper-date">2023-03-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> FateZero: Fusing Attentions for Zero-shot Text-based Video Editing  </div>
                                <div> Chenyang Qi, Xiaodong Cun, Yong Zhang, Chenyang Lei, Xintao Wang, Ying Shan, Qifeng Chen </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.09535"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://fate-zero-edit.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/ChenyangQiQi/FateZero"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-16</div>
                            </div>
                            <div class="paper-date">2023-03-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Unified Multi-Modal Latent Diffusion for Joint Subject and Text Conditional Image Generation  </div>
                                <div> Yiyang Ma, Huan Yang, Wenjing Wang, Jianlong Fu, Jiaying Liu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.09319"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-16</div>
                            </div>
                            <div class="paper-date">2023-03-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer  </div>
                                <div> Serin Yang, Hyunmin Hwang, Jong Chul Ye </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.08622"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-15</div>
                            </div>
                            <div class="paper-date">2023-03-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Aerial Diffusion: Text Guided Ground-to-Aerial View Translation from a Single Image using Diffusion Models  </div>
                                <div> Divya Kothandaraman, Tianyi Zhou, Ming Lin, Dinesh Manocha </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.11444"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/divyakraman/AerialDiffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-15</div>
                            </div>
                            <div class="paper-date">2023-03-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Highly Personalized Text Embedding for Image Manipulation by Stable Diffusion  </div>
                                <div> Inhwa Han, Serin Yang, Taesung Kwon, Jong Chul Ye </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.08767"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-15</div>
                            </div>
                            <div class="paper-date">2023-03-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation  </div>
                                <div> Junyoung Seo, Wooseok Jang, Min-Seop Kwak, Jaehoon Ko, Hyeonsu Kim, Junho Kim, Jin-Hwa Kim, Jiyoung Lee, Seungryong Kim </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.07937"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-14</div>
                            </div>
                            <div class="paper-date">2023-03-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Editing Implicit Assumptions in Text-to-Image Diffusion Models  </div>
                                <div> Hadas Orgad, Bahjat Kawar, Yonatan Belinkov </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.08084"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://time-diffusion.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/bahjat-kawar/time-diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-14</div>
                            </div>
                            <div class="paper-date">2023-03-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Edit-A-Video: Single Video Editing with Object-Aware Consistency  </div>
                                <div> Chaehun Shin, Heeseung Kim, Che Hyun Lee, Sang-gil Lee, Sungroh Yoon </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.07945"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://edit-a-video.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-14</div>
                            </div>
                            <div class="paper-date">2023-03-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Erasing Concepts from Diffusion Models  </div>
                                <div> Rohit Gandikota, Joanna Materzynska, Jaden Fiotto-Kaufman, David Bau </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.07345"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://erasing.baulab.info/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/rohitgandikota/erasing"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-13</div>
                            </div>
                            <div class="paper-date">2023-03-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale  </div>
                                <div> Fan Bao, Shen Nie, Kaiwen Xue, Chongxuan Li, Shi Pu, Yaole Wang, Gang Yue, Yue Cao, Hang Su, Jun Zhu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.06555"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/thu-ml/unidiffuser"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-12</div>
                            </div>
                            <div class="paper-date">2023-03-12</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Cones: Concept Neurons in Diffusion Models for Customized Generation  </div>
                                <div> Zhiheng Liu, Ruili Feng, Kai Zhu, Yifei Zhang, Kecheng Zheng, Yu Liu, Deli Zhao, Jingren Zhou, Yang Cao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.05125"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-09</div>
                            </div>
                            <div class="paper-date">2023-03-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> A Prompt Log Analysis of Text-to-Image Generation Systems  </div>
                                <div> Yutong Xie, Zhaoying Pan, Jinge Ma, Jie Luo, Qiaozhu Mei </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.04587"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-08</div>
                            </div>
                            <div class="paper-date">2023-03-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Video-P2P: Video Editing with Cross-attention Control  </div>
                                <div> Shaoteng Liu, Yuechen Zhang, Wenbo Li, Zhe Lin, Jiaya Jia </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.04761"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://video-p2p.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-08</div>
                            </div>
                            <div class="paper-date">2023-03-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models  </div>
                                <div> Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, Nan Duan </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.04671"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/microsoft/visual-chatgpt"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-08</div>
                            </div>
                            <div class="paper-date">2023-03-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Zeroth-Order Optimization Meets Human Feedback: Provable Learning via Ranking Oracles  </div>
                                <div> Zhiwei Tang, Dmitry Rybin, Tsung-Hui Chang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.03751"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/TZW1998/Taming-Stable-Diffusion-with-Human-Ranking-Feedback"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-07</div>
                            </div>
                            <div class="paper-date">2023-03-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Unleashing Text-to-Image Diffusion Models for Visual Perception  </div>
                                <div> Wenliang Zhao, Yongming Rao, Zuyan Liu, Benlin Liu, Jie Zhou, Jiwen Lu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.02153"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/wl-zhao/VPD"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-03</div>
                            </div>
                            <div class="paper-date">2023-03-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Collage Diffusion  </div>
                                <div> Vishnu Sarukkai, Linden Li, Arden Ma, Christopher Ré, Kayvon Fatahalian </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.00262"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-01</div>
                            </div>
                            <div class="paper-date">2023-03-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Towards Enhanced Controllability of Diffusion Models  </div>
                                <div> Wonwoong Cho, Hareesh Ravi, Midhun Harikumar, Vinh Khuc, Krishna Kumar Singh, Jingwan Lu, David I. Inouye, Ajinkya Kale </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.14368"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-28</div>
                            </div>
                            <div class="paper-date">2023-02-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Directed Diffusion: Direct Control of Object Placement through Attention Guidance  </div>
                                <div> Wan-Duo Kurt Ma, J.P. Lewis, W. Bastiaan Kleijn, Thomas Leung </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.13153"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-25</div>
                            </div>
                            <div class="paper-date">2023-02-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Modulating Pretrained Diffusion Models for Multimodal Image Synthesis  </div>
                                <div> Cusuh Ham, James Hays, Jingwan Lu, Krishna Kumar Singh, Zhifei Zhang, Tobias Hinz </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.12764"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-24</div>
                            </div>
                            <div class="paper-date">2023-02-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Controlled and Conditional Text to Image Generation with Diffusion Prior  </div>
                                <div> Pranav Aggarwal, Hareesh Ravi, Naveen Marri, Sachin Kelkar, Fengbin Chen, Vinh Khuc, Midhun Harikumar, Ritiz Tambi, Sudharshan Reddy Kakumanu, Purvak Lapsiya, Alvin Ghouas, Sarah Saber, Malavika Ramprasad, Baldo Faieta, Ajinkya Kale </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.11710"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-23</div>
                            </div>
                            <div class="paper-date">2023-02-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Region-Aware Diffusion for Zero-shot Text-driven Image Editing  </div>
                                <div> Nisha Huang, Fan Tang, Weiming Dong, Tong-Yee Lee, Changsheng Xu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.11797"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/haha-lisa/RDM-Region-Aware-Diffusion-Model"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-23</div>
                            </div>
                            <div class="paper-date">2023-02-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC  </div>
                                <div> Yilun Du, Conor Durkan, Robin Strudel, Joshua B. Tenenbaum, Sander Dieleman, Rob Fergus, Jascha Sohl-Dickstein, Arnaud Doucet, Will Grathwohl </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.11552"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://energy-based-model.github.io/reduce-reuse-recycle/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-22</div>
                            </div>
                            <div class="paper-date">2023-02-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Learning 3D Photography Videos via Self-supervised Diffusion on Single Images  </div>
                                <div> Xiaodong Wang, Chenfei Wu, Shengming Yin, Minheng Ni, Jianfeng Wang, Linjie Li, Zhengyuan Yang, Fan Yang, Lijuan Wang, Zicheng Liu, Yuejian Fang, Nan Duan </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.10781"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-21</div>
                            </div>
                            <div class="paper-date">2023-02-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Boundary Guided Mixing Trajectory for Semantic Control with Diffusion Models  </div>
                                <div> Ye Zhu, Yu Wu, Zhiwei Deng, Olga Russakovsky, Yan Yan </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.08357"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-16</div>
                            </div>
                            <div class="paper-date">2023-02-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation  </div>
                                <div> Omer Bar-Tal, Lior Yariv, Yaron Lipman, Tali Dekel </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.08113"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://multidiffusion.github.io/"
                                           class="link-primary">roject</a> &nbsp
                                        <a href="https://github.com/omerbt/MultiDiffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-16</div>
                            </div>
                            <div class="paper-date">2023-02-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models  </div>
                                <div> Chong Mou, Xintao Wang, Liangbin Xie, Jian Zhang, Zhongang Qi, Ying Shan, Xiaohu Qie </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.08453"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/TencentARC/T2I-Adapter"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-16</div>
                            </div>
                            <div class="paper-date">2023-02-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-driven Visual Synthesis with Latent Diffusion Prior  </div>
                                <div> Ting-Hsuan Liao, Songwei Ge, Yiran Xu, Yao-Chih Lee, Badour AlBahar, Jia-Bin Huang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.08510"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://latent-diffusion-prior.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-16</div>
                            </div>
                            <div class="paper-date">2023-02-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Exploring the Representation Manifolds of Stable Diffusion Through the Lens of Intrinsic Dimension  </div>
                                <div> Henry Kvinge, Davis Brown, Charles Godfrey </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.09301"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-16</div>
                            </div>
                            <div class="paper-date">2023-02-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> PRedItOR: Text Guided Image Editing with Diffusion Prio  </div>
                                <div> Hareesh Ravi, Sachin Kelkar, Midhun Harikumar, Ajinkya Kale </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.07979"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-15</div>
                            </div>
                            <div class="paper-date">2023-02-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation  </div>
                                <div> Joshua Vendrow, Saachi Jain, Logan Engstrom, Aleksander Madry </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.07865"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/MadryLab/dataset-interfaces"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-15</div>
                            </div>
                            <div class="paper-date">2023-02-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Universal Guidance for Diffusion Models  </div>
                                <div> Arpit Bansal, Hong-Min Chu, Avi Schwarzschild, Soumyadip Sengupta, Micah Goldblum, Jonas Geiping, Tom Goldstein </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.07121"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/arpitbansal297/Universal-Guided-Diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-14</div>
                            </div>
                            <div class="paper-date">2023-02-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-Guided Scene Sketch-to-Photo Synthesis  </div>
                                <div> AprilPyone MaungMaung, Makoto Shing, Kentaro Mitsui, Kei Sawada, Fumio Okura </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.06883"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-14</div>
                            </div>
                            <div class="paper-date">2023-02-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Analyzing Multimodal Objectives Through the Lens of Generative Diffusion Guidance  </div>
                                <div> Chaerin Kong, Nojun Kwak </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.10305"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-10</div>
                            </div>
                            <div class="paper-date">2023-02-10</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Adding Conditional Control to Text-to-Image Diffusion Models  </div>
                                <div> Lvmin Zhang, Maneesh Agrawala </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.05543"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/lllyasviel/ControlNet"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-10</div>
                            </div>
                            <div class="paper-date">2023-02-10</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Is This Loss Informative? Speeding Up Textual Inversion with Deterministic Objective Evaluation  </div>
                                <div> Anton Voronov, Mikhail Khoroshikh, Artem Babenko, Max Ryabinin </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.04841"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-09</div>
                            </div>
                            <div class="paper-date">2023-02-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Zero-shot Generation of Coherent Storybook from Plain Text Story using Diffusion Models  </div>
                                <div> Hyeonho Jeong, Gihyun Kwon, Jong Chul Ye </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.03900"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-08</div>
                            </div>
                            <div class="paper-date">2023-02-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> GLAZE: Protecting Artists from Style Mimicry by Text-to-Image Models  </div>
                                <div> Shawn Shan, Jenna Cryan, Emily Wenger, Haitao Zheng, Rana Hanocka, Ben Y. Zhao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.04222"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-08</div>
                            </div>
                            <div class="paper-date">2023-02-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Q-Diffusion: Quantizing Diffusion Models  </div>
                                <div> Xiuyu Li, Long Lian, Yijiang Liu, Huanrui Yang, Zhen Dong, Daniel Kang, Shanghang Zhang, Kurt Keutzer </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.04304"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/Xiuyu-Li/q-diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-08</div>
                            </div>
                            <div class="paper-date">2023-02-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery  </div>
                                <div> Yuxin Wen, Neel Jain, John Kirchenbauer, Micah Goldblum, Jonas Geiping, Tom Goldstein </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.03668"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/YuxinWenRick/hard-prompts-made-easy"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-07</div>
                            </div>
                            <div class="paper-date">2023-02-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Fair Diffusion: Instructing Text-to-Image Generation Models on Fairness  </div>
                                <div> Felix Friedrich, Patrick Schramowski, Manuel Brack, Lukas Struppek, Dominik Hintersdorf, Sasha Luccioni, Kristian Kersting </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.10893"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-07</div>
                            </div>
                            <div class="paper-date">2023-02-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Structure and Content-Guided Video Synthesis with Diffusion Models  </div>
                                <div> Patrick Esser, Johnathan Chiu, Parmida Atighehchian, Jonathan Granskog, Anastasis Germanidis </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.03011"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://research.runwayml.com/gen1"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-06</div>
                            </div>
                            <div class="paper-date">2023-02-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Zero-shot Image-to-Image Translation  </div>
                                <div> Gaurav Parmar, Krishna Kumar Singh, Richard Zhang, Yijun Li, Jingwan Lu, Jun-Yan Zhu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.03027"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-06</div>
                            </div>
                            <div class="paper-date">2023-02-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Eliminating Prior Bias for Semantic Image Editing via Dual-Cycle Diffusion  </div>
                                <div> Zuopeng Yang, Tianshu Chu, Xin Lin, Erdun Gao, Daqing Liu, Jie Yang, Chaoyue Wang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.02394"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-05</div>
                            </div>
                            <div class="paper-date">2023-02-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ReDi: Efficient Learning-Free Diffusion Inference via Trajectory Retrieval  </div>
                                <div> Kexun Zhang, Xianjun Yang, William Yang Wang, Lei Li </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.02285"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-05</div>
                            </div>
                            <div class="paper-date">2023-02-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Mixture of Diffusers for scene composition and high resolution image generation  </div>
                                <div> Álvaro Barbero Jiménez </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.02412"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/albarji/mixture-of-diffusers"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-05</div>
                            </div>
                            <div class="paper-date">2023-02-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Semantic-Guided Image Augmentation with Pre-trained Models  </div>
                                <div> Bohan Li, Xinghao Wang, Xiao Xu, Yutai Hou, Yunlong Feng, Feng Wang, Wanxiang Che </div>
                                <div>
                                        SIGGRAPH 2023.

                                        <a href="https://arxiv.org/abs/2302.02070"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://texturepaper.github.io/TEXTurePaper/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-04</div>
                            </div>
                            <div class="paper-date">2023-02-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> TEXTure: Text-Guided Texturing of 3D Shapes  </div>
                                <div> Elad Richardson, Gal Metzer, Yuval Alaluf, Raja Giryes, Daniel Cohen-Or </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.01721"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://texturepaper.github.io/TEXTurePaper/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/TEXTurePaper/TEXTurePaper"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-03</div>
                            </div>
                            <div class="paper-date">2023-02-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Dreamix: Video Diffusion Models are General Video Editors  </div>
                                <div> Eyal Molad, Eliahu Horwitz, Dani Valevski, Alex Rav Acha, Yossi Matias, Yael Pritch, Yaniv Leviathan, Yedid Hoshen </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.01329"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://dreamix-video-editing.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-02</div>
                            </div>
                            <div class="paper-date">2023-02-02</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Trash to Treasure: Using text-to-image models to inform the design of physical artefacts  </div>
                                <div> Amy Smith, Hope Schroeder, Ziv Epstein, Michael Cook, Simon Colton, Andrew Lippman </div>
                                <div>
                                        AAAI 2023.

                                        <a href="https://arxiv.org/abs/2302.00561"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-01</div>
                            </div>
                            <div class="paper-date">2023-02-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Zero3D: Semantic-Driven Multi-Category 3D Shape Generation  </div>
                                <div> Bo Han, Yitong Liu, Yixuan Shen </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.13591"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-31</div>
                            </div>
                            <div class="paper-date">2023-01-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models  </div>
                                <div> Hila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, Daniel Cohen-Or </div>
                                <div>
                                        SIGGRAPH 2023.

                                        <a href="https://arxiv.org/abs/2301.13826"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://attendandexcite.github.io/Attend-and-Excite/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/AttendAndExcite/Attend-and-Excite"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-31</div>
                            </div>
                            <div class="paper-date">2023-01-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis  </div>
                                <div> Ming Tao, Bing-Kun Bao, Hao Tang, Changsheng Xu </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2301.12959"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/tobran/GALIP"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-30</div>
                            </div>
                            <div class="paper-date">2023-01-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> PromptMix: Text-to-image diffusion models enhance the performance of lightweight networks  </div>
                                <div> Arian Bakhtiarnia, Qi Zhang, Alexandros Iosifidis </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.12914"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://gitlab.au.dk/maleci/promptmix"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-30</div>
                            </div>
                            <div class="paper-date">2023-01-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Shape-aware Text-driven Layered Video Editing  </div>
                                <div> Yao-Chih Lee, Ji-Ze Genevieve Jang, Yi-Ting Chen, Elizabeth Qiu, Jia-Bin Huang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.13173"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://text-video-edit.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-30</div>
                            </div>
                            <div class="paper-date">2023-01-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset  </div>
                                <div> Zhixuan Liu, Youeun Shin, Beverley-Claire Okogwu, Youngsik Yun, Lia Coleman, Peter Schaldenbrand, Jihie Kim, Jean Oh </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.12073"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-28</div>
                            </div>
                            <div class="paper-date">2023-01-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SEGA: Instructing Diffusion using Semantic Dimensions  </div>
                                <div> Manuel Brack, Felix Friedrich, Dominik Hintersdorf, Lukas Struppek, Patrick Schramowski, Kristian Kersting </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.12247"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-28</div>
                            </div>
                            <div class="paper-date">2023-01-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-To-4D Dynamic Scene Generation  </div>
                                <div> Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual, Iurii Makarov, Filippos Kokkinos, Naman Goyal, Andrea Vedaldi, Devi Parikh, Justin Johnson, Yaniv Taigman </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.11280"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-26</div>
                            </div>
                            <div class="paper-date">2023-01-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Guiding Text-to-Image Diffusion Model Towards Grounded Generation  </div>
                                <div> Ziyi Li, Qinye Zhou, Xiaoyun Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.05221"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://lipurple.github.io/Grounded_Diffusion/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-12</div>
                            </div>
                            <div class="paper-date">2023-01-12</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Speech Driven Video Editing via an Audio-Conditioned Diffusion Model  </div>
                                <div> Dan Bigioi, Shubhajit Basak, Hugh Jordan, Rachel McDonnell, Peter Corcoran </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.04474"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-10</div>
                            </div>
                            <div class="paper-date">2023-01-10</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffTalk: Crafting Diffusion Models for Generalized Talking Head Synthesis  </div>
                                <div> Shuai Shen, Wenliang Zhao, Zibin Meng, Wanhua Li, Zheng Zhu, Jie Zhou, Jiwen Lu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.03786"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-10</div>
                            </div>
                            <div class="paper-date">2023-01-10</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Speech Driven Video Editing via an Audio-Conditioned Diffusion Model  </div>
                                <div> Dan Bigioi, Shubhajit Basak, Hugh Jordan, Rachel McDonnell, Peter Corcoran </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.04474"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://danbigioi.github.io/DiffusionVideoEditing/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/DanBigioi/DiffusionVideoEditing"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-10</div>
                            </div>
                            <div class="paper-date">2023-01-10</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Visual Story Generation Based on Emotion and Keywords  </div>
                                <div> Yuetian Chen, Ruohua Li, Bowen Shi, Peiru Liu, Mei Si </div>
                                <div>
                                        AIIDE INT 2022.

                                        <a href="https://arxiv.org/abs/2301.02777"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-07</div>
                            </div>
                            <div class="paper-date">2023-01-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation  </div>
                                <div> Michał Stypułkowski, Konstantinos Vougioukas, Sen He, Maciej Zięba, Stavros Petridis, Maja Pantic </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.03396"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://mstypulkowski.github.io/diffusedheads/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-06</div>
                            </div>
                            <div class="paper-date">2023-01-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Muse: Text-To-Image Generation via Masked Generative Transformers  </div>
                                <div> Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, Jose Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Murphy, William T. Freeman, Michael Rubinstein, Yuanzhen Li, Dilip Krishnan </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.00704"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://muse-model.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-02</div>
                            </div>
                            <div class="paper-date">2023-01-02</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Exploring Vision Transformers as Diffusion Learners  </div>
                                <div> He Cao, Jianan Wang, Tianhe Ren, Xianbiao Qi, Yihao Chen, Yuan Yao, Lei Zhang </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.13771"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-28</div>
                            </div>
                            <div class="paper-date">2022-12-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models  </div>
                                <div> Jiale Xu, Xintao Wang, Weihao Cheng, Yan-Pei Cao, Ying Shan, Xiaohu Qie, Shenghua Gao </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2212.14704"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://bluestyle97.github.io/dream3d/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-28</div>
                            </div>
                            <div class="paper-date">2022-12-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation  </div>
                                <div> Jay Zhangjie Wu, Yixiao Ge, Xintao Wang, Weixian Lei, Yuchao Gu, Wynne Hsu, Ying Shan, Xiaohu Qie, Mike Zheng Shou </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.11565"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://tuneavideo.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-22</div>
                            </div>
                            <div class="paper-date">2022-12-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Contrastive Language-Vision AI Models Pretrained on Web-Scraped Multimodal Data Exhibit Sexual Objectification Bias  </div>
                                <div> Robert Wolfe, Yiwei Yang, Bill Howe, Aylin Caliskan </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.11261"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-21</div>
                            </div>
                            <div class="paper-date">2022-12-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Optimizing Prompts for Text-to-Image Generation  </div>
                                <div> Yaru Hao, Zewen Chi, Li Dong, Furu Wei </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.09611"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://huggingface.co/spaces/microsoft/Promptist"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/microsoft/LMOps/tree/main/promptist"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-19</div>
                            </div>
                            <div class="paper-date">2022-12-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Uncovering the Disentanglement Capability in Text-to-Image Diffusion Models  </div>
                                <div> Qiucheng Wu, Yujian Liu, Handong Zhao, Ajinkya Kale, Trung Bui, Tong Yu, Zhe Lin, Yang Zhang, Shiyu Chang </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.08698"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/UCSB-NLP-Chang/DiffusionDisentanglement"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-16</div>
                            </div>
                            <div class="paper-date">2022-12-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> TeTIm-Eval: a novel curated evaluation data set for comparing text-to-image models  </div>
                                <div> Federico A. Galatolo, Mario G. C. A. Cimino, Edoardo Cogotti </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.07839"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-15</div>
                            </div>
                            <div class="paper-date">2022-12-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> The Infinite Index: Information Retrieval on Generative Text-To-Image Models  </div>
                                <div> Niklas Deckers, Maik Fröbe, Johannes Kiesel, Gianluca Pandolfo, Christopher Schröder, Benno Stein, Martin Potthast </div>
                                <div>
                                        CHIIR 2023.

                                        <a href="https://arxiv.org/abs/2212.07476"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-14</div>
                            </div>
                            <div class="paper-date">2022-12-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Imagen Editor and EditBench: Advancing and Evaluating Text-Guided Image Inpainting  </div>
                                <div> Su Wang, Chitwan Saharia, Ceslee Montgomery, Jordi Pont-Tuset, Shai Noy, Stefano Pellegrini, Yasumasa Onoe, Sarah Laszlo, David J. Fleet, Radu Soricut, Jason Baldridge, Mohammad Norouzi, Peter Anderson, William Chan </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2212.06909"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-13</div>
                            </div>
                            <div class="paper-date">2022-12-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> LidarCLIP or: How I Learned to Talk to Point Clouds  </div>
                                <div> Georg Hess, Adam Tonderski, Christoffer Petersson, Lennart Svensson, Kalle Åström </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.06858"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/atonderski/lidarclip"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-13</div>
                            </div>
                            <div class="paper-date">2022-12-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> The Stable Artist: Steering Semantics in Diffusion Latent Space  </div>
                                <div> Manuel Brack, Patrick Schramowski, Felix Friedrich, Dominik Hintersdorf, Kristian Kersting </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.06013"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-12</div>
                            </div>
                            <div class="paper-date">2022-12-12</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis  </div>
                                <div> Weixi Feng, Xuehai He, Tsu-Jui Fu, Varun Jampani, Arjun Akula, Pradyumna Narayana, Sugato Basu, Xin Eric Wang, William Yang Wang </div>
                                <div>
                                        ICLR 2023.

                                        <a href="https://arxiv.org/abs/2212.05032"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/weixi-feng/Structured-Diffusion-Guidance"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-09</div>
                            </div>
                            <div class="paper-date">2022-12-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Model  </div>
                                <div> Shaoan Xie, Zhifei Zhang, Zhe Lin, Tobias Hinz, Kun Zhang </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.05034"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-09</div>
                            </div>
                            <div class="paper-date">2022-12-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Executing your Commands via Motion Diffusion in Latent Space  </div>
                                <div> Xin Chen, Biao Jiang, Wen Liu, Zilong Huang, Bin Fu, Tao Chen, Jingyi Yu, Gang Yu </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.04048"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://chenxin.tech/mld/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-08</div>
                            </div>
                            <div class="paper-date">2022-12-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion Guided Domain Adaptation of Image Generators  </div>
                                <div> Kunpeng Song, Ligong Han, Bingchen Liu, Dimitris Metaxas, Ahmed Elgammal </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.04473"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://styleganfusion.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-08</div>
                            </div>
                            <div class="paper-date">2022-12-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Multi-Concept Customization of Text-to-Image Diffusion  </div>
                                <div> Nupur Kumari, Bingliang Zhang, Richard Zhang, Eli Shechtman, Jun-Yan Zhu </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.04488"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://www.cs.cmu.edu/~custom-diffusion/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-08</div>
                            </div>
                            <div class="paper-date">2022-12-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SINE: SINgle Image Editing with Text-to-Image Diffusion Models  </div>
                                <div> Zhixing Zhang, Ligong Han, Arnab Ghosh, Dimitris Metaxas, Jian Ren </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.04489"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://zhang-zx.github.io/SINE/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/zhang-zx/SINE"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-08</div>
                            </div>
                            <div class="paper-date">2022-12-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation  </div>
                                <div> Yen-Chi Cheng, Hsin-Ying Lee, Sergey Tulyakov, Alexander Schwing, Liangyan Gui </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.04493"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://yccyenchicheng.github.io/SDFusion/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-08</div>
                            </div>
                            <div class="paper-date">2022-12-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> MoFusion: A Framework for Denoising-Diffusion-based Motion Synthesis  </div>
                                <div> Rishabh Dabral, Muhammad Hamza Mughal, Vladislav Golyanik, Christian Theobalt </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.04495"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://vcai.mpi-inf.mpg.de/projects/MoFusion/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-08</div>
                            </div>
                            <div class="paper-date">2022-12-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Judge, Localize, and Edit: Ensuring Visual Commonsense Morality for Text-to-Image Generation  </div>
                                <div> Seongbeom Park, Suhong Moon, Jinkyu Kim </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.03507"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-07</div>
                            </div>
                            <div class="paper-date">2022-12-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Magic: Multi Art Genre Intelligent Choreography Dataset and Network for 3D Dance Generation  </div>
                                <div> Ronghui Li, Junfan Zhao, Yachao Zhang, Mingyang Su, Zeping Ren, Han Zhang, Xiu Li </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.03741"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-07</div>
                            </div>
                            <div class="paper-date">2022-12-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Talking Head Generation with Probabilistic Audio-to-Visual Diffusion Priors  </div>
                                <div> Zhentao Yu, Zixin Yin, Deyu Zhou, Duomin Wang, Finn Wong, Baoyuan Wang </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.04248"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://zxyin.github.io/TH-PAD/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-07</div>
                            </div>
                            <div class="paper-date">2022-12-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding  </div>
                                <div> Gyeongman Kim, Hajin Shim, Hyunsu Kim, Yunjey Choi, Junho Kim, Eunho Yang </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2212.02802"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://diff-video-ae.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/man805/Diffusion-Video-Autoencoders"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-06</div>
                            </div>
                            <div class="paper-date">2022-12-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> M-VADER: A Model for Diffusion with Multimodal Context  </div>
                                <div> Samuel Weinbach, Marco Bellagente, Constantin Eichenberg, Andrew Dai, Robert Baldock, Souradeep Nanda, Björn Deiseroth, Koen Oostermeijer, Hannah Teufel, Andres Felipe Cruz-Salinas </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.02936"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-06</div>
                            </div>
                            <div class="paper-date">2022-12-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ADIR: Adaptive Diffusion for Image Reconstruction  </div>
                                <div> Shady Abu-Hussein, Tom Tirer, Raja Giryes </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.03221"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://shadyabh.github.io/ADIR/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-06</div>
                            </div>
                            <div class="paper-date">2022-12-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion-SDF: Text-to-Shape via Voxelized Diffusion  </div>
                                <div> Muheng Li, Yueqi Duan, Jie Zhou, Jiwen Lu </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2212.03293"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://ttlmh.github.io/DiffusionSDF/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/ttlmh/Diffusion-SDF"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-06</div>
                            </div>
                            <div class="paper-date">2022-12-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Semantic-Conditional Diffusion Networks for Image Captioning  </div>
                                <div> Jianjie Luo, Yehao Li, Yingwei Pan, Ting Yao, Jianlin Feng, Hongyang Chao, Tao Mei </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2212.03099"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/YehLi/xmodaler/tree/master/configs/image_caption/scdnet"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-06</div>
                            </div>
                            <div class="paper-date">2022-12-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> NeRDi: Single-View NeRF Synthesis with Language-Guided Diffusion as General Image Priors  </div>
                                <div> Congyue Deng, Chiyu "Max'' Jiang, Charles R. Qi, Xinchen Yan, Yin Zhou, Leonidas Guibas, Dragomir Anguelov </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.03267"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-06</div>
                            </div>
                            <div class="paper-date">2022-12-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Shape-Guided Diffusion with Inside-Outside Attention  </div>
                                <div> Dong Huk Park, Grace Luo, Clayton Toste, Samaneh Azadi, Xihui Liu, Maka Karalashvili, Anna Rohrbach, Trevor Darrell </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.00210"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://shape-guided-diffusion.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-01</div>
                            </div>
                            <div class="paper-date">2022-12-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Unite and Conquer: Cross Dataset Multimodal Synthesis using Diffusion Models  </div>
                                <div> Nithin Gopalakrishnan Nair, Wele Gedara Chaminda Bandara, Vishal M. Patel </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.00793"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://nithin-gk.github.io/projectpages/Multidiff/index.html"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-01</div>
                            </div>
                            <div class="paper-date">2022-12-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative Model  </div>
                                <div> Gwanghyun Kim, Se Young Chun </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2211.16374"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://datid-3d.github.io/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-29</div>
                            </div>
                            <div class="paper-date">2022-11-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SinDDM: A Single Image Denoising Diffusion Model  </div>
                                <div> Vladimir Kulikov, Shahar Yadin, Matan Kleiner, Tomer Michaeli </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.16582"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://matankleiner.github.io/sinddm/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-29</div>
                            </div>
                            <div class="paper-date">2022-11-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Refined Semantic Enhancement towards Frequency Diffusion for Video Captioning  </div>
                                <div> Xian Zhong, Zipeng Li, Shuqin Chen, Kui Jiang, Chen Chen, Mang Ye </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.15076"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/lzp870/RSFD"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-28</div>
                            </div>
                            <div class="paper-date">2022-11-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Unified Discrete Diffusion for Simultaneous Vision-Language Generation  </div>
                                <div> Minghui Hu, Chuanxia Zheng, Heliang Zheng, Tat-Jen Cham, Chaoyue Wang, Zuopeng Yang, Dacheng Tao, Ponnuthurai N. Suganthan </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.14842"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-27</div>
                            </div>
                            <div class="paper-date">2022-11-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SpaText: Spatio-Textual Representation for Controllable Image Generation  </div>
                                <div> Omri Avrahami, Thomas Hayes, Oran Gafni, Sonal Gupta, Yaniv Taigman, Devi Parikh, Dani Lischinski, Ohad Fried, Xi Yin </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2211.14305"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://omriavrahami.com/spatext/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-25</div>
                            </div>
                            <div class="paper-date">2022-11-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> 3DDesigner: Towards Photorealistic 3D Object Generation and Editing with Text-guided Diffusion Models  </div>
                                <div> Gang Li, Heliang Zheng, Chaoyue Wang, Chang Li, Changwen Zheng, Dacheng Tao </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.14108"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-25</div>
                            </div>
                            <div class="paper-date">2022-11-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Shifted Diffusion for Text-to-image Generation  </div>
                                <div> Yufan Zhou, Bingchen Liu, Yizhe Zhu, Xiao Yang, Changyou Chen, Jinhui Xu </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2211.15388"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-24</div>
                            </div>
                            <div class="paper-date">2022-11-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Sketch-Guided Text-to-Image Diffusion Models  </div>
                                <div> Andrey Voynov, Kfir Aberman, Daniel Cohen-Or </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.13752"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://sketch-guided-diffusion.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-24</div>
                            </div>
                            <div class="paper-date">2022-11-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Schrödinger's Bat: Diffusion Models Sometimes Generate Polysemous Words in Superposition  </div>
                                <div> Jennifer C. White, Ryan Cotterell </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.13095"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-23</div>
                            </div>
                            <div class="paper-date">2022-11-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Make-A-Story: Visual Memory Conditioned Consistent Story Generation  </div>
                                <div> Tanzila Rahman, Hsin-Ying Lee, Jian Ren, Sergey Tulyakov, Shweta Mahajan, Leonid Sigal </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2211.13319"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-23</div>
                            </div>
                            <div class="paper-date">2022-11-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SinDiffusion: Learning a Diffusion Model from a Single Natural Image  </div>
                                <div> Weilun Wang, Jianmin Bao, Wengang Zhou, Dongdong Chen, Dong Chen, Lu Yuan, Houqiang Li </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.12445"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/WeilunWang/SinDiffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-22</div>
                            </div>
                            <div class="paper-date">2022-11-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Human Evaluation of Text-to-Image Models on a Multi-Task Benchmark  </div>
                                <div> Vitali Petsiuk, Alexander E. Siemenn, Saisamrit Surbehera, Zad Chin, Keith Tyser, Gregory Hunter, Arvind Raghavan, Yann Hicke, Bryan A. Plummer, Ori Kerret, Tonio Buonassisi, Kate Saenko, Armando Solar-Lezama, Iddo Drori </div>
                                <div>
                                        NeurIPS Workshop 2022.

                                        <a href="https://arxiv.org/abs/2211.12112"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-22</div>
                            </div>
                            <div class="paper-date">2022-11-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation  </div>
                                <div> Narek Tumanyan, Michal Geyer, Shai Bagon, Tali Dekel </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2211.12572"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/MichalGeyer/plug-and-play"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-22</div>
                            </div>
                            <div class="paper-date">2022-11-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> EDICT: Exact Diffusion Inversion via Coupled Transformations  </div>
                                <div> Bram Wallace, Akash Gokul, Nikhil Naik </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.12446"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/salesforce/EDICT"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-22</div>
                            </div>
                            <div class="paper-date">2022-11-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> VectorFusion: Text-to-SVG by Abstracting Pixel-Based Diffusion Models  </div>
                                <div> Ajay Jain, Amber Xie, Pieter Abbeel </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.11319"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://ajayj.com/vectorfusion"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-21</div>
                            </div>
                            <div class="paper-date">2022-11-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Investigating Prompt Engineering in Diffusion Models  </div>
                                <div> Sam Witteveen, Martin Andrews </div>
                                <div>
                                        NeurIPS Workshop 2022.

                                        <a href="https://arxiv.org/abs/2211.15462"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-21</div>
                            </div>
                            <div class="paper-date">2022-11-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Exploring Discrete Diffusion Models for Image Captioning  </div>
                                <div> Zixin Zhu, Yixuan Wei, Jianfeng Wang, Zhe Gan, Zheng Zhang, Le Wang, Gang Hua, Lijuan Wang, Zicheng Liu, Han Hu </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.11694"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/buxiangzhiren/DDCap"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-21</div>
                            </div>
                            <div class="paper-date">2022-11-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SinFusion: Training Diffusion Models on a Single Image or Video  </div>
                                <div> Yaniv Nikankin, Niv Haim, Michal Irani </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.11743"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://yanivnik.github.io/sinfusion/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-21</div>
                            </div>
                            <div class="paper-date">2022-11-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Synthesizing Coherent Story with Auto-Regressive Latent Diffusion Models  </div>
                                <div> Xichen Pan, Pengda Qin, Yuhong Li, Hui Xue, Wenhu Chen </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.10950"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/xichenpan/ARLDM"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-20</div>
                            </div>
                            <div class="paper-date">2022-11-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffStyler: Controllable Dual Diffusion for Text-Driven Image Stylization  </div>
                                <div> Nisha Huang, Yuxin Zhang, Fan Tang, Chongyang Ma, Haibin Huang, Yong Zhang, Weiming Dong, Changsheng Xu </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.10682"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-19</div>
                            </div>
                            <div class="paper-date">2022-11-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Invariant Learning via Diffusion Dreamed Distribution Shifts  </div>
                                <div> Priyatham Kattakinda, Alexander Levine, Soheil Feizi </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.10370"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-18</div>
                            </div>
                            <div class="paper-date">2022-11-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Magic3D: High-Resolution Text-to-3D Content Creation  </div>
                                <div> Chen-Hsuan Lin, Jun Gao, Luming Tang, Towaki Takikawa, Xiaohui Zeng, Xun Huang, Karsten Kreis, Sanja Fidler, Ming-Yu Liu, Tsung-Yi Lin </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2211.10440"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://deepimagination.cc/Magic3D/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-18</div>
                            </div>
                            <div class="paper-date">2022-11-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> InstructPix2Pix: Learning to Follow Image Editing Instructions  </div>
                                <div> Tim Brooks, Aleksander Holynski, Alexei A. Efros </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2211.09800"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://www.timothybrooks.com/instruct-pix2pix"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/timothybrooks/instruct-pix2pix"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-17</div>
                            </div>
                            <div class="paper-date">2022-11-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Null-text Inversion for Editing Real Images using Guided Diffusion Model  </div>
                                <div> Ron Mokady, Amir Hertz, Kfir Aberman, Yael Pritch, Daniel Cohen-Or </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.09794"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-17</div>
                            </div>
                            <div class="paper-date">2022-11-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Direct Inversion: Optimization-Free Text-Driven Real Image Editing with Diffusion Models  </div>
                                <div> Adham Elarabawy, Harish Kamath, Samuel Denton </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.07825"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-15</div>
                            </div>
                            <div class="paper-date">2022-11-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Versatile Diffusion: Text, Images and Variations All in One Diffusion Model  </div>
                                <div> Xingqian Xu, Zhangyang Wang, Eric Zhang, Kai Wang, Humphrey Shi </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.08332"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/SHI-Labs/Versatile-Diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-15</div>
                            </div>
                            <div class="paper-date">2022-11-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Arbitrary Style Guidance for Enhanced Diffusion-Based Text-to-Image Generation  </div>
                                <div> Zhihong Pan, Xin Zhou, Hao Tian </div>
                                <div>
                                        WACV 2023.

                                        <a href="https://arxiv.org/abs/2211.07751"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-14</div>
                            </div>
                            <div class="paper-date">2022-11-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Safe Latent Diffusion: Mitigating Inappropriate Degeneration in Diffusion Models  </div>
                                <div> Patrick Schramowski, Manuel Brack, Björn Deiseroth, Kristian Kersting </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2211.05105"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/ml-research/safe-latent-diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-09</div>
                            </div>
                            <div class="paper-date">2022-11-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Rickrolling the Artist: Injecting Invisible Backdoors into Text-Guided Image Generation Models  </div>
                                <div> Lukas Struppek, Dominik Hintersdorf, Kristian Kersting </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.02408"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/LukasStruppek/Rickrolling-the-Artist"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-04</div>
                            </div>
                            <div class="paper-date">2022-11-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> eDiffi: Text-to-Image Diffusion Models with an Ensemble of Expert Denoisers  </div>
                                <div> Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song, Karsten Kreis, Miika Aittala, Timo Aila, Samuli Laine, Bryan Catanzaro, Tero Karras, Ming-Yu Liu </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.01324"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://deepimagination.cc/eDiffi/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-02</div>
                            </div>
                            <div class="paper-date">2022-11-02</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> UPainting: Unified Text-to-Image Diffusion Generation with Cross-modal Guidance  </div>
                                <div> Wei Li, Xue Xu, Xinyan Xiao, Jiachen Liu, Hu Yang, Guohao Li, Zhanpeng Wang, Zhifan Feng, Qiaoqiao She, Yajuan Lyu, Hua Wu </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.16031"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-28</div>
                            </div>
                            <div class="paper-date">2022-10-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> MagicMix: Semantic Mixing with Diffusion Models  </div>
                                <div> Jun Hao Liew, Hanshu Yan, Daquan Zhou, Jiashi Feng </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.16056"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://magicmix.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-28</div>
                            </div>
                            <div class="paper-date">2022-10-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced Mixture-of-Denoising-Experts  </div>
                                <div> Zhida Feng, Zhenyu Zhang, Xintong Yu, Yewei Fang, Lanxin Li, Xuyi Chen, Yuxiang Lu, Jiaxiang Liu, Weichong Yin, Shikun Feng, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2210.15257"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-27</div>
                            </div>
                            <div class="paper-date">2022-10-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> How well can Text-to-Image Generative Models understand Ethical Natural Language Interventions?  </div>
                                <div> Hritik Bansal, Da Yin, Masoud Monajatipoor, Kai-Wei Chang </div>
                                <div>
                                        EMNLP 2022.

                                        <a href="https://arxiv.org/abs/2210.15230"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/Hritikbansal/entigen_emnlp"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-27</div>
                            </div>
                            <div class="paper-date">2022-10-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models  </div>
                                <div> Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, Duen Horng Chau </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.14896"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://poloclub.github.io/diffusiondb/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/poloclub/diffusiondb"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-26</div>
                            </div>
                            <div class="paper-date">2022-10-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Lafite2: Few-shot Text-to-Image Generation  </div>
                                <div> Yufan Zhou, Chunyuan Li, Changyou Chen, Jianfeng Gao, Jinhui Xu </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.14124"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-25</div>
                            </div>
                            <div class="paper-date">2022-10-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> High-Resolution Image Editing via Multi-Stage Blended Diffusion  </div>
                                <div> Johannes Ackermann, Minjun Li </div>
                                <div>
                                        NeurIPS Workshop 2022.

                                        <a href="https://arxiv.org/abs/2210.12965"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/pfnet-research/multi-stage-blended-diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-24</div>
                            </div>
                            <div class="paper-date">2022-10-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> A Visual Tour Of Current Challenges In Multimodal Language Models  </div>
                                <div> Shashank Sonkar, Naiming Liu, Richard G. Baraniuk </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.12565"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-22</div>
                            </div>
                            <div class="paper-date">2022-10-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Conditional Diffusion with Less Explicit Guidance via Model Predictive Control  </div>
                                <div> Max W. Shen, Ehsan Hajiramezanali, Gabriele Scalia, Alex Tseng, Nathaniel Diamant, Tommaso Biancalani, Andreas Loukas </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.12192"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-21</div>
                            </div>
                            <div class="paper-date">2022-10-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion Models already have a Semantic Latent Space  </div>
                                <div> Mingi Kwon, Jaeseok Jeong, Youngjung Uh </div>
                                <div>
                                        ICLR 2023.

                                        <a href="https://arxiv.org/abs/2210.10960"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://kwonminki.github.io/Asyrp/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-20</div>
                            </div>
                            <div class="paper-date">2022-10-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffEdit: Diffusion-based semantic image editing with mask guidance  </div>
                                <div> Guillaume Couairon, Jakob Verbeek, Holger Schwenk, Matthieu Cord </div>
                                <div>
                                        ICLR 2023.

                                        <a href="https://arxiv.org/abs/2210.11427"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-20</div>
                            </div>
                            <div class="paper-date">2022-10-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Swinv2-Imagen: Hierarchical Vision Transformer Diffusion Models for Text-to-Image Generation  </div>
                                <div> Ruijun Li, Weihua Li, Yi Yang, Hanyu Wei, Jianhua Jiang, Quan Bai </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.09549"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-18</div>
                            </div>
                            <div class="paper-date">2022-10-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> UniTune: Text-Driven Image Editing by Fine Tuning an Image Generation Model on a Single Image  </div>
                                <div> Dani Valevski, Matan Kalman, Yossi Matias, Yaniv Leviathan </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.09477"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-18</div>
                            </div>
                            <div class="paper-date">2022-10-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Imagic: Text-Based Real Image Editing with Diffusion Models  </div>
                                <div> Bahjat Kawar, Shiran Zada, Oran Lang, Omer Tov, Huiwen Chang, Tali Dekel, Inbar Mosseri, Michal Irani </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2210.09276"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://imagic-editing.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-17</div>
                            </div>
                            <div class="paper-date">2022-10-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Leveraging Off-the-shelf Diffusion Model for Multi-attribute Fashion Image Manipulation  </div>
                                <div> Chaerin Kong, DongHyeon Jeon, Ohjoon Kwon, Nojun Kwak </div>
                                <div>
                                        WACV 2022.

                                        <a href="https://arxiv.org/abs/2210.05872"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-12</div>
                            </div>
                            <div class="paper-date">2022-10-12</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Unifying Diffusion Models' Latent Space, with Applications to CycleDiffusion and Guidance  </div>
                                <div> Chen Henry Wu, Fernando De la Torre </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.05559"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/ChenWu98/cycle-diffusion"
                                           class="link-primary">Github-1</a> &nbsp
                                        <a href="https://github.com/ChenWu98/unified-generative-zoo"
                                           class="link-primary">Github-2</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-11</div>
                            </div>
                            <div class="paper-date">2022-10-11</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> clip2latent: Text driven sampling of a pre-trained StyleGAN using denoising diffusion and CLIP  </div>
                                <div> Justin N. M. Pinkney, Chuan Li </div>
                                <div>
                                        BMVC 2022.

                                        <a href="https://arxiv.org/abs/2210.02347"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/justinpinkney/clip2latent"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-05</div>
                            </div>
                            <div class="paper-date">2022-10-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> LDEdit: Towards Generalized Text Guided Image Manipulation via Latent Diffusion Models  </div>
                                <div> Paramanand Chandramouli, Kanchana Vaishnavi Gandikota </div>
                                <div>
                                        BMVC 2022.

                                        <a href="https://arxiv.org/abs/2210.02249"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-05</div>
                            </div>
                            <div class="paper-date">2022-10-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DALL-E-Bot: Introducing Web-Scale Diffusion Models to Robotics  </div>
                                <div> Ivan Kapelyukh, Vitalis Vosylius, Edward Johns </div>
                                <div>
                                        IEEE RA-L 2022.

                                        <a href="https://arxiv.org/abs/2210.02438"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-05</div>
                            </div>
                            <div class="paper-date">2022-10-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Imagen Video: High Definition Video Generation with Diffusion Models  </div>
                                <div> Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik P. Kingma, Ben Poole, Mohammad Norouzi, David J. Fleet, Tim Salimans </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.02303"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-05</div>
                            </div>
                            <div class="paper-date">2022-10-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Membership Inference Attacks Against Text-to-image Generation Models  </div>
                                <div> Yixin Wu, Ning Yu, Zheng Li, Michael Backes, Yang Zhang </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.00968"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-03</div>
                            </div>
                            <div class="paper-date">2022-10-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Creative Painting with Latent Diffusion Models  </div>
                                <div> Xianchao Wu </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2209.14697"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-09-29</div>
                            </div>
                            <div class="paper-date">2022-09-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Re-Imagen: Retrieval-Augmented Text-to-Image Generator  </div>
                                <div> Wenhu Chen, Hexiang Hu, Chitwan Saharia, William W. Cohen </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2209.14491"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-09-29</div>
                            </div>
                            <div class="paper-date">2022-09-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DreamFusion: Text-to-3D using 2D Diffusion  </div>
                                <div> Ben Poole, Ajay Jain, Jonathan T. Barron, Ben Mildenhall </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2209.14988"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://dreamfusion3d.github.io/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-09-29</div>
                            </div>
                            <div class="paper-date">2022-09-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Make-A-Video: Text-to-Video Generation without Text-Video Data  </div>
                                <div> Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, Yaniv Taigman </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2209.14792"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-09-29</div>
                            </div>
                            <div class="paper-date">2022-09-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Draw Your Art Dream: Diverse Digital Art Synthesis with Multimodal Guided Diffusion  </div>
                                <div> Nisha Huang, Fan Tang, Weiming Dong, Changsheng Xu </div>
                                <div>
                                        ACM MM 2022.

                                        <a href="https://arxiv.org/abs/2209.13360"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/haha-lisa/MGAD-multimodal-guided-artwork-diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-09-27</div>
                            </div>
                            <div class="paper-date">2022-09-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Personalizing Text-to-Image Generation via Aesthetic Gradients  </div>
                                <div> Victor Gallego </div>
                                <div>
                                        NeurIPS Workshop 2022.

                                        <a href="https://arxiv.org/abs/2209.12330"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/vicgalle/stable-diffusion-aesthetic-gradients"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-09-25</div>
                            </div>
                            <div class="paper-date">2022-09-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Best Prompts for Text-to-Image Models and How to Find Them  </div>
                                <div> Nikita Pavlichenko, Dmitry Ustalov </div>
                                <div>
                                        NeurIPS Workshop 2022.

                                        <a href="https://arxiv.org/abs/2209.11711"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-09-23</div>
                            </div>
                            <div class="paper-date">2022-09-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> The Biased Artist: Exploiting Cultural Biases via Homoglyphs in Text-Guided Image Generation Models  </div>
                                <div> Lukas Struppek, Dominik Hintersdorf, Kristian Kersting </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2209.08891"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/LukasStruppek/The-Biased-Artist"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-09-19</div>
                            </div>
                            <div class="paper-date">2022-09-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models  </div>
                                <div> Chen Henry Wu, Saman Motamed, Shaunak Srivastava, Fernando De la Torre </div>
                                <div>
                                        NeurIPS 2022.

                                        <a href="https://arxiv.org/abs/2209.06970"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/ChenWu98/Generative-Visual-Prompt"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-09-14</div>
                            </div>
                            <div class="paper-date">2022-09-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation  </div>
                                <div> Zhengzhe Liu, Peng Dai, Ruihui Li, Xiaojuan Qi, Chi-Wing Fu </div>
                                <div>
                                        ICLR 2023.

                                        <a href="https://arxiv.org/abs/2209.04145"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/liuzhengzhe/ISS-Image-as-Stepping-Stone-for-Text-Guided-3D-Shape-Generation"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-09-09</div>
                            </div>
                            <div class="paper-date">2022-09-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation  </div>
                                <div> Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, Kfir Aberman </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2208.12242"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://dreambooth.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/Victarry/stable-dreambooth"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-08-25</div>
                            </div>
                            <div class="paper-date">2022-08-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models  </div>
                                <div> Robin Rombach, Andreas Blattmann, Björn Ommer </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2207.13038"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/CompVis/latent-diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-07-26</div>
                            </div>
                            <div class="paper-date">2022-07-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Discrete Contrastive Diffusion for Cross-Modal and Conditional Generation  </div>
                                <div> Ye Zhu, Yu Wu, Kyle Olszewski, Jian Ren, Sergey Tulyakov, Yan Yan </div>
                                <div>
                                        ICLR 2023.

                                        <a href="https://arxiv.org/abs/2206.07771"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/L-YeZhu/CDCD"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-06-15</div>
                            </div>
                            <div class="paper-date">2022-06-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Blended Latent Diffusion  </div>
                                <div> Omri Avrahami, Ohad Fried, Dani Lischinski </div>
                                <div>
                                        ACM 2022.

                                        <a href="https://arxiv.org/abs/2206.02779"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://omriavrahami.com/blended-latent-diffusion-page/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/omriav/blended-latent-diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-06-06</div>
                            </div>
                            <div class="paper-date">2022-06-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Compositional Visual Generation with Composable Diffusion Models  </div>
                                <div> Nan Liu, Shuang Li, Yilun Du, Antonio Torralba, Joshua B. Tenenbaum </div>
                                <div>
                                        ECCV 2022.

                                        <a href="https://arxiv.org/abs/2206.01714"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-06-03</div>
                            </div>
                            <div class="paper-date">2022-06-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiVAE: Photorealistic Images Synthesis with Denoising Diffusion Decoder  </div>
                                <div> Jie Shi, Chenfei Wu, Jian Liang, Xiang Liu, Nan Duan </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2206.00386"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-06-01</div>
                            </div>
                            <div class="paper-date">2022-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text2Human: Text-Driven Controllable Human Image Generation  </div>
                                <div> Yuming Jiang, Shuai Yang, Haonan Qiu, Wayne Wu, Chen Change Loy, Ziwei Liu </div>
                                <div>
                                        ACM 2022.

                                        <a href="https://arxiv.org/abs/2205.15996"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/yumingj/Text2Human"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-05-31</div>
                            </div>
                            <div class="paper-date">2022-05-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Improved Vector Quantized Diffusion Models  </div>
                                <div> Zhicong Tang, Shuyang Gu, Jianmin Bao, Dong Chen, Fang Wen </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2205.16007"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/microsoft/VQ-Diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-05-31</div>
                            </div>
                            <div class="paper-date">2022-05-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding  </div>
                                <div> Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, Mohammad Norouzi </div>
                                <div>
                                        NeurIPS 2022.

                                        <a href="https://arxiv.org/abs/2205.11487"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/lucidrains/imagen-pytorch"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-05-23</div>
                            </div>
                            <div class="paper-date">2022-05-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Retrieval-Augmented Diffusion Models  </div>
                                <div> Andreas Blattmann, Robin Rombach, Kaan Oktay, Björn Ommer </div>
                                <div>
                                        NeurIPS 2022.

                                        <a href="https://arxiv.org/abs/2204.11824"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/lucidrains/retrieval-augmented-ddpm"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-04-25</div>
                            </div>
                            <div class="paper-date">2022-04-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Hierarchical Text-Conditional Image Generation with CLIP Latents  </div>
                                <div> Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark Chen </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2204.06125"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/lucidrains/DALLE2-pytorch"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-04-13</div>
                            </div>
                            <div class="paper-date">2022-04-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> KNN-Diffusion: Image Generation via Large-Scale Retrieval  </div>
                                <div> Oron Ashual, Shelly Sheynin, Adam Polyak, Uriel Singer, Oran Gafni, Eliya Nachmani, Yaniv Taigman </div>
                                <div>
                                        ICLR 2023.

                                        <a href="https://arxiv.org/abs/2204.02849"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-04-06</div>
                            </div>
                            <div class="paper-date">2022-04-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> High-Resolution Image Synthesis with Latent Diffusion Models  </div>
                                <div> Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer </div>
                                <div>
                                        CVPR 2022.

                                        <a href="https://arxiv.org/abs/2112.10752"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/CompVis/latent-diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-12-20</div>
                            </div>
                            <div class="paper-date">2021-12-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Tackling the Generative Learning Trilemma with Denoising Diffusion GANs  </div>
                                <div> Zhisheng Xiao, Karsten Kreis, Arash Vahdat </div>
                                <div>
                                        ICLR 2022 (Spotlight).

                                        <a href="https://arxiv.org/abs/2112.07804"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://nvlabs.github.io/denoising-diffusion-gan"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-12-15</div>
                            </div>
                            <div class="paper-date">2021-12-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> More Control for Free! Image Synthesis with Semantic Diffusion Guidance  </div>
                                <div> Xihui Liu, Dong Huk Park, Samaneh Azadi, Gong Zhang, Arman Chopikyan, Yuxiao Hu, Humphrey Shi, Anna Rohrbach, Trevor Darrell </div>
                                <div>
                                        WACV 2021.

                                        <a href="https://arxiv.org/abs/2112.05744"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://xh-liu.github.io/sdg/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-12-10</div>
                            </div>
                            <div class="paper-date">2021-12-10</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Blended Diffusion for Text-driven Editing of Natural Images  </div>
                                <div> Omri Avrahami, Dani Lischinski, Ohad Fried </div>
                                <div>
                                        CVPR 2022.

                                        <a href="https://arxiv.org/abs/2111.14818"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://omriavrahami.com/blended-diffusion-page/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/omriav/blended-diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-11-29</div>
                            </div>
                            <div class="paper-date">2021-11-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Vector Quantized Diffusion Model for Text-to-Image Synthesis  </div>
                                <div> Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, Bo Zhang, Dongdong Chen, Lu Yuan, Baining Guo </div>
                                <div>
                                        CVPR 2022.

                                        <a href="https://arxiv.org/abs/2111.14822"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/microsoft/VQ-Diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-11-29</div>
                            </div>
                            <div class="paper-date">2021-11-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffusionCLIP: Text-guided Image Manipulation Using Diffusion Models  </div>
                                <div> Gwanghyun Kim, Jong Chul Ye </div>
                                <div>
                                        CVPR 2022.

                                        <a href="https://arxiv.org/abs/2110.02711"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/gwang-kim/DiffusionCLIP"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-10-06</div>
                            </div>
                            <div class="paper-date">2021-10-06</div>
                        </li>
                </ol>
                <div class="mt-3 mb-3 text-center text-secondary">Counts - 417 &nbsp <a href="#">Back to
                    top</a></div>
            </main>

        </div>
    </div>
</div>


<!-- JavaScript Bundle with Popper -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-pprn3073KE6tl6bjs2QrFaJGz5/SUsLqktiwsUTF55Jfv3qYSDhgCecCxMW52nD2"
        crossorigin="anonymous"></script>
<script src="sidebars.js"></script>
<script>
    function toggle_counter() {
        const elements = document.getElementsByClassName("counter");
        for (let i = 0; i < elements.length; i++) {
            if (elements[i].style.display === "none") {
                console.log(elements[i].style.display)
                elements[i].style.display = "block";
            } else {
                elements[i].style.display = "none";
            }
        }
    }
</script>
</body>
</html>