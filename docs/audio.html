<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <meta name="description" content=""/>
    <meta name="author"
          content="Zeqiang Lai"
    />
    <title>Awesome Diffusion</title>

    <!-- CSS only -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-0evHe/X+R7YkIZDRvuzKMRqM+OrBnVFBL6DOitfPri4tjfHxaWutUpFmBp4vmVor" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="style.css" rel="stylesheet"/>
    <link href="sidebars.css" rel="stylesheet"/>
</head>
<body>
<nav class="navbar navbar-expand-md fixed-top bg-light">
    <div class="container">
        <button
                class="navbar-toggler float-left"
                type="button"
                data-bs-toggle="collapse"
                data-bs-target="#bd-docs-nav"
                aria-controls="bd-docs-nav"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <a class="navbar-brand" href="#">Awesome Diffusion Models</a>
        <button
                class="navbar-toggler"
                type="button"
                data-bs-toggle="collapse"
                data-bs-target="#navbarCollapse"
                aria-controls="navbarCollapse"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav me-auto mb-2 mb-md-0">
                <li class="nav-item">
                        <a class="nav-link active" aria-current="page" href="index.html">Paper</a>
                </li>
                <li class="nav-item">
                        <a class="nav-link" href="resource.html">Resources</a>
                </li>
            </ul>
            <ul class="navbar-nav flex-row flex-wrap ms-md-auto">
                <li class="nav-item col-6 col-lg-auto">
                    <a class="nav-link py-2 px-0 px-lg-2" href="#" onclick="toggle_counter()"
                       rel="noopener">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                             class="bi bi-disc navbar-nav-svg" viewBox="0 0 16 16">
                            <path d="M8 15A7 7 0 1 1 8 1a7 7 0 0 1 0 14zm0 1A8 8 0 1 0 8 0a8 8 0 0 0 0 16z"/>
                            <path d="M10 8a2 2 0 1 1-4 0 2 2 0 0 1 4 0zM8 4a4 4 0 0 0-4 4 .5.5 0 0 1-1 0 5 5 0 0 1 5-5 .5.5 0 0 1 0 1zm4.5 3.5a.5.5 0 0 1 .5.5 5 5 0 0 1-5 5 .5.5 0 0 1 0-1 4 4 0 0 0 4-4 .5.5 0 0 1 .5-.5z"/>
                        </svg>
                        <small class="d-lg-none ms-2">Toggle Counter</small>
                    </a>
                </li>
                <li class="nav-item col-6 col-lg-auto">
                    <a class="nav-link py-2 px-0 px-lg-2" href="https://github.com/heejkoo/Awesome-Diffusion-Models" target="_blank" rel="noopener">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" class="navbar-nav-svg"
                             viewBox="0 0 512 499.36" role="img"><title>GitHub</title>
                            <path fill="currentColor" fill-rule="evenodd"
                                  d="M256 0C114.64 0 0 114.61 0 256c0 113.09 73.34 209 175.08 242.9 12.8 2.35 17.47-5.56 17.47-12.34 0-6.08-.22-22.18-.35-43.54-71.2 15.49-86.2-34.34-86.2-34.34-11.64-29.57-28.42-37.45-28.42-37.45-23.27-15.84 1.73-15.55 1.73-15.55 25.69 1.81 39.21 26.38 39.21 26.38 22.84 39.12 59.92 27.82 74.5 21.27 2.33-16.54 8.94-27.82 16.25-34.22-56.84-6.43-116.6-28.43-116.6-126.49 0-27.95 10-50.8 26.35-68.69-2.63-6.48-11.42-32.5 2.51-67.75 0 0 21.49-6.88 70.4 26.24a242.65 242.65 0 0 1 128.18 0c48.87-33.13 70.33-26.24 70.33-26.24 14 35.25 5.18 61.27 2.55 67.75 16.41 17.9 26.31 40.75 26.31 68.69 0 98.35-59.85 120-116.88 126.32 9.19 7.9 17.38 23.53 17.38 47.41 0 34.22-.31 61.83-.31 70.23 0 6.85 4.61 14.81 17.6 12.31C438.72 464.97 512 369.08 512 256.02 512 114.62 397.37 0 256 0z"></path>
                        </svg>
                        <small class="d-lg-none ms-2">GitHub</small>
                    </a>
                </li>
            </ul>
        </div>
    </div>
</nav>


<div class="container-fluid">
    <div class="container">
        <div class="row">
            <div class="col-md-3 bd-sidebar" style="padding-right: 2rem">
                <!-- <nav class="collapse show" id="bd-docs-nav"> -->
                    <ol class="list-unstyled">
                            <li class="mb-1">
                                <div class="d-flex justify-content-between align-items-center">
                                    <a class="btn rounded border-0 collapsed" href="vision.html">
                                        <strong>Vision</strong>
                                    </a>
                                    <span class="badge rounded-pill text-bg-secondary counter"> 1543 </span>
                                </div>
                                <div class="collapse show" id="home-collapse">
                                    <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Generation
                                                    </a>
                                                    <div class="counter">295</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_classification.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Classification
                                                    </a>
                                                    <div class="counter">31</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_segmentation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Segmentation
                                                    </a>
                                                    <div class="counter">49</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_image_translation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Image Translation
                                                    </a>
                                                    <div class="counter">46</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_inverse_problems.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Inverse Problems
                                                    </a>
                                                    <div class="counter">163</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_medical_imaging.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Medical Imaging
                                                    </a>
                                                    <div class="counter">133</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_multi-modal_learning.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Multi-modal Learning
                                                    </a>
                                                    <div class="counter">417</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_3d_vision.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >3D Vision
                                                    </a>
                                                    <div class="counter">183</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_adversarial_attack.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Adversarial Attack
                                                    </a>
                                                    <div class="counter">45</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_miscellany.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Miscellany
                                                    </a>
                                                    <div class="counter">181</div>
                                                </div>
                                            </li>
                                    </ul>
                                </div>
                            </li>
                            <li class="mb-1">
                                <div class="d-flex justify-content-between align-items-center">
                                    <a class="btn rounded border-0 collapsed" href="audio.html">
                                        <strong>Audio</strong>
                                    </a>
                                    <span class="badge rounded-pill text-bg-secondary counter"> 118 </span>
                                </div>
                                <div class="collapse show" id="home-collapse">
                                    <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Generation
                                                    </a>
                                                    <div class="counter">34</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_conversion.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Conversion
                                                    </a>
                                                    <div class="counter">4</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_enhancement.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Enhancement
                                                    </a>
                                                    <div class="counter">25</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_separation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Separation
                                                    </a>
                                                    <div class="counter">5</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_text-to-speech.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Text-to-Speech
                                                    </a>
                                                    <div class="counter">40</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_miscellany.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Miscellany
                                                    </a>
                                                    <div class="counter">10</div>
                                                </div>
                                            </li>
                                    </ul>
                                </div>
                            </li>
                            <li class="mb-1">
                                <div class="d-flex justify-content-between align-items-center">
                                    <a class="btn rounded border-0 collapsed" href="tabular_and_time_series.html">
                                        <strong>Tabular and Time Series</strong>
                                    </a>
                                    <span class="badge rounded-pill text-bg-secondary counter"> 38 </span>
                                </div>
                                <div class="collapse show" id="home-collapse">
                                    <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="tabular_and_time_series_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Generation
                                                    </a>
                                                    <div class="counter">10</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="tabular_and_time_series_forecasting.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Forecasting
                                                    </a>
                                                    <div class="counter">12</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="tabular_and_time_series_imputation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Imputation
                                                    </a>
                                                    <div class="counter">6</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="tabular_and_time_series_miscellany.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Miscellany
                                                    </a>
                                                    <div class="counter">10</div>
                                                </div>
                                            </li>
                                    </ul>
                                </div>
                            </li>
                            <li class="mb-1">
                                <div class="d-flex justify-content-between align-items-center">
                                    <a class="btn rounded border-0 collapsed" href="graph.html">
                                        <strong>Graph</strong>
                                    </a>
                                    <span class="badge rounded-pill text-bg-secondary counter"> 70 </span>
                                </div>
                                <div class="collapse show" id="home-collapse">
                                    <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="graph_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Generation
                                                    </a>
                                                    <div class="counter">20</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="graph_molecular_and_material_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Molecular and Material Generation
                                                    </a>
                                                    <div class="counter">50</div>
                                                </div>
                                            </li>
                                    </ul>
                                </div>
                            </li>
                    </ul>

                <!-- </nav> -->
            </div>
            <main class='col-md-9 bd-content' role="main">
                <ol class="list-group list-group-numbered">
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> UnitSpeech: Speaker-adaptive Speech Synthesis with Untranscribed Data  </div>
                                <div> Heeseung Kim, Sungwon Kim, Jiheum Yeom, Sungroh Yoon </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.16083"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-28</div>
                            </div>
                            <div class="paper-date">2023-06-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion Posterior Sampling for Informed Single-Channel Dereverberation  </div>
                                <div> Jean-Marie Lemercier, Simon Welker, Timo Gerkmann </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.12286"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-21</div>
                            </div>
                            <div class="paper-date">2023-06-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-Driven Foley Sound Generation With Latent Diffusion Model  </div>
                                <div> Yi Yuan, Haohe Liu, Xubo Liu, Xiyuan Kang, Peipei Wu, Mark D. Plumbley, Wenwu Wang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.10359"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-17</div>
                            </div>
                            <div class="paper-date">2023-06-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models  </div>
                                <div> Hao-Wen Dong, Xiaoyu Liu, Jordi Pons, Gautam Bhattacharya, Santiago Pascual, Joan Serrà, Taylor Berg-Kirkpatrick, Julian McAuley </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.09635"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-16</div>
                            </div>
                            <div class="paper-date">2023-06-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis  </div>
                                <div> Shivam Mehta, Siyang Wang, Simon Alexanderson, Jonas Beskow, Éva Székely, Gustav Eje Henter </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.09417"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-15</div>
                            </div>
                            <div class="paper-date">2023-06-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Variance-Preserving-Based Interpolation Diffusion Models for Speech Enhancement  </div>
                                <div> Zilu Guo, Jun Du, Chin-Hui Lee, Yu Gao, Wenbin Zhang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.08527"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-14</div>
                            </div>
                            <div class="paper-date">2023-06-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models  </div>
                                <div> Yinghao Aaron Li, Cong Han, Vinay S. Raghavan, Gavin Mischler, Nima Mesgarani </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.07691"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-13</div>
                            </div>
                            <div class="paper-date">2023-06-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> UniCATS: A Unified Context-Aware Text-to-Speech Framework with Contextual VQ-Diffusion and Vocoding  </div>
                                <div> Chenpeng Du, Yiwei Guo, Feiyu Shen, Zhijun Liu, Zheng Liang, Xie Chen, Shuai Wang, Hui Zhang, Kai Yu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.07547"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-13</div>
                            </div>
                            <div class="paper-date">2023-06-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> HiddenSinger: High-Quality Singing Voice Synthesis via Neural Audio Codec and Latent Diffusion Models  </div>
                                <div> Ji-Sang Hwang, Sang-Hoon Lee, Seong-Whan Lee </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.06814"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-12</div>
                            </div>
                            <div class="paper-date">2023-06-12</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Boosting Fast and High-Quality Speech Synthesis with Linear Diffusion  </div>
                                <div> Haogeng Liu, Tao Wang, Jie Cao, Ran He, Jianhua Tao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.05708"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-09</div>
                            </div>
                            <div class="paper-date">2023-06-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Interpretable Style Transfer for Text-to-Speech with ControlVAE and Diffusion Bridge  </div>
                                <div> Wenhao Guan, Tao Li, Yishuang Li, Hukai Huang, Qingyang Hong, Lin Li </div>
                                <div>
                                        Interspeech 2023.

                                        <a href="https://arxiv.org/abs/2306.04301"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-07</div>
                            </div>
                            <div class="paper-date">2023-06-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive Bias  </div>
                                <div> Ziyue Jiang, Yi Ren, Zhenhui Ye, Jinglin Liu, Chen Zhang, Qian Yang, Shengpeng Ji, Rongjie Huang, Chunfeng Wang, Xiang Yin, Zejun Ma, Zhou Zhao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.03509"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://mega-tts.github.io/demo-page/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-06</div>
                            </div>
                            <div class="paper-date">2023-06-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Zero-Shot Blind Audio Bandwidth Extension  </div>
                                <div> Eloi Moliner, Filip Elvander, Vesa Välimäki </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.01433"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-02</div>
                            </div>
                            <div class="paper-date">2023-06-02</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> UnDiff: Unsupervised Voice Restoration with Unconditional Diffusion Model  </div>
                                <div> Anastasiia Iashchenko, Pavel Andreev, Ivan Shchekotov, Nicholas Babaev, Dmitry Vetrov </div>
                                <div>
                                        Interspeech 2023.

                                        <a href="https://arxiv.org/abs/2306.00721"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> EmoMix: Emotion Mixing via Diffusion Models for Emotional Speech Synthesis  </div>
                                <div> Haobin Tang, Xulong Zhang, Jianzong Wang, Ning Cheng, Jing Xiao </div>
                                <div>
                                        InterSpeech 2023.

                                        <a href="https://arxiv.org/abs/2306.00648"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-01</div>
                            </div>
                            <div class="paper-date">2023-06-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Make-An-Audio 2: Temporal-Enhanced Text-to-Audio Generation  </div>
                                <div> Jiawei Huang, Yi Ren, Rongjie Huang, Dongchao Yang, Zhenhui Ye, Chen Zhang, Jinglin Liu, Xiang Yin, Zejun Ma, Zhou Zhao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.18474"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-29</div>
                            </div>
                            <div class="paper-date">2023-05-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diverse and Expressive Speech Prosody Prediction with Denoising Diffusion Probabilistic Model  </div>
                                <div> Xiang Li, Songxiang Liu, Max W. Y. Lam, Zhiyong Wu, Chao Weng, Helen Meng </div>
                                <div>
                                        Interspeech 2023.

                                        <a href="https://arxiv.org/abs/2305.16749"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-26</div>
                            </div>
                            <div class="paper-date">2023-05-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DDDM-VC: Decoupled Denoising Diffusion Models with Disentangled Representation and Prior Mixup for Verified Robust Voice Conversion  </div>
                                <div> Ha-Yeong Choi, Sang-Hoon Lee, Seong-Whan Lee </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.15816"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://hayeong0.github.io/DDDM-VC-demo/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Efficient Neural Music Generation  </div>
                                <div> Max W. Y. Lam, Qiao Tian, Tang Li, Zongyu Yin, Siyuan Feng, Ming Tu, Yuliang Ji, Rui Xia, Mingbo Ma, Xuchen Song, Jitong Chen, Yuping Wang, Yuxuan Wang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.15719"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://efficient-melody.github.io/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-25</div>
                            </div>
                            <div class="paper-date">2023-05-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion-Based Audio Inpainting  </div>
                                <div> Eloi Moliner, Vesa Välimäki </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.15266"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-24</div>
                            </div>
                            <div class="paper-date">2023-05-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> FluentSpeech: Stutter-Oriented Automatic Speech Editing with Context-Aware Diffusion Models  </div>
                                <div> Ziyue Jiang, Qian Yang, Jialong Zuo, Zhenhui Ye, Rongjie Huang, Yi Ren, Zhou Zhao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13612"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/Zain-Jiang/Speech-Editing-Toolkit"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-23</div>
                            </div>
                            <div class="paper-date">2023-05-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ZET-Speech: Zero-shot adaptive Emotion-controllable Text-to-Speech Synthesis with Diffusion and Style-based Models  </div>
                                <div> Minki Kang, Wooseok Han, Sung Ju Hwang, Eunho Yang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13831"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-23</div>
                            </div>
                            <div class="paper-date">2023-05-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SE-Bridge: Speech Enhancement with Consistent Brownian Bridge  </div>
                                <div> Zhibin Qiu, Mengfan Fu, Fuchun Sun, Gulila Altenbek, Hao Huang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13796"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-23</div>
                            </div>
                            <div class="paper-date">2023-05-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> U-DiT TTS: U-Diffusion Vision Transformer for Text-to-Speech  </div>
                                <div> Xin Jing, Yi Chang, Zijiang Yang, Jiangjian Xie, Andreas Triantafyllopoulos, Bjoern W. Schuller </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13195"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://eihw.github.io/u-dit-tts/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffAVA: Personalized Text-to-Audio Generation with Visual Alignment  </div>
                                <div> Shentong Mo, Jing Shi, Yapeng Tian </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.12903"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ViT-TTS: Visual Text-to-Speech with Scalable Diffusion Transformer  </div>
                                <div> Huadai Liu, Rongjie Huang, Xuan Lin, Wenqiang Xu, Maozong Zheng, Hong Chen, Jinzheng He, Zhou Zhao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.12708"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://vit-tts.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Duplex Diffusion Models Improve Speech-to-Speech Translation  </div>
                                <div> Xianchao Wu </div>
                                <div>
                                        ACL 2023.

                                        <a href="https://arxiv.org/abs/2305.12628"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> A Preliminary Study on Augmenting Speech Emotion Recognition using a Diffusion Model  </div>
                                <div> Ibrahim Malik, Siddique Latif, Raja Jurdak, Björn Schuller </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.11413"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-19</div>
                            </div>
                            <div class="paper-date">2023-05-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> RMSSinger: Realistic-Music-Score based Singing Voice Synthesis  </div>
                                <div> Jinzheng He, Jinglin Liu, Zhenhui Ye, Rongjie Huang, Chenye Cui, Huadai Liu, Zhou Zhao </div>
                                <div>
                                        ACL 2023.

                                        <a href="https://arxiv.org/abs/2305.10686"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://rmssinger.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-18</div>
                            </div>
                            <div class="paper-date">2023-05-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion-Based Speech Enhancement with Joint Generative and Predictive Decoders  </div>
                                <div> Hao Shi, Kazuki Shimada, Masato Hirano, Takashi Shibuya, Yuichiro Koyama, Zhi Zhong, Shusuke Takahashi, Tatsuya Kawahara, Yuki Mitsufuji </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.10734"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-18</div>
                            </div>
                            <div class="paper-date">2023-05-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency Model  </div>
                                <div> Zhen Ye, Wei Xue, Xu Tan, Jie Chen, Qifeng Liu, Yike Guo </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.06908"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://comospeech.github.io/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-11</div>
                            </div>
                            <div class="paper-date">2023-05-11</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion-based Signal Refiner for Speech Separation  </div>
                                <div> Masato Hirano, Kazuki Shimada, Yuichiro Koyama, Shusuke Takahashi, Yuki Mitsufuji </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.05857"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-10</div>
                            </div>
                            <div class="paper-date">2023-05-10</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model  </div>
                                <div> Deepanway Ghosal, Navonil Majumder, Ambuj Mehrish, Soujanya Poria </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.13731"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://tango-web.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/declare-lab/tango"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-24</div>
                            </div>
                            <div class="paper-date">2023-04-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffVoice: Text-to-Speech with Latent Diffusion  </div>
                                <div> Zhijun Liu, Yiwei Guo, Kai Yu </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2304.11750"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-23</div>
                            </div>
                            <div class="paper-date">2023-04-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> AUDIT: Audio Editing by Following Instructions with Latent Diffusion Models  </div>
                                <div> Yuancheng Wang, Zeqian Ju, Xu Tan, Lei He, Zhizheng Wu, Jiang Bian, Sheng Zhao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.00830"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://audit-demo.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-03</div>
                            </div>
                            <div class="paper-date">2023-04-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Data Augmentation for Environmental Sound Classification Using Diffusion Probabilistic Model with Top-k Selection Discriminator  </div>
                                <div> Yunhao Chen, Yunjie Zhu, Zihui Yan, Jianlu Shen, Zhen Ren, Yifan Huang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.15161"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/JNAIC/DPMs-for-Audio-Data-Augmentation"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-27</div>
                            </div>
                            <div class="paper-date">2023-03-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Enhancing Unsupervised Speech Recognition with Diffusion GANs  </div>
                                <div> Xianchao Wu </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2303.13559"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-23</div>
                            </div>
                            <div class="paper-date">2023-03-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Speech Signal Improvement Using Causal Generative Diffusion Models  </div>
                                <div> Julius Richter, Simon Welker, Jean-Marie Lemercier, Bunlong Lay, Tal Peer, Timo Gerkmann </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2303.08674"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-15</div>
                            </div>
                            <div class="paper-date">2023-03-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Generating symbolic music using diffusion models  </div>
                                <div> Lilac Atassi </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.08385"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-15</div>
                            </div>
                            <div class="paper-date">2023-03-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffuseRoll: Multi-track multi-category music generation based on diffusion model  </div>
                                <div> Hongfei Wang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.07794"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-14</div>
                            </div>
                            <div class="paper-date">2023-03-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> An investigation into the adaptability of a diffusion-based TTS model  </div>
                                <div> Haolin Chen, Philip N. Garner </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.01849"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-03</div>
                            </div>
                            <div class="paper-date">2023-03-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Defending against Adversarial Audio via Diffusion Model  </div>
                                <div> Shutong Wu, Jiongxiao Wang, Wei Ping, Weili Nie, Chaowei Xiao </div>
                                <div>
                                        ICLR 2023.

                                        <a href="https://arxiv.org/abs/2303.01507"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/cychomatica/AudioPure"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-02</div>
                            </div>
                            <div class="paper-date">2023-03-02</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Reducing the Prior Mismatch of Stochastic Differential Equations for Diffusion-based Speech Enhancement  </div>
                                <div> Bunlong Lay, Simon Welker, Julius Richter, Timo Gerkmann </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.14748"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-28</div>
                            </div>
                            <div class="paper-date">2023-02-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Imaginary Voice: Face-styled Diffusion Model for Text-to-Speech  </div>
                                <div> Jiyoung Lee, Joon Son Chung, Soo-Whan Chung </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2302.13700"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-27</div>
                            </div>
                            <div class="paper-date">2023-02-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Metric-oriented Speech Enhancement using Diffusion Probabilistic Model  </div>
                                <div> Chen Chen, Yuchen Hu, Weiwei Weng, Eng Siong Chng </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.11989"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-23</div>
                            </div>
                            <div class="paper-date">2023-02-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ERNIE-Music: Text-to-Waveform Music Generation with Diffusion Models  </div>
                                <div> Pengfei Zhu, Chao Pang, Shuohuan Wang, Yekun Chai, Yu Sun, Hao Tian, Hua Wu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.04456"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-09</div>
                            </div>
                            <div class="paper-date">2023-02-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Noise2Music: Text-conditioned Music Generation with Diffusion Models  </div>
                                <div> Qingqing Huang, Daniel S. Park, Tao Wang, Timo I. Denk, Andy Ly, Nanxin Chen, Zhengdong Zhang, Zhishuai Zhang, Jiahui Yu, Christian Frank, Jesse Engel, Quoc V. Le, William Chan, Wei Han </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.03917"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://google-research.github.io/noise2music/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-08</div>
                            </div>
                            <div class="paper-date">2023-02-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Multi-Source Diffusion Models for Simultaneous Music Generation and Separation  </div>
                                <div> Giorgio Mariani, Irene Tallini, Emilian Postolache, Michele Mancusi, Luca Cosmo, Emanuele Rodolà </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.02257"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://gladia-research-group.github.io/multi-source-diffusion-models/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-04</div>
                            </div>
                            <div class="paper-date">2023-02-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Multi-Source Diffusion Models for Simultaneous Music Generation and Separation  </div>
                                <div> Giorgio Mariani, Irene Tallini, Emilian Postolache, Michele Mancusi, Luca Cosmo, Emanuele Rodolà </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.02257"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://gladia-research-group.github.io/multi-source-diffusion-models/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-04</div>
                            </div>
                            <div class="paper-date">2023-02-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> InstructTTS: Modelling Expressive TTS in Discrete Latent Space with Natural Language Style Prompt  </div>
                                <div> Dongchao Yang, Songxiang Liu, Rongjie Huang, Guangzhi Lei, Chao Weng, Helen Meng, Dong Yu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.13662"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="http://dongchaoyang.top/InstructTTS/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-31</div>
                            </div>
                            <div class="paper-date">2023-01-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models  </div>
                                <div> Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, Zhou Zhao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.12661"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://text-to-audio.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-30</div>
                            </div>
                            <div class="paper-date">2023-01-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> AudioLDM: Text-to-Audio Generation with Latent Diffusion Models  </div>
                                <div> Haohe Liu, Zehua Chen, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, Mark D. Plumbley </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.12503"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://audioldm.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/haoheliu/AudioLDM"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-29</div>
                            </div>
                            <div class="paper-date">2023-01-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Moûsai: Text-to-Music Generation with Long-Context Latent Diffusion  </div>
                                <div> Flavio Schneider, Zhijing Jin, Bernhard Schölkopf </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.11757"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://anonymous0.notion.site/anonymous0/Mo-sai-Text-to-Audio-with-Long-Context-Latent-Diffusion-b43dbc71caf94b5898f9e8de714ab5dc"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/archinetai/audio-diffusion-pytorch"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-27</div>
                            </div>
                            <div class="paper-date">2023-01-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Separate And Diffuse: Using a Pretrained Diffusion Model for Improving Source Separation  </div>
                                <div> Shahar Lutati, Eliya Nachmani, Lior Wolf </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.10752"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-25</div>
                            </div>
                            <div class="paper-date">2023-01-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ResGrad: Residual Denoising Diffusion Probabilistic Models for Text to Speech  </div>
                                <div> Zehua Chen, Yihan Wu, Yichong Leng, Jiawei Chen, Haohe Liu, Xu Tan, Yang Cui, Ke Wang, Lei He, Sheng Zhao, Jiang Bian, Danilo Mandic </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.14518"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://resgrad1.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-30</div>
                            </div>
                            <div class="paper-date">2022-12-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> StoRM: A Diffusion-based Stochastic Regeneration Model for Speech Enhancement and Dereverberation  </div>
                                <div> Jean-Marie Lemercier, Julius Richter, Simon Welker, Timo Gerkmann </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2212.11851"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-22</div>
                            </div>
                            <div class="paper-date">2022-12-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation  </div>
                                <div> Ludan Ruan, Yiyang Ma, Huan Yang, Huiguo He, Bei Liu, Jianlong Fu, Nicholas Jing Yuan, Qin Jin, Baining Guo </div>
                                <div>
                                        CVPR 2023.

                                        <a href="https://arxiv.org/abs/2212.09478"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/researchmm/MM-Diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-19</div>
                            </div>
                            <div class="paper-date">2022-12-19</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-to-speech synthesis based on latent variable conversion using diffusion probabilistic model and variational autoencoder  </div>
                                <div> Yusuke Yasuda, Tomoki Toda </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2212.08329"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-16</div>
                            </div>
                            <div class="paper-date">2022-12-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Any-speaker Adaptive Text-To-Speech Synthesis with Diffusion Models  </div>
                                <div> Minki Kang, Dongchan Min, Sung Ju Hwang </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2211.09383"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://nardien.github.io/grad-stylespeech-demo/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-17</div>
                            </div>
                            <div class="paper-date">2022-11-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> EmoDiff: Intensity Controllable Emotional Text-to-Speech with Soft-Label Guidance  </div>
                                <div> Yiwei Guo, Chenpeng Du, Xie Chen, Kai Yu </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2211.09496"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://cantabile-kwok.github.io/EmoDiff-intensity-ctrl/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-17</div>
                            </div>
                            <div class="paper-date">2022-11-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Unsupervised vocal dereverberation with diffusion-based generative models  </div>
                                <div> Koichi Saito, Naoki Murata, Toshimitsu Uesaka, Chieh-Hsin Lai, Yuhta Takida, Takao Fukui, Yuki Mitsufuji </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2211.04124"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-08</div>
                            </div>
                            <div class="paper-date">2022-11-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffPhase: Generative Diffusion-based STFT Phase Retrieval  </div>
                                <div> Tal Peer, Simon Welker, Timo Gerkmann </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2211.04332"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-08</div>
                            </div>
                            <div class="paper-date">2022-11-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> NoreSpeech: Knowledge Distillation based Conditional Diffusion Model for Noise-robust Expressive TTS  </div>
                                <div> Dongchao Yang, Songxiang Liu, Jianwei Yu, Helin Wang, Chao Weng, Yuexian Zou </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2211.02448"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-04</div>
                            </div>
                            <div class="paper-date">2022-11-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Cold Diffusion for Speech Enhancement  </div>
                                <div> Hao Yen, François G. Germain, Gordon Wichern, Jonathan Le Roux </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2211.02527"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-04</div>
                            </div>
                            <div class="paper-date">2022-11-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Analysing Diffusion-based Generative Approaches versus Discriminative Approaches for Speech Restoration  </div>
                                <div> Jean-Marie Lemercier, Julius Richter, Simon Welker, Timo Gerkmann </div>
                                <div>
                                        Interspeech 2022.

                                        <a href="https://arxiv.org/abs/2211.02397"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://www.inf.uni-hamburg.de/en/inst/ab/sp/publications/sgmse-multitask.html"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/sp-uhh/sgmse"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-04</div>
                            </div>
                            <div class="paper-date">2022-11-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SDMuse: Stochastic Differential Music Editing and Generation via Hybrid Representation  </div>
                                <div> Chen Zhang, Yi Ren, Kejun Zhang, Shuicheng Yan </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2211.00222"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://sdmuse.github.io/posts/sdmuse/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-01</div>
                            </div>
                            <div class="paper-date">2022-11-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion-based Generative Speech Source Separation  </div>
                                <div> Robin Scheibler, Youna Ji, Soo-Whan Chung, Jaeuk Byun, Soyeon Choe, Min-Seok Choi </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2210.17327"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-31</div>
                            </div>
                            <div class="paper-date">2022-10-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SRTNet: Time Domain Speech Enhancement Via Stochastic Refinement  </div>
                                <div> Zhibin Qiu, Mengfan Fu, Yinfeng Yu, LiLi Yin, Fuchun Sun, Hao Huang </div>
                                <div>
                                        ICASSP 2022.

                                        <a href="https://arxiv.org/abs/2210.16805"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/zhibinQiu/SRTNet"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-30</div>
                            </div>
                            <div class="paper-date">2022-10-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> A Versatile Diffusion-based Generative Refiner for Speech Enhancement  </div>
                                <div> Ryosuke Sawata, Naoki Murata, Yuhta Takida, Toshimitsu Uesaka, Takashi Shibuya, Shusuke Takahashi, Yuki Mitsufuji </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2210.17287"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-27</div>
                            </div>
                            <div class="paper-date">2022-10-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Conditioning and Sampling in Variational Diffusion Models for Speech Super-resolution  </div>
                                <div> Chin-Yun Yu, Sung-Lin Yeh, György Fazekas, Hao Tang </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2210.15793"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://yoyololicon.github.io/diffwave-sr/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/yoyololicon/diffwave-sr"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-27</div>
                            </div>
                            <div class="paper-date">2022-10-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Solving Audio Inverse Problems with a Diffusion Model  </div>
                                <div> Eloi Moliner, Jaakko Lehtinen, Vesa Välimäki </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2210.15228"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-27</div>
                            </div>
                            <div class="paper-date">2022-10-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Full-band General Audio Synthesis with Score-based Diffusion  </div>
                                <div> Santiago Pascual, Gautam Bhattacharya, Chunghsin Yeh, Jordi Pons, Joan Serrà </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.14661"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-26</div>
                            </div>
                            <div class="paper-date">2022-10-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> TransFusion: Transcribing Speech with Multinomial Diffusion  </div>
                                <div> Matthew Baas, Kevin Eloff, Herman Kamper </div>
                                <div>
                                        SACAIR 2022.

                                        <a href="https://arxiv.org/abs/2210.07677"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/RF5/transfusion-asr"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-14</div>
                            </div>
                            <div class="paper-date">2022-10-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Hierarchical Diffusion Models for Singing Voice Neural Vocoder  </div>
                                <div> Naoya Takahashi, Mayank Kumar, Singh, Yuki Mitsufuji </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2210.07508"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-14</div>
                            </div>
                            <div class="paper-date">2022-10-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> WaveFit: An Iterative and Non-autoregressive Neural Vocoder based on Fixed-Point Iteration  </div>
                                <div> Yuma Koizumi, Kohei Yatabe, Heiga Zen, Michiel Bacchiani </div>
                                <div>
                                        IEEE SLT 2023.

                                        <a href="https://arxiv.org/abs/2210.01029"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://google.github.io/df-conformer/wavefit/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-03</div>
                            </div>
                            <div class="paper-date">2022-10-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Mandarin Singing Voice Synthesis with Denoising Diffusion Probabilistic Wasserstein GAN  </div>
                                <div> Yin-Ping Cho, Yu Tsao, Hsin-Min Wang, Yi-Wen Liu </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2209.10446"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://yinping-cho.github.io/diffwgansvs.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-09-21</div>
                            </div>
                            <div class="paper-date">2022-09-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Instrument Separation of Symbolic Music by Explicitly Guided Diffusion Model  </div>
                                <div> Sangjun Han, Hyeongrae Ihm, DaeHan Ahn, Woohyung Lim </div>
                                <div>
                                        NeurIPS Workshop 2022.

                                        <a href="https://arxiv.org/abs/2209.02696"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-09-05</div>
                            </div>
                            <div class="paper-date">2022-09-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Speech Enhancement and Dereverberation with Diffusion-based Generative Models  </div>
                                <div> Julius Richter, Simon Welker, Jean-Marie Lemercier, Bunlong Lay, Timo Gerkmann </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2208.05830"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://www.inf.uni-hamburg.de/en/inst/ab/sp/publications/sgmse"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/sp-uhh/sgmse"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-08-11</div>
                            </div>
                            <div class="paper-date">2022-08-11</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DDSP-based Singing Vocoders: A New Subtractive-based Synthesizer and A Comprehensive Evaluation  </div>
                                <div> Da-Yi Wu, Wen-Yi Hsiao, Fu-Rong Yang, Oscar Friedman, Warren Jackson, Scott Bruzenak, Yi-Wen Liu, Yi-Hsuan Yang </div>
                                <div>
                                        ISMIR 2022.

                                        <a href="https://arxiv.org/abs/2208.04756"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/YatingMusic/ddsp-singing-vocoders/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-08-09</div>
                            </div>
                            <div class="paper-date">2022-08-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffsound: Discrete Diffusion Model for Text-to-sound Generation  </div>
                                <div> Dongchao Yang, Jianwei Yu, Helin Wang, Wen Wang, Chao Weng, Yuexian Zou, Dong Yu </div>
                                <div>
                                        TASLP 2022.

                                        <a href="https://arxiv.org/abs/2207.09983"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="http://dongchaoyang.top/text-to-sound-synthesis-demo/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-07-20</div>
                            </div>
                            <div class="paper-date">2022-07-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ProDiff: Progressive Fast Diffusion Model For High-Quality Text-to-Speech  </div>
                                <div> Rongjie Huang, Zhou Zhao, Huadai Liu, Jinglin Liu, Chenye Cui, Yi Ren </div>
                                <div>
                                        ACM Multimedia 2022.

                                        <a href="https://arxiv.org/abs/2207.06389"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://prodiff.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-07-13</div>
                            </div>
                            <div class="paper-date">2022-07-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates  </div>
                                <div> Seungu Han, Junhyeok Lee </div>
                                <div>
                                        Interspeech 2022.

                                        <a href="https://arxiv.org/abs/2206.08545"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://mindslab-ai.github.io/nuwave2/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-06-17</div>
                            </div>
                            <div class="paper-date">2022-06-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> CARD: Classification and Regression Diffusion Models  </div>
                                <div> Xizewen Han, Huangjie Zheng, Mingyuan Zhou </div>
                                <div>
                                        NeurIPS 2022.

                                        <a href="https://arxiv.org/abs/2206.07275"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-06-15</div>
                            </div>
                            <div class="paper-date">2022-06-15</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Adversarial Audio Synthesis with Complex-valued Polynomial Networks  </div>
                                <div> Yongtao Wu, Grigorios G Chrysos, Volkan Cevher </div>
                                <div>
                                        ICML workshop 2022.

                                        <a href="https://arxiv.org/abs/2206.06811"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-06-14</div>
                            </div>
                            <div class="paper-date">2022-06-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Multi-instrument Music Synthesis with Spectrogram Diffusion  </div>
                                <div> Curtis Hawthorne, Ian Simon, Adam Roberts, Neil Zeghidour, Josh Gardner, Ethan Manilow, Jesse Engel </div>
                                <div>
                                        ISMIR 2022.

                                        <a href="https://arxiv.org/abs/2206.05408"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-06-11</div>
                            </div>
                            <div class="paper-date">2022-06-11</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Universal Speech Enhancement with Score-based Diffusion  </div>
                                <div> Joan Serrà, Santiago Pascual, Jordi Pons, R. Oguz Araz, Davide Scaini </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2206.03065"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-06-07</div>
                            </div>
                            <div class="paper-date">2022-06-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Zero-Shot Voice Conditioning for Denoising Diffusion TTS Models  </div>
                                <div> Alon Levkovitch, Eliya Nachmani, Lior Wolf </div>
                                <div>
                                        Interspeech 2022.

                                        <a href="https://arxiv.org/abs/2206.02246"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://alonlevko.github.io/ilvr-tts-diff"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-06-05</div>
                            </div>
                            <div class="paper-date">2022-06-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Guided-TTS 2: A Diffusion Model for High-quality Adaptive Text-to-Speech with Untranscribed Data  </div>
                                <div> Sungwon Kim, Heeseung Kim, Sungroh Yoon </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2205.15370"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://ksw0306.github.io/guided-tts2-demo/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-05-30</div>
                            </div>
                            <div class="paper-date">2022-05-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> BinauralGrad: A Two-Stage Conditional Diffusion Probabilistic Model for Binaural Audio Synthesis  </div>
                                <div> Yichong Leng, Zehua Chen, Junliang Guo, Haohe Liu, Jiawei Chen, Xu Tan, Danilo Mandic, Lei He, Xiang-Yang Li, Tao Qin, Sheng Zhao, Tie-Yan Liu </div>
                                <div>
                                        NeurIPS 2022.

                                        <a href="https://arxiv.org/abs/2205.14807"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://speechresearch.github.io/binauralgrad/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-05-30</div>
                            </div>
                            <div class="paper-date">2022-05-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis  </div>
                                <div> Rongjie Huang, Max W. Y. Lam, Jun Wang, Dan Su, Dong Yu, Yi Ren, Zhou Zhao </div>
                                <div>
                                        IJCAI 2022.

                                        <a href="https://arxiv.org/abs/2204.09934"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://fastdiff.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/Rongjiehuang/FastDiff"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-04-21</div>
                            </div>
                            <div class="paper-date">2022-04-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Speech Enhancement with Score-Based Generative Models in the Complex STFT Domain  </div>
                                <div> Simon Welker, Julius Richter, Timo Gerkmann </div>
                                <div>
                                        InterSpeech 2022.

                                        <a href="https://arxiv.org/abs/2203.17004"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/sp-uhh/sgmse"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-03-31</div>
                            </div>
                            <div class="paper-date">2022-03-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> SpecGrad: Diffusion Probabilistic Model based Neural Vocoder with Adaptive Noise Spectral Shaping  </div>
                                <div> Yuma Koizumi, Heiga Zen, Kohei Yatabe, Nanxin Chen, Michiel Bacchiani </div>
                                <div>
                                        Interspeech 2022.

                                        <a href="https://arxiv.org/abs/2203.16749"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-03-31</div>
                            </div>
                            <div class="paper-date">2022-03-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> BDDM: Bilateral Denoising Diffusion Models for Fast and High-Quality Speech Synthesis  </div>
                                <div> Max W. Y. Lam, Jun Wang, Dan Su, Dong Yu </div>
                                <div>
                                        ICLR 2022.

                                        <a href="https://arxiv.org/abs/2203.13508"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/tencent-ailab/bddm"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-03-25</div>
                            </div>
                            <div class="paper-date">2022-03-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Conditional Diffusion Probabilistic Model for Speech Enhancement  </div>
                                <div> Yen-Ju Lu, Zhong-Qiu Wang, Shinji Watanabe, Alexander Richard, Cheng Yu, Yu Tsao </div>
                                <div>
                                        IEEE 2022.

                                        <a href="https://arxiv.org/abs/2202.05256"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/neillu23/cdiffuse"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-02-10</div>
                            </div>
                            <div class="paper-date">2022-02-10</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> InferGrad: Improving Diffusion Models for Vocoder by Considering Inference in Training  </div>
                                <div> Zehua Chen, Xu Tan, Ke Wang, Shifeng Pan, Danilo Mandic, Lei He, Sheng Zhao </div>
                                <div>
                                        ICASSP 2022.

                                        <a href="https://arxiv.org/abs/2202.03751"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-02-08</div>
                            </div>
                            <div class="paper-date">2022-02-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ItôWave: Itô Stochastic Differential Equation Is All You Need For Wave Generation  </div>
                                <div> Shoule Wu, Ziqiang Shi </div>
                                <div>
                                        CoRR 2022.

                                        <a href="https://arxiv.org/abs/2201.12519"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://wushoule.github.io/ItoAudio/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-01-29</div>
                            </div>
                            <div class="paper-date">2022-01-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffGAN-TTS: High-Fidelity and Efficient Text-to-Speech with Denoising Diffusion GANs  </div>
                                <div> Songxiang Liu, Dan Su, Dong Yu </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2201.11972"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/keonlee9420/DiffGAN-TTS"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-01-28</div>
                            </div>
                            <div class="paper-date">2022-01-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Itô-Taylor Sampling Scheme for Denoising Diffusion Probabilistic Models using Ideal Derivatives  </div>
                                <div> Hideyuki Tachibana, Mocho Go, Muneyoshi Inahara, Yotaro Katayama, Yotaro Watanabe </div>
                                <div>
                                        arXiv 2021.

                                        <a href="https://arxiv.org/abs/2112.13339"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-12-26</div>
                            </div>
                            <div class="paper-date">2021-12-26</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Guided-TTS:Text-to-Speech with Untranscribed Speech  </div>
                                <div> Heeseung Kim, Sungwon Kim, Sungroh Yoon </div>
                                <div>
                                        ICML 2021.

                                        <a href="https://arxiv.org/abs/2111.11755"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-11-30</div>
                            </div>
                            <div class="paper-date">2021-11-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Denoising Diffusion Gamma Models  </div>
                                <div> Eliya Nachmani, Robin San Roman, Lior Wolf </div>
                                <div>
                                        arXiv 2021.

                                        <a href="https://arxiv.org/abs/2110.05948"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-10-10</div>
                            </div>
                            <div class="paper-date">2021-10-10</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> EdiTTS: Score-based Editing for Controllable Text-to-Speech  </div>
                                <div> Jaesung Tae, Hyeongju Kim, Taesu Kim </div>
                                <div>
                                        Interspeech 2022.

                                        <a href="https://arxiv.org/abs/2110.02584"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://editts.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/neosapience/EdiTTS"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-10-06</div>
                            </div>
                            <div class="paper-date">2021-10-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme  </div>
                                <div> Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova, Mikhail Kudinov, Jiansheng Wei </div>
                                <div>
                                        ICLR 2022.

                                        <a href="https://arxiv.org/abs/2109.13821"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://diffvc-fast-ml-solver.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-09-28</div>
                            </div>
                            <div class="paper-date">2021-09-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> A Study on Speech Enhancement Based on Diffusion Probabilistic Model  </div>
                                <div> Yen-Ju Lu, Yu Tsao, Shinji Watanabe </div>
                                <div>
                                        APSIPA 2021.

                                        <a href="https://arxiv.org/abs/2107.11876"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-07-25</div>
                            </div>
                            <div class="paper-date">2021-07-25</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Variational Diffusion Models  </div>
                                <div> Diederik P. Kingma, Tim Salimans, Ben Poole, Jonathan Ho </div>
                                <div>
                                        NeurIPS 2021.

                                        <a href="https://arxiv.org/abs/2107.00630"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/revsic/jax-variational-diffwave"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-07-01</div>
                            </div>
                            <div class="paper-date">2021-07-01</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis  </div>
                                <div> Nanxin Chen, Yu Zhang, Heiga Zen, Ron J. Weiss, Mohammad Norouzi, Najim Dehak, William Chan </div>
                                <div>
                                        Interspeech 2021.

                                        <a href="https://arxiv.org/abs/2106.09660"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://mindslab-ai.github.io/wavegrad2/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/keonlee9420/WaveGrad2"
                                           class="link-primary">Github</a> &nbsp
                                        <a href="https://github.com/mindslab-ai/wavegrad2"
                                           class="link-primary">Github2</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-06-17</div>
                            </div>
                            <div class="paper-date">2021-06-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> CRASH: Raw Audio Score-based Generative Modeling for Controllable High-resolution Drum Sound Synthesis  </div>
                                <div> Simon Rouard, Gaëtan Hadjeres </div>
                                <div>
                                        ISMIR 2021.

                                        <a href="https://arxiv.org/abs/2106.07431"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://crash-diffusion.github.io/crash/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-06-14</div>
                            </div>
                            <div class="paper-date">2021-06-14</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Driven Adaptive Prior  </div>
                                <div> Sang-gil Lee, Heeseung Kim, Chaehun Shin, Xu Tan, Chang Liu, Qi Meng, Tao Qin, Wei Chen, Sungroh Yoon, Tie-Yan Liu </div>
                                <div>
                                        ICLR 2022.

                                        <a href="https://arxiv.org/abs/2106.06406"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://speechresearch.github.io/priorgrad/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-06-11</div>
                            </div>
                            <div class="paper-date">2021-06-11</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffSVC: A Diffusion Probabilistic Model for Singing Voice Conversion*  </div>
                                <div> Songxiang Liu, Yuewen Cao, Dan Su, Helen Meng </div>
                                <div>
                                        IEEE 2021.

                                        <a href="https://arxiv.org/abs/2105.13871"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/liusongxiang/diffsvc"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-05-28</div>
                            </div>
                            <div class="paper-date">2021-05-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ItôTTS and ItôWave: Linear Stochastic Differential Equation Is All You Need For Audio Generation  </div>
                                <div> Shoule Wu, Ziqiang Shi </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2105.07583"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://wushoule.github.io/ItoAudio/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-05-17</div>
                            </div>
                            <div class="paper-date">2021-05-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech  </div>
                                <div> Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova, Mikhail Kudinov </div>
                                <div>
                                        ICML 2021.

                                        <a href="https://arxiv.org/abs/2105.06337"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://grad-tts.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/huawei-noah/Speech-Backbones/tree/main/Grad-TTS"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-05-13</div>
                            </div>
                            <div class="paper-date">2021-05-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism  </div>
                                <div> Jinglin Liu, Chengxi Li, Yi Ren, Feiyang Chen, Peng Liu, Zhou Zhao </div>
                                <div>
                                        AAAI 2022.

                                        <a href="https://arxiv.org/abs/2105.02446"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://diffsinger.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/keonlee9420/DiffSinger"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-05-06</div>
                            </div>
                            <div class="paper-date">2021-05-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism  </div>
                                <div> Jinglin Liu, Chengxi Li, Yi Ren, Feiyang Chen, Peng Liu, Zhou Zhao </div>
                                <div>
                                        AAAI 2022.

                                        <a href="https://arxiv.org/abs/2105.02446"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://diffsinger.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/keonlee9420/DiffSinger"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-05-06</div>
                            </div>
                            <div class="paper-date">2021-05-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Restoring degraded speech via a modified diffusion model  </div>
                                <div> Jianwei Zhang, Suren Jayasuriya, Visar Berisha </div>
                                <div>
                                        Interspeech 2021.

                                        <a href="https://arxiv.org/abs/2104.11347"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-04-22</div>
                            </div>
                            <div class="paper-date">2021-04-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling*  </div>
                                <div> Junhyeok Lee, Seungu Han </div>
                                <div>
                                        Interspeech 2021.

                                        <a href="https://arxiv.org/abs/2104.02321"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://mindslab-ai.github.io/nuwave/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/mindslab-ai/nuwave"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-04-06</div>
                            </div>
                            <div class="paper-date">2021-04-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diff-TTS: A Denoising Diffusion Model for Text-to-Speech*  </div>
                                <div> Myeonghun Jeong, Hyeongju Kim, Sung Jun Cheon, Byoung Jin Choi, Nam Soo Kim </div>
                                <div>
                                        Interspeech 2021.

                                        <a href="https://arxiv.org/abs/2104.01409"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-04-03</div>
                            </div>
                            <div class="paper-date">2021-04-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Symbolic Music Generation with Diffusion Models  </div>
                                <div> Gautam Mittal, Jesse Engel, Curtis Hawthorne, Ian Simon </div>
                                <div>
                                        ISMIR 2021.

                                        <a href="https://arxiv.org/abs/2103.16091"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/magenta/symbolic-music-diffusion"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-03-30</div>
                            </div>
                            <div class="paper-date">2021-03-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffWave: A Versatile Diffusion Model for Audio Synthesis  </div>
                                <div> Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, Bryan Catanzaro </div>
                                <div>
                                        ICLR 2021.

                                        <a href="https://arxiv.org/abs/2009.09761"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://diffwave-demo.github.io/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2020-09-21</div>
                            </div>
                            <div class="paper-date">2020-09-21</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> WaveGrad: Estimating Gradients for Waveform Generation  </div>
                                <div> Nanxin Chen, Yu Zhang, Heiga Zen, Ron J. Weiss, Mohammad Norouzi, William Cha </div>
                                <div>
                                        ICLR 2021.

                                        <a href="https://arxiv.org/abs/2009.00713"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://wavegrad.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/ivanvovk/WaveGrad"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2020-09-02</div>
                            </div>
                            <div class="paper-date">2020-09-02</div>
                        </li>
                </ol>
                <div class="mt-3 mb-3 text-center text-secondary">Counts - 118 &nbsp <a href="#">Back to
                    top</a></div>
            </main>

        </div>
    </div>
</div>


<!-- JavaScript Bundle with Popper -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-pprn3073KE6tl6bjs2QrFaJGz5/SUsLqktiwsUTF55Jfv3qYSDhgCecCxMW52nD2"
        crossorigin="anonymous"></script>
<script src="sidebars.js"></script>
<script>
    function toggle_counter() {
        const elements = document.getElementsByClassName("counter");
        for (let i = 0; i < elements.length; i++) {
            if (elements[i].style.display === "none") {
                console.log(elements[i].style.display)
                elements[i].style.display = "block";
            } else {
                elements[i].style.display = "none";
            }
        }
    }
</script>
</body>
</html>