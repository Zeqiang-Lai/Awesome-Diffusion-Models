<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <meta name="description" content=""/>
    <meta name="author"
          content="Zeqiang Lai"
    />
    <title>Awesome Diffusion</title>

    <!-- CSS only -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-0evHe/X+R7YkIZDRvuzKMRqM+OrBnVFBL6DOitfPri4tjfHxaWutUpFmBp4vmVor" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="style.css" rel="stylesheet"/>
    <link href="sidebars.css" rel="stylesheet"/>
</head>
<body>
<nav class="navbar navbar-expand-md fixed-top bg-light">
    <div class="container">
        <button
                class="navbar-toggler float-left"
                type="button"
                data-bs-toggle="collapse"
                data-bs-target="#bd-docs-nav"
                aria-controls="bd-docs-nav"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <a class="navbar-brand" href="#">Awesome Diffusion Models</a>
        <button
                class="navbar-toggler"
                type="button"
                data-bs-toggle="collapse"
                data-bs-target="#navbarCollapse"
                aria-controls="navbarCollapse"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav me-auto mb-2 mb-md-0">
                <li class="nav-item">
                        <a class="nav-link active" aria-current="page" href="index.html">Paper</a>
                </li>
                <li class="nav-item">
                        <a class="nav-link" href="resource.html">Resources</a>
                </li>
            </ul>
            <ul class="navbar-nav flex-row flex-wrap ms-md-auto">
                <li class="nav-item col-6 col-lg-auto">
                    <a class="nav-link py-2 px-0 px-lg-2" href="#" onclick="toggle_counter()"
                       rel="noopener">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                             class="bi bi-disc navbar-nav-svg" viewBox="0 0 16 16">
                            <path d="M8 15A7 7 0 1 1 8 1a7 7 0 0 1 0 14zm0 1A8 8 0 1 0 8 0a8 8 0 0 0 0 16z"/>
                            <path d="M10 8a2 2 0 1 1-4 0 2 2 0 0 1 4 0zM8 4a4 4 0 0 0-4 4 .5.5 0 0 1-1 0 5 5 0 0 1 5-5 .5.5 0 0 1 0 1zm4.5 3.5a.5.5 0 0 1 .5.5 5 5 0 0 1-5 5 .5.5 0 0 1 0-1 4 4 0 0 0 4-4 .5.5 0 0 1 .5-.5z"/>
                        </svg>
                        <small class="d-lg-none ms-2">Toggle Counter</small>
                    </a>
                </li>
                <li class="nav-item col-6 col-lg-auto">
                    <a class="nav-link py-2 px-0 px-lg-2" href="https://github.com/heejkoo/Awesome-Diffusion-Models" target="_blank" rel="noopener">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" class="navbar-nav-svg"
                             viewBox="0 0 512 499.36" role="img"><title>GitHub</title>
                            <path fill="currentColor" fill-rule="evenodd"
                                  d="M256 0C114.64 0 0 114.61 0 256c0 113.09 73.34 209 175.08 242.9 12.8 2.35 17.47-5.56 17.47-12.34 0-6.08-.22-22.18-.35-43.54-71.2 15.49-86.2-34.34-86.2-34.34-11.64-29.57-28.42-37.45-28.42-37.45-23.27-15.84 1.73-15.55 1.73-15.55 25.69 1.81 39.21 26.38 39.21 26.38 22.84 39.12 59.92 27.82 74.5 21.27 2.33-16.54 8.94-27.82 16.25-34.22-56.84-6.43-116.6-28.43-116.6-126.49 0-27.95 10-50.8 26.35-68.69-2.63-6.48-11.42-32.5 2.51-67.75 0 0 21.49-6.88 70.4 26.24a242.65 242.65 0 0 1 128.18 0c48.87-33.13 70.33-26.24 70.33-26.24 14 35.25 5.18 61.27 2.55 67.75 16.41 17.9 26.31 40.75 26.31 68.69 0 98.35-59.85 120-116.88 126.32 9.19 7.9 17.38 23.53 17.38 47.41 0 34.22-.31 61.83-.31 70.23 0 6.85 4.61 14.81 17.6 12.31C438.72 464.97 512 369.08 512 256.02 512 114.62 397.37 0 256 0z"></path>
                        </svg>
                        <small class="d-lg-none ms-2">GitHub</small>
                    </a>
                </li>
            </ul>
        </div>
    </div>
</nav>


<div class="container-fluid">
    <div class="container">
        <div class="row">
            <div class="col-md-3 bd-sidebar" style="padding-right: 2rem">
                <!-- <nav class="collapse show" id="bd-docs-nav"> -->
                    <ol class="list-unstyled">
                            <li class="mb-1">
                                <div class="d-flex justify-content-between align-items-center">
                                    <a class="btn rounded border-0 collapsed" href="vision.html">
                                        <strong>Vision</strong>
                                    </a>
                                    <span class="badge rounded-pill text-bg-secondary counter"> 1543 </span>
                                </div>
                                <div class="collapse show" id="home-collapse">
                                    <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Generation
                                                    </a>
                                                    <div class="counter">295</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_classification.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Classification
                                                    </a>
                                                    <div class="counter">31</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_segmentation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Segmentation
                                                    </a>
                                                    <div class="counter">49</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_image_translation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Image Translation
                                                    </a>
                                                    <div class="counter">46</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_inverse_problems.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Inverse Problems
                                                    </a>
                                                    <div class="counter">163</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_medical_imaging.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Medical Imaging
                                                    </a>
                                                    <div class="counter">133</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_multi-modal_learning.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Multi-modal Learning
                                                    </a>
                                                    <div class="counter">417</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_3d_vision.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >3D Vision
                                                    </a>
                                                    <div class="counter">183</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_adversarial_attack.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Adversarial Attack
                                                    </a>
                                                    <div class="counter">45</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="vision_miscellany.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Miscellany
                                                    </a>
                                                    <div class="counter">181</div>
                                                </div>
                                            </li>
                                    </ul>
                                </div>
                            </li>
                            <li class="mb-1">
                                <div class="d-flex justify-content-between align-items-center">
                                    <a class="btn rounded border-0 collapsed" href="audio.html">
                                        <strong>Audio</strong>
                                    </a>
                                    <span class="badge rounded-pill text-bg-secondary counter"> 118 </span>
                                </div>
                                <div class="collapse show" id="home-collapse">
                                    <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Generation
                                                    </a>
                                                    <div class="counter">34</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_conversion.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Conversion
                                                    </a>
                                                    <div class="counter">4</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_enhancement.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Enhancement
                                                    </a>
                                                    <div class="counter">25</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_separation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Separation
                                                    </a>
                                                    <div class="counter">5</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_text-to-speech.html"
                                                       class="a-toggle link-dark d-inline-flex text-decoration-none rounded"
                                                    >Text-to-Speech
                                                    </a>
                                                    <div class="counter">40</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="audio_miscellany.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Miscellany
                                                    </a>
                                                    <div class="counter">10</div>
                                                </div>
                                            </li>
                                    </ul>
                                </div>
                            </li>
                            <li class="mb-1">
                                <div class="d-flex justify-content-between align-items-center">
                                    <a class="btn rounded border-0 collapsed" href="tabular_and_time_series.html">
                                        <strong>Tabular and Time Series</strong>
                                    </a>
                                    <span class="badge rounded-pill text-bg-secondary counter"> 38 </span>
                                </div>
                                <div class="collapse show" id="home-collapse">
                                    <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="tabular_and_time_series_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Generation
                                                    </a>
                                                    <div class="counter">10</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="tabular_and_time_series_forecasting.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Forecasting
                                                    </a>
                                                    <div class="counter">12</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="tabular_and_time_series_imputation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Imputation
                                                    </a>
                                                    <div class="counter">6</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="tabular_and_time_series_miscellany.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Miscellany
                                                    </a>
                                                    <div class="counter">10</div>
                                                </div>
                                            </li>
                                    </ul>
                                </div>
                            </li>
                            <li class="mb-1">
                                <div class="d-flex justify-content-between align-items-center">
                                    <a class="btn rounded border-0 collapsed" href="graph.html">
                                        <strong>Graph</strong>
                                    </a>
                                    <span class="badge rounded-pill text-bg-secondary counter"> 70 </span>
                                </div>
                                <div class="collapse show" id="home-collapse">
                                    <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="graph_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Generation
                                                    </a>
                                                    <div class="counter">20</div>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="d-flex justify-content-between">
                                                    <a href="graph_molecular_and_material_generation.html"
                                                       class="link-dark d-inline-flex text-decoration-none rounded"
                                                    >Molecular and Material Generation
                                                    </a>
                                                    <div class="counter">50</div>
                                                </div>
                                            </li>
                                    </ul>
                                </div>
                            </li>
                    </ul>

                <!-- </nav> -->
            </div>
            <main class='col-md-9 bd-content' role="main">
                <ol class="list-group list-group-numbered">
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-Driven Foley Sound Generation With Latent Diffusion Model  </div>
                                <div> Yi Yuan, Haohe Liu, Xubo Liu, Xiyuan Kang, Peipei Wu, Mark D. Plumbley, Wenwu Wang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.10359"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-17</div>
                            </div>
                            <div class="paper-date">2023-06-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models  </div>
                                <div> Hao-Wen Dong, Xiaoyu Liu, Jordi Pons, Gautam Bhattacharya, Santiago Pascual, Joan Serrà, Taylor Berg-Kirkpatrick, Julian McAuley </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.09635"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-16</div>
                            </div>
                            <div class="paper-date">2023-06-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> UniCATS: A Unified Context-Aware Text-to-Speech Framework with Contextual VQ-Diffusion and Vocoding  </div>
                                <div> Chenpeng Du, Yiwei Guo, Feiyu Shen, Zhijun Liu, Zheng Liang, Xie Chen, Shuai Wang, Hui Zhang, Kai Yu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.07547"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-13</div>
                            </div>
                            <div class="paper-date">2023-06-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models  </div>
                                <div> Yinghao Aaron Li, Cong Han, Vinay S. Raghavan, Gavin Mischler, Nima Mesgarani </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.07691"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-13</div>
                            </div>
                            <div class="paper-date">2023-06-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Interpretable Style Transfer for Text-to-Speech with ControlVAE and Diffusion Bridge  </div>
                                <div> Wenhao Guan, Tao Li, Yishuang Li, Hukai Huang, Qingyang Hong, Lin Li </div>
                                <div>
                                        Interspeech 2023.

                                        <a href="https://arxiv.org/abs/2306.04301"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-07</div>
                            </div>
                            <div class="paper-date">2023-06-07</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive Bias  </div>
                                <div> Ziyue Jiang, Yi Ren, Zhenhui Ye, Jinglin Liu, Chen Zhang, Qian Yang, Shengpeng Ji, Rongjie Huang, Chunfeng Wang, Xiang Yin, Zejun Ma, Zhou Zhao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2306.03509"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://mega-tts.github.io/demo-page/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-06-06</div>
                            </div>
                            <div class="paper-date">2023-06-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Make-An-Audio 2: Temporal-Enhanced Text-to-Audio Generation  </div>
                                <div> Jiawei Huang, Yi Ren, Rongjie Huang, Dongchao Yang, Zhenhui Ye, Chen Zhang, Jinglin Liu, Xiang Yin, Zejun Ma, Zhou Zhao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.18474"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-29</div>
                            </div>
                            <div class="paper-date">2023-05-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ZET-Speech: Zero-shot adaptive Emotion-controllable Text-to-Speech Synthesis with Diffusion and Style-based Models  </div>
                                <div> Minki Kang, Wooseok Han, Sung Ju Hwang, Eunho Yang </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13831"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-23</div>
                            </div>
                            <div class="paper-date">2023-05-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ViT-TTS: Visual Text-to-Speech with Scalable Diffusion Transformer  </div>
                                <div> Huadai Liu, Rongjie Huang, Xuan Lin, Wenqiang Xu, Maozong Zheng, Hong Chen, Jinzheng He, Zhou Zhao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.12708"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://vit-tts.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffAVA: Personalized Text-to-Audio Generation with Visual Alignment  </div>
                                <div> Shentong Mo, Jing Shi, Yapeng Tian </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.12903"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> U-DiT TTS: U-Diffusion Vision Transformer for Text-to-Speech  </div>
                                <div> Xin Jing, Yi Chang, Zijiang Yang, Jiangjian Xie, Andreas Triantafyllopoulos, Bjoern W. Schuller </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.13195"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://eihw.github.io/u-dit-tts/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-22</div>
                            </div>
                            <div class="paper-date">2023-05-22</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> RMSSinger: Realistic-Music-Score based Singing Voice Synthesis  </div>
                                <div> Jinzheng He, Jinglin Liu, Zhenhui Ye, Rongjie Huang, Chenye Cui, Huadai Liu, Zhou Zhao </div>
                                <div>
                                        ACL 2023.

                                        <a href="https://arxiv.org/abs/2305.10686"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://rmssinger.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-18</div>
                            </div>
                            <div class="paper-date">2023-05-18</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency Model  </div>
                                <div> Zhen Ye, Wei Xue, Xu Tan, Jie Chen, Qifeng Liu, Yike Guo </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2305.06908"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://comospeech.github.io/"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-05-11</div>
                            </div>
                            <div class="paper-date">2023-05-11</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model  </div>
                                <div> Deepanway Ghosal, Navonil Majumder, Ambuj Mehrish, Soujanya Poria </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2304.13731"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://tango-web.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/declare-lab/tango"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-24</div>
                            </div>
                            <div class="paper-date">2023-04-24</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffVoice: Text-to-Speech with Latent Diffusion  </div>
                                <div> Zhijun Liu, Yiwei Guo, Kai Yu </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2304.11750"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-04-23</div>
                            </div>
                            <div class="paper-date">2023-04-23</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> An investigation into the adaptability of a diffusion-based TTS model  </div>
                                <div> Haolin Chen, Philip N. Garner </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2303.01849"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-03-03</div>
                            </div>
                            <div class="paper-date">2023-03-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Imaginary Voice: Face-styled Diffusion Model for Text-to-Speech  </div>
                                <div> Jiyoung Lee, Joon Son Chung, Soo-Whan Chung </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2302.13700"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-27</div>
                            </div>
                            <div class="paper-date">2023-02-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ERNIE-Music: Text-to-Waveform Music Generation with Diffusion Models  </div>
                                <div> Pengfei Zhu, Chao Pang, Shuohuan Wang, Yekun Chai, Yu Sun, Hao Tian, Hua Wu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.04456"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-09</div>
                            </div>
                            <div class="paper-date">2023-02-09</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Noise2Music: Text-conditioned Music Generation with Diffusion Models  </div>
                                <div> Qingqing Huang, Daniel S. Park, Tao Wang, Timo I. Denk, Andy Ly, Nanxin Chen, Zhengdong Zhang, Zhishuai Zhang, Jiahui Yu, Christian Frank, Jesse Engel, Quoc V. Le, William Chan, Wei Han </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2302.03917"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://google-research.github.io/noise2music/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-02-08</div>
                            </div>
                            <div class="paper-date">2023-02-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> InstructTTS: Modelling Expressive TTS in Discrete Latent Space with Natural Language Style Prompt  </div>
                                <div> Dongchao Yang, Songxiang Liu, Rongjie Huang, Guangzhi Lei, Chao Weng, Helen Meng, Dong Yu </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.13662"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="http://dongchaoyang.top/InstructTTS/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-31</div>
                            </div>
                            <div class="paper-date">2023-01-31</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models  </div>
                                <div> Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, Zhou Zhao </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.12661"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://text-to-audio.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-30</div>
                            </div>
                            <div class="paper-date">2023-01-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> AudioLDM: Text-to-Audio Generation with Latent Diffusion Models  </div>
                                <div> Haohe Liu, Zehua Chen, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, Mark D. Plumbley </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.12503"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://audioldm.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/haoheliu/AudioLDM"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-29</div>
                            </div>
                            <div class="paper-date">2023-01-29</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Moûsai: Text-to-Music Generation with Long-Context Latent Diffusion  </div>
                                <div> Flavio Schneider, Zhijing Jin, Bernhard Schölkopf </div>
                                <div>
                                        arXiv 2023.

                                        <a href="https://arxiv.org/abs/2301.11757"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://anonymous0.notion.site/anonymous0/Mo-sai-Text-to-Audio-with-Long-Context-Latent-Diffusion-b43dbc71caf94b5898f9e8de714ab5dc"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/archinetai/audio-diffusion-pytorch"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2023-01-27</div>
                            </div>
                            <div class="paper-date">2023-01-27</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> ResGrad: Residual Denoising Diffusion Probabilistic Models for Text to Speech  </div>
                                <div> Zehua Chen, Yihan Wu, Yichong Leng, Jiawei Chen, Haohe Liu, Xu Tan, Yang Cui, Ke Wang, Lei He, Sheng Zhao, Jiang Bian, Danilo Mandic </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2212.14518"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://resgrad1.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-30</div>
                            </div>
                            <div class="paper-date">2022-12-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Text-to-speech synthesis based on latent variable conversion using diffusion probabilistic model and variational autoencoder  </div>
                                <div> Yusuke Yasuda, Tomoki Toda </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2212.08329"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-12-16</div>
                            </div>
                            <div class="paper-date">2022-12-16</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> EmoDiff: Intensity Controllable Emotional Text-to-Speech with Soft-Label Guidance  </div>
                                <div> Yiwei Guo, Chenpeng Du, Xie Chen, Kai Yu </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2211.09496"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://cantabile-kwok.github.io/EmoDiff-intensity-ctrl/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-17</div>
                            </div>
                            <div class="paper-date">2022-11-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Any-speaker Adaptive Text-To-Speech Synthesis with Diffusion Models  </div>
                                <div> Minki Kang, Dongchan Min, Sung Ju Hwang </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2211.09383"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://nardien.github.io/grad-stylespeech-demo/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-17</div>
                            </div>
                            <div class="paper-date">2022-11-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> NoreSpeech: Knowledge Distillation based Conditional Diffusion Model for Noise-robust Expressive TTS  </div>
                                <div> Dongchao Yang, Songxiang Liu, Jianwei Yu, Helin Wang, Chao Weng, Yuexian Zou </div>
                                <div>
                                        ICASSP 2023.

                                        <a href="https://arxiv.org/abs/2211.02448"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-11-04</div>
                            </div>
                            <div class="paper-date">2022-11-04</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> WaveFit: An Iterative and Non-autoregressive Neural Vocoder based on Fixed-Point Iteration  </div>
                                <div> Yuma Koizumi, Kohei Yatabe, Heiga Zen, Michiel Bacchiani </div>
                                <div>
                                        IEEE SLT 2023.

                                        <a href="https://arxiv.org/abs/2210.01029"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://google.github.io/df-conformer/wavefit/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-10-03</div>
                            </div>
                            <div class="paper-date">2022-10-03</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diffsound: Discrete Diffusion Model for Text-to-sound Generation  </div>
                                <div> Dongchao Yang, Jianwei Yu, Helin Wang, Wen Wang, Chao Weng, Yuexian Zou, Dong Yu </div>
                                <div>
                                        TASLP 2022.

                                        <a href="https://arxiv.org/abs/2207.09983"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="http://dongchaoyang.top/text-to-sound-synthesis-demo/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-07-20</div>
                            </div>
                            <div class="paper-date">2022-07-20</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Zero-Shot Voice Conditioning for Denoising Diffusion TTS Models  </div>
                                <div> Alon Levkovitch, Eliya Nachmani, Lior Wolf </div>
                                <div>
                                        Interspeech 2022.

                                        <a href="https://arxiv.org/abs/2206.02246"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://alonlevko.github.io/ilvr-tts-diff"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-06-05</div>
                            </div>
                            <div class="paper-date">2022-06-05</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Guided-TTS 2: A Diffusion Model for High-quality Adaptive Text-to-Speech with Untranscribed Data  </div>
                                <div> Sungwon Kim, Heeseung Kim, Sungroh Yoon </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2205.15370"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://ksw0306.github.io/guided-tts2-demo/"
                                           class="link-primary">Project</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-05-30</div>
                            </div>
                            <div class="paper-date">2022-05-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> InferGrad: Improving Diffusion Models for Vocoder by Considering Inference in Training  </div>
                                <div> Zehua Chen, Xu Tan, Ke Wang, Shifeng Pan, Danilo Mandic, Lei He, Sheng Zhao </div>
                                <div>
                                        ICASSP 2022.

                                        <a href="https://arxiv.org/abs/2202.03751"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-02-08</div>
                            </div>
                            <div class="paper-date">2022-02-08</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffGAN-TTS: High-Fidelity and Efficient Text-to-Speech with Denoising Diffusion GANs  </div>
                                <div> Songxiang Liu, Dan Su, Dong Yu </div>
                                <div>
                                        arXiv 2022.

                                        <a href="https://arxiv.org/abs/2201.11972"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://github.com/keonlee9420/DiffGAN-TTS"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2022-01-28</div>
                            </div>
                            <div class="paper-date">2022-01-28</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Guided-TTS:Text-to-Speech with Untranscribed Speech  </div>
                                <div> Heeseung Kim, Sungwon Kim, Sungroh Yoon </div>
                                <div>
                                        ICML 2021.

                                        <a href="https://arxiv.org/abs/2111.11755"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-11-30</div>
                            </div>
                            <div class="paper-date">2021-11-30</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> EdiTTS: Score-based Editing for Controllable Text-to-Speech  </div>
                                <div> Jaesung Tae, Hyeongju Kim, Taesu Kim </div>
                                <div>
                                        Interspeech 2022.

                                        <a href="https://arxiv.org/abs/2110.02584"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://editts.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/neosapience/EdiTTS"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-10-06</div>
                            </div>
                            <div class="paper-date">2021-10-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis  </div>
                                <div> Nanxin Chen, Yu Zhang, Heiga Zen, Ron J. Weiss, Mohammad Norouzi, Najim Dehak, William Chan </div>
                                <div>
                                        Interspeech 2021.

                                        <a href="https://arxiv.org/abs/2106.09660"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://mindslab-ai.github.io/wavegrad2/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/keonlee9420/WaveGrad2"
                                           class="link-primary">Github</a> &nbsp
                                        <a href="https://github.com/mindslab-ai/wavegrad2"
                                           class="link-primary">Github2</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-06-17</div>
                            </div>
                            <div class="paper-date">2021-06-17</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech  </div>
                                <div> Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova, Mikhail Kudinov </div>
                                <div>
                                        ICML 2021.

                                        <a href="https://arxiv.org/abs/2105.06337"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://grad-tts.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/huawei-noah/Speech-Backbones/tree/main/Grad-TTS"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-05-13</div>
                            </div>
                            <div class="paper-date">2021-05-13</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism  </div>
                                <div> Jinglin Liu, Chengxi Li, Yi Ren, Feiyang Chen, Peng Liu, Zhou Zhao </div>
                                <div>
                                        AAAI 2022.

                                        <a href="https://arxiv.org/abs/2105.02446"
                                           class="link-primary">Paper</a> &nbsp
                                        <a href="https://diffsinger.github.io/"
                                           class="link-primary">Project</a> &nbsp
                                        <a href="https://github.com/keonlee9420/DiffSinger"
                                           class="link-primary">Github</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-05-06</div>
                            </div>
                            <div class="paper-date">2021-05-06</div>
                        </li>
                        <li class="list-group-item d-flex justify-content-between align-items-start list-item-flex">
                            <div class="ms-2 me-auto paper-main">
                                <div class="fw-bold"> Diff-TTS: A Denoising Diffusion Model for Text-to-Speech*  </div>
                                <div> Myeonghun Jeong, Hyeongju Kim, Sung Jun Cheon, Byoung Jin Choi, Nam Soo Kim </div>
                                <div>
                                        Interspeech 2021.

                                        <a href="https://arxiv.org/abs/2104.01409"
                                           class="link-primary">Paper</a> &nbsp
                                </div>
                                <div class="paper-date-inner">2021-04-03</div>
                            </div>
                            <div class="paper-date">2021-04-03</div>
                        </li>
                </ol>
                <div class="mt-3 mb-3 text-center text-secondary">Counts - 40 &nbsp <a href="#">Back to
                    top</a></div>
            </main>

        </div>
    </div>
</div>


<!-- JavaScript Bundle with Popper -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-pprn3073KE6tl6bjs2QrFaJGz5/SUsLqktiwsUTF55Jfv3qYSDhgCecCxMW52nD2"
        crossorigin="anonymous"></script>
<script src="sidebars.js"></script>
<script>
    function toggle_counter() {
        const elements = document.getElementsByClassName("counter");
        for (let i = 0; i < elements.length; i++) {
            if (elements[i].style.display === "none") {
                console.log(elements[i].style.display)
                elements[i].style.display = "block";
            } else {
                elements[i].style.display = "none";
            }
        }
    }
</script>
</body>
</html>